{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3.4] LM Agent Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup (don't read just run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "# os.chdir(\"c:\\\\Users\\\\styme\\\\OneDrive\\\\Documents\\\\AI STUFF\\\\Model Written Evals\\\\Code Replication\\\\ARENA_evals\\\\curriculum\")\n",
    "import wikipedia\n",
    "from wikipedia import WikipediaPage\n",
    "from wikipedia import DisambiguationError, PageError\n",
    "from openai import OpenAI\n",
    "from openai.types.chat.chat_completion_message_tool_call import ChatCompletionMessageToolCall\n",
    "from openai.types.chat.chat_completion_message import ChatCompletionMessage\n",
    "from anthropic import Anthropic\n",
    "from utils import establish_client_OpenAI\n",
    "from utils import retry_with_exponential_backoff\n",
    "from pprint import pprint\n",
    "from typing import Literal, Optional\n",
    "from inspect_ai.model import ChatMessageUser, ChatMessageAssistant, ChatMessageSystem\n",
    "import re\n",
    "from utils import countrylist\n",
    "from utils import evaluate_expression\n",
    "\n",
    "# Test the function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1Ô∏è‚É£ Intro to LM Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resources**:\n",
    "\n",
    "- [OpenAI Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)\n",
    "\n",
    "- [Anthropic Function Calling Guide](https://docs.anthropic.com/en/docs/build-with-claude/tool-use)\n",
    "\n",
    "- [Evaluating Language-Model Agents on Realistic Autonomous Tasks](https://evals.alignment.org/Evaluating_LMAs_Realistic_Tasks.pdf) (Kinniment et al., ARC Evaluations Team (now METR), 2023)\n",
    "\n",
    "- [Large Language Models can Strategically Deceive their Users when Put Under Pressure](https://arxiv.org/pdf/2311.07590) (Scheurer et al., Apollo Research, ICLR 2024)\n",
    "\n",
    "- [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/) (Lilian Weng, OpenAI Safety Team, 2023)\n",
    "\n",
    "- [AXRP Episode 34 - AI Evaluations with Beth Barnes](https://www.alignmentforum.org/posts/vACr4DExfeRMaCoo7/axrp-episode-34-ai-evaluations-with-beth-barnes) (Daniel Filan, 2024)\n",
    "\n",
    "- [Reflexion: Language Agents with Verbal Reinforcement Learning](https://arxiv.org/pdf/2303.11366) (Shinn et al., 2023)\n",
    "\n",
    "- [Answering Questions by Meta-Reasoning over Multiple Chains of Thought](https://arxiv.org/pdf/2304.13007) (Yoran et al., 2024)\n",
    "\n",
    "- [Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/pdf/2302.04761) (Schick et al., META AI Research, 2023)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is an LM agent?\n",
    "\n",
    "Points to make:\n",
    "- \"LM agent\" is a glorified for-loop\n",
    "    - Define scaffolding\n",
    "- More schematic breakdown of possible scaffolding: \"tools\" (describe what this means, what \"tool calling\" is), \"memory\"\n",
    "- Examples of prominent LM agents:\n",
    "    - Minecraft agent\n",
    "    - ...\n",
    "\n",
    "An LM agent consists of 4 main things.\n",
    "\n",
    "- A 'reasoner' or 'reasoning engine.' (Some people also call this a 'world model'). For LM agents this is a large language model.\n",
    "\n",
    "- Tools which allow the agent to act in the environment.\n",
    "\n",
    "- Memory so that the agent can recall prior actions. This can either be:\n",
    "\n",
    "    - Short-term memory: In the context of LM agents this is generally the context window\n",
    "\n",
    "    - Long-term memory: There are many cases where context-windows are too short, and we will need to give the agent high-level information about actions it took a long time ago. There are many methods to store this 'long-term memory' for agents (see some methods [here])\n",
    "\n",
    "- Scaffolding: This is essentially any structure which we provide to the 'reasoning engine' in order to help it to reason better, such as:\n",
    "\n",
    "    - Prompting frameworks.\n",
    "\n",
    "    - The ability to trial plans into the future.\n",
    "\n",
    "    - Using subagents to take care of subtasks.\n",
    "\n",
    "    - Subgoal decomposition.\n",
    "\n",
    "EXCALIDRAW!\n",
    "\n",
    "## Why Evaluate LM Agents?\n",
    "\n",
    "Points to make - \"Why evaluate LM agents\":\n",
    "- Models often fail in easily-fixable ways\n",
    "    - examples\n",
    "- How much capability can be unleashed by simple fixes? We want to gather evidence against the possibility that with simple tricks, a relative weak AI model like ChatGPT can do way more things than we previously thought. Maybe we are only using a small fraction of the model's capabilities, and the model could likely achieve a difficult hacking task if it can effectively direct all of its capabilities on it. If this is true, it would significantly change our evaluations of what models are capable of and what models are safe. LLM agent evals scaffolds the model to try to overcome simple failures and to elicit the maximum possible capability from the model. It would be evidence against this if we tried \"very hard\" to build LM agents and elicit capabilities for \"a long time\" and failed. However, it is also true that we can never be certain . More importantly, quantify \n",
    "    - Apollo \"Science of Evals\" \n",
    "    - GDM quantify bits\n",
    "\n",
    "\n",
    "Many of our threat models for the future harms of AI systems go through agentic behavior. If we knew that chatbots were only ever capable of simulating continuations of text in their context window, we'd still be worried about them ‚Äî but significantly less. However, we know today that this is not the case. In fact, since the release of ChatGPT, the use of LLMs as reasoning engines for agentic systems has proliferated signficantly. See [AutoGPT](https://autogpt.net/) and [LangChain](https://www.langchain.com/). These agents started off rather disappointingly when they were based on GPT-3.5, however as more powerful LLMs come out, and AI companies ensure their LLMs are better at tool-use, these agents will continue to improve. \n",
    "\n",
    "There are three main concerns for LM agents that we want to mitigate:\n",
    "\n",
    "- Their capabilities may be signficantly greater than those of the base LLM (especially when augmented with tool use).\n",
    "\n",
    "- There are many possible improvements for increased performance from LM agents, and these improvement methods are often signficantly cheaper and easier to implement than training the base model.\n",
    "\n",
    "- Current fine-tuning and RLHF/Constitutional AI methods are mostly targeted towards chatbot-style text output. We aren't as confident about how such methods will generalize to agentic scenarios.\n",
    "\n",
    "The first two issues here relate to the **capabilities** of LM agents, and the last issue relates to the **alignment** properties of LM agents. The agent we'll be building will be testing for the **capability** properties of agents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2Ô∏è‚É£ Build a simple LM agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will start by building a simple LM 'agent'. The task we'll get it to solve is an arithmetic task. LLMs struggle with arithmetic, but we can drastically improve their performance by providing a simple calculation tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Build a simple arithmetic problem\n",
    "```c\n",
    "Difficulty: üî¥üî¥üî¥‚ö™‚ö™\n",
    "Importance: üîµüîµ‚ö™‚ö™‚ö™\n",
    "\n",
    "You should spend up to 20-25 minutes on this exercise.\n",
    "```\n",
    "\n",
    "In LM agent eval, there will usually be a `Task` class, which interacts with the `Agent`. In general, this:\n",
    "- prepares and gives the task instruction (and necessary files, functions etc) to the agent\n",
    "- formats/processes and scores the agent's output\n",
    "- updates the task state accordingly (e.g. proceeds onto the next step of the task, ends the task)\n",
    "\n",
    "We will build a toy task called `ArithmeticProblem`. This task takes in two numbers and create a list of arithmetic calculation problems with the two numbers, using arithmetic operations defined in `operations`. \n",
    "\n",
    "Build a class for a \"game\" that takes in two numbers, and creates a task consisting of `len(operations)` many problems of the form \"Calculate `num1 operations[i] num2`\". Once one problem is solved, the class should move to the next one.\n",
    "\n",
    "We'll try the model with and without tools on this task, and see how significantly performance improves.\n",
    "\n",
    "<details><summary>Aside: Handling calculations</summary><br> When we handle the calculations for the model, technically we could use Python's <code>eval()</code> function (this is what <a href = \"https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/calculator_tool.ipynb\">Anthropic did</a>(!)). However, this function evaluates an arbitrary string expression, and so allows AI models to run arbitrary code. In the long-run, we're trying to do these evaluations on models which we suspect of being dangerous; so even though we could probably trust the current suite of language models offered by OpenAI and Anthropic, we should get into good habits of not running arbitrary code outputted by language models (except in very carefully set-up environments). To this end, we've implemented an <code>evaluate_expression</code> function for you to use instead.</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10 + 15': '25.0', '10 - 15': '-5.0', '10 * 15': '150.0', '10 / 15': '0.6666666666666666', '10 % 15': '10.0', '10 // 15': '0.0'}\n"
     ]
    }
   ],
   "source": [
    "class ArithmeticProblem:\n",
    "    def __init__(self, num1: int | float, num2: int | float):\n",
    "        self.num1 = num1\n",
    "        self.num2 = num2\n",
    "        self.operations: List[str] = [\"+\", \"-\", \"*\", \"/\", \"%\", \"//\"]\n",
    "        self.correct_answers: Dict[str, float] = self._generate_answers()\n",
    "        self.is_solved: Dict[str, bool] = {expr: False for expr in self.correct_answers}\n",
    "        self.current_task_number = 0\n",
    "\n",
    "    def _generate_answers(self) -> Dict[str, float]:\n",
    "        return {\n",
    "            f\"{self.num1} {op} {self.num2}\": eval(f\"{self.num1} {op} {self.num2}\")\n",
    "            for op in self.operations\n",
    "        }\n",
    "\n",
    "    def get_current_task(self) -> str:\n",
    "        \"\"\"\n",
    "        Returns the current task as a string\n",
    "        \"\"\"\n",
    "        return f\"{str(self.num1)} {self.operations[self.current_task_number]} {str(self.num2)}\"\n",
    "\n",
    "    def check_solved(self) -> bool:\n",
    "        \"\"\"\n",
    "        Returns True if all tasks are solved, False otherwise\n",
    "        \"\"\"\n",
    "        return all(self.is_solved.values())\n",
    "\n",
    "    def check_answer(self, model_answer: str) -> bool:\n",
    "        \"\"\"\n",
    "        Returns True if the model_answer is correct, False otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        correct_answer = self.correct_answers[get_current_task()]\n",
    "        return isclose(float(model_answer), correct_answer, rel_tol=1e-5, abs_tol=1e-8)\n",
    "        \n",
    "\n",
    "    def update_current_task(self) -> None:\n",
    "        \"\"\"\n",
    "        Sets the current task as solved and updates the current_task_number by one\n",
    "        \"\"\"\n",
    "        self.is_solved[get_current_task()] = True\n",
    "        self.current_task_number = (self.current_task_number + 1) % len(self.operations)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate(self, expression: str) -> str:\n",
    "        \"\"\"\n",
    "        Evaluates the string expression in Python using `evaluate_expression()` and returns the result as a string\n",
    "        \"\"\"\n",
    "        print(\"Expression received:\", expression)\n",
    "        try:\n",
    "            return str(evaluate_expression(expression))\n",
    "        except (SyntaxError, NameError, ZeroDivisionError) as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "x = ArithmeticProblem(10, 15)\n",
    "print(x.correct_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Write a tool description for `ArithmeticProblem`\n",
    "```c\n",
    "Difficulty: üî¥üî¥‚ö™‚ö™‚ö™\n",
    "Importance: üîµüîµüîµ‚ö™‚ö™\n",
    "\n",
    "You should spend up to 10-15 minutes on this exercise.\n",
    "```\n",
    "\n",
    "When you do this exercise, make sure you refer back to [OpenAI's function calling guide](https://platform.openai.com/docs/guides/function-calling). Anthropic has a good example of what good and bad tool calling looks like [here](https://docs.anthropic.com/en/docs/build-with-claude/tool-use#example-poor-tool-description) which you should refer to. The main takeaway, as always with LLMs, is to **provide explicit descriptions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_list = [\n",
    "    {\n",
    "        \"type\" : \"function\",\n",
    "        \"function\" : {\n",
    "            \"name\" : \"calculate\",\n",
    "            \"description\" : \"Calculates the result of an arithmetic expression. For example, you could provide an input in the form \\\"2+3\\\" and the function would return 5. Or you could provide an expression like \\\"10/3\\\" and the function would return 3.3333333333333335.\",\n",
    "            \"parameters\" : {\n",
    "                \"type\" : \"object\",\n",
    "                \"properties\" : {\n",
    "                    \"expression\" : {\n",
    "                        \"type\" : \"string\",\n",
    "                        \"description\" : \"The arithmetic expression that you want to be evaluated.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\" : [\"expression\"],\n",
    "                \"additionalProperties\" : False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are two functions that will be useful when designing agents. They take content and tool_call objects and return an expression which can be fed directly into the `ChatHistory`. If you're unsure about any aspect of them, then you should refer back to OpenAI's API documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_call_message(tool_call : ChatCompletionMessageToolCall, content : str) -> dict:\n",
    "    return {\n",
    "        \"role\" : \"tool\",\n",
    "        \"tool_call_id\" : tool_call.id,\n",
    "        \"name\" : tool_call.function.name,\n",
    "        \"content\" : content\n",
    "    }\n",
    "\n",
    "def user_message(content : str) -> dict:\n",
    "    return {\n",
    "        \"role\" : \"user\",\n",
    "        \"content\" : content\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Implement an LM agent class using the arithmetic task above\n",
    "```c\n",
    "Difficulty: üî¥üî¥üî¥üî¥‚ö™\n",
    "Importance: üîµüîµüîµüîµüîµ\n",
    "\n",
    "You should spend up to 20-25 minutes on this exercise.\n",
    "```\n",
    "\n",
    "Build out the following simple agent class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAgent:\n",
    "    def __init__(self, task : ArithmeticProblem, model : Literal['gpt-4o-mini'] = \"gpt-4o-mini\", tools : list = tool_list):\n",
    "        self.task = task \n",
    "        self.model = model\n",
    "        self.tools = tools\n",
    "        self.client = establish_client_OpenAI()\n",
    "\n",
    "\n",
    "        self.user_message = \"Calculate the result of the following expression: \" + self.task.get_current_task() + \".\"\n",
    "        self.answer_message = \"Now provide your answer in the format Answer: NUMBER where NUMBER is the answer to the question. Only output in this format.\"\n",
    "        self.incorrect_message = \"Incorrect.\"\n",
    "        self.correct_message = \"Correct.\"\n",
    "\n",
    "        self.messages=[user_message(self.user_message)]\n",
    "\n",
    "    @retry_with_exponential_backoff\n",
    "    def get_response_with_tools(self) -> ChatCompletionMessage:\n",
    "        # Generate a response where the model can use tools and add the response to the messages\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=self.messages,\n",
    "            tools = self.tools,\n",
    "            tool_choice = \"auto\"\n",
    "        )\n",
    "        self.messages.append(response.choices[0].message)\n",
    "        return response.choices[0].message\n",
    "\n",
    "    def get_response_no_tools(self) -> ChatCompletionMessage:\n",
    "        # Generate a response where the model cannot use tools and add the response to the messages\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=self.messages,\n",
    "        )\n",
    "        self.messages.append(response.choices[0].message)\n",
    "        return response.choices[0].message\n",
    "        \n",
    "    def do_tool_calls(self, message : ChatCompletionMessage) -> str:\n",
    "        # Do the tool calls and return the response and add the tool calls to the messages\n",
    "        tool_calls = message.tool_calls\n",
    "        if tool_calls:\n",
    "            for tool_call in tool_calls:\n",
    "                if tool_call.function.name == \"calculate\":\n",
    "                    func = getattr(self.task, tool_call.function.name)\n",
    "                    arguments = json.loads(tool_call.function.arguments)\n",
    "                    tool_response = func(**arguments)\n",
    "                    self.messages.append(tool_call_message(tool_call, str(tool_response)))\n",
    "            return tool_response\n",
    "        \n",
    "    def output_and_check_answer(self) -> ChatCompletionMessage:\n",
    "        '''\n",
    "        Get the model to output a final answer and then check if it is correct, and update the task. \n",
    "        Add the final answer to the messages, and tell the model if the answer is correct or incorrect.\n",
    "        '''\n",
    "        self.messages.append(user_message(self.answer_message))\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=self.messages,\n",
    "        )\n",
    "        self.messages.append(response.choices[0].message)\n",
    "        if self.task.check_answer(str(response.choices[0].message.content)[8:]):\n",
    "            self.messages.append(user_message(self.correct_message))\n",
    "            self.task.update_current_task()\n",
    "            self.user_message = \"Calculate the result of the following expression: \" + self.task.get_current_task() + \".\"\n",
    "            self.messages.append(user_message(self.user_message))\n",
    "        else:\n",
    "            self.messages.append(user_message(self.incorrect_message))\n",
    "        return response.choices[0].message\n",
    "        \n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Define an agent_loop which uses the agent class to solve the task\n",
    "```c\n",
    "Difficulty: üî¥‚ö™‚ö™‚ö™‚ö™\n",
    "Importance: üîµüîµüîµüîµ‚ö™\n",
    "\n",
    "You should spend up to 5-10 minutes on this exercise.\n",
    "```\n",
    "\n",
    "Try implementing the agent_loop below with and without tools, to see how much better the model does when we give it tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "1500 + 1091\n",
      "2591.0\n",
      "Answer: 2591\n",
      "None\n",
      "1500 - 1091\n",
      "409.0\n",
      "Answer: 409\n",
      "None\n",
      "1500 * 1091\n",
      "1636500.0\n",
      "Answer: 1636500\n",
      "None\n",
      "1500 / 1091\n",
      "1.374885426214482\n",
      "Answer: 1.374885426214482\n",
      "None\n",
      "1500 % 1091\n",
      "409.0\n",
      "Answer: 409\n",
      "None\n",
      "1500 // 1091\n",
      "1.0\n",
      "Answer: 1\n",
      "All tasks solved.\n",
      "All tasks solved.\n",
      "All tasks solved.\n",
      "All tasks solved.\n"
     ]
    }
   ],
   "source": [
    "task = ArithmeticProblem(1500,1091)\n",
    "agent = SimpleAgent(task)\n",
    "\n",
    "def agent_loop(numLoops : int = 10) -> NoneType:\n",
    "    for i in range(numLoops):\n",
    "        if task.check_solved():\n",
    "            print(\"All tasks solved.\")\n",
    "        else:\n",
    "            response = agent.get_response_with_tools()\n",
    "            print(response.content)\n",
    "            tool_response = agent.do_tool_calls(response)\n",
    "            print(tool_response)\n",
    "            response = agent.output_and_check_answer()\n",
    "            print(response.content)\n",
    "\n",
    "agent_loop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print all the messages from the `ChatHistory` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[43magent\u001b[49m\u001b[38;5;241m.\u001b[39mmessages:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(message\u001b[38;5;241m.\u001b[39mcontent))\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m: \u001b[38;5;28mprint\u001b[39m(message[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "for message in agent.messages:\n",
    "    try: print(str(message.content))\n",
    "    except: print(message[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3Ô∏è‚É£ Building a More Complex Task\n",
    "\n",
    "Now that we know how to do function calling, and have a rough understanding of what goes into designing an LM agent, we're going to build a more complicated task. This task won't be instantly solvable by LLMs with simple tool use, and so it will enable us to see if we can elicit better capabilities from models.\n",
    "\n",
    "The task we'll build and elicit behavior for will be the [Wikipedia game](https://en.wikipedia.org/wiki/Wikipedia:Wiki_Game). This is not directly related to any capabilities we are worried about, and if GPT-(N+1) were able to accomplish this task, but GPT-N weren't, then we wouldn't tell OpenAI to be particularly careful about the release of GPT-(N+1) as a result of this capability. However it does make a useful test case for elicitation methods, since by choosing different articles to navigate to/from, we can vary the difficulty continuously, compare performance on similar tasks, determine the stochasticicity of agent behavior, and more.\n",
    "\n",
    "EXCALIDRAW! (describing wikipedia game.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple function that uses the `wikipedia` API to get a `pageObject` for a particular page based on the title. We've implemented this function for you, just to handle the errors that most often come up when accessing wikipedia pages suggested by a language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "from wikipedia import DisambiguationError, PageError\n",
    "def get_page(title : str) -> WikipediaPage:\n",
    "    try: x = wikipedia.page(title,auto_suggest=False,redirect=True)\n",
    "    except DisambiguationError as e:\n",
    "        x = wikipedia.page(e.options[0], auto_suggest=False, redirect=True)\n",
    "    except PageError as e:\n",
    "        x = wikipedia.page(title, redirect=True, auto_suggest=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Familiarize yourself with the Wikipedia API\n",
    "```c\n",
    "Difficulty: üî¥üî¥‚ö™‚ö™‚ö™\n",
    "Importance: üîµüîµüîµ‚ö™‚ö™\n",
    "\n",
    "You should spend up to 15-20 mins on this exercise.\n",
    "```\n",
    "\n",
    "Familiarise yourself with the wikipedia API. Make sure you have a good understanding how content is outputted and structured for different pages, how different links are formatted, how we refer to and access pages, and why we've set the flags to `auto_suggest=False` and `redirect=True`.\n",
    "\n",
    "<details><summary> Aside: Wikipedia API content </summary>\n",
    "\n",
    "The wikipedia API often outputs content in unintuitive ways. For example, articles that are essentially just a big list become near useless, since the content omits the list (for example, see the wikipedia API content for <a href = \"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population\">List of countries and dependencies by population</a>). This is fine for our purposes, as these list articles are often banned in wikipedia racing anyway. But this is why it's important to determine what content the wikipedia API accesses ‚Äî anfd why you want to make sure you're testing a large diversity of wikipedia articles.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a list of countries and dependencies by population. It includes sovereign states, inhabited dependent territories and, in some cases, constituent countries of sovereign states, with inclusion within the list being primarily based on the ISO standard ISO 3166-1. For instance, the United Kingdom is considered a single entity, while the constituent countries of the Kingdom of the Netherlands are considered separately. In addition, this list includes certain states with limited recognition not found in ISO 3166-1. Also given in a percentage is each country's population compared with the world population, which the United Nations estimates at 8.13 billion as of 2024.\n",
      "\n",
      "\n",
      "== Method ==\n",
      "\n",
      "Figures used in this chart are based on the most up-to-date estimates or projections by the national census authority, where available, and are usually rounded off.\n",
      "Where updated national data are not available, figures are based on the estimates or projections for 2024 by the Population Division of the United Nations Department of Economic and Social Affairs.\n",
      "Because the compiled figures are not collected at the same time in every country, or at the same level of accuracy, the resulting numerical comparisons may create misleading conclusions. Furthermore, the addition of figures from all countries may not equal the world total.\n",
      "Areas that form integral parts of sovereign states, such as the countries of the United Kingdom, are counted as part of the sovereign states concerned. Not included are other entities that are not sovereign states, such as the European Union, and independent territories that do not have permanent populations, such as the Chagos Archipelago and various countries' claims to Antarctica.\n",
      "\n",
      "\n",
      "== Sovereign states and dependencies by population ==\n",
      "Note: A numbered rank is assigned to the 193 member states of the United Nations, plus the two observer states to the United Nations General Assembly. Dependent territories and constituent countries that are parts of sovereign states are not assigned a numbered rank. In addition, sovereign states with limited recognition are included, but not assigned a number rank.\n",
      "\n",
      "\n",
      "== See also ==\n",
      "List of countries by population (United Nations)\n",
      "Demographics of the world\n",
      "List of countries and dependencies by area\n",
      "List of countries and dependencies by population density\n",
      "List of countries by population growth rate\n",
      "\n",
      "\n",
      "== Explanatory notes ==\n",
      "\n",
      "\n",
      "== References ==\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "from wikipedia import WikipediaPage\n",
    "wikipedia_page = get_page(\"List of countries and dependencies by population\") # Experiment with different values for auto_suggest and redirect when using the agent. See what happens\n",
    "print(wikipedia_page.content)\n",
    "#print(wikipedia_page.title)\n",
    "#print(wikipedia_page.html())\n",
    "#print(wikipedia_page.links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Get a list of *accessible links* from a wikipedia page\n",
    "```c\n",
    "Difficulty: üî¥üî¥‚ö™‚ö™‚ö™\n",
    "Importance: üîµüîµüîµ‚ö™‚ö™\n",
    "\n",
    "You should spend up to 10-15 mins on this exercise.\n",
    "```\n",
    "\n",
    "When writing this function, if you manage to get the links in a very effective way, then do that. But remember that Wikipedia is written by a large number of different contributors, often adhering to inconsistent stylings (especially for smaller articles). We just need to get something that **works well enough**. Put more time into doing this effectively if you want at the end, but as soon as something plausibly works, you should move on.\n",
    "\n",
    "<img src=\"https://imgs.xkcd.com/comics/code_lifespan_2x.png\" width=\"400px\" style = \"margin-left: auto; margin-right: auto;display:block\"></img>\n",
    "\n",
    "The resulting list of accessible links should be about a third as long as the list of links from the wikipedia API (with more variance for shorter articles as you would expect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570\n",
      "1401\n",
      "444\n",
      "1593\n",
      "363\n",
      "1191\n",
      "329\n",
      "1093\n",
      "218\n",
      "982\n",
      "210\n",
      "815\n",
      "139\n",
      "706\n",
      "251\n",
      "1296\n",
      "119\n",
      "780\n",
      "519\n",
      "1657\n",
      "454\n",
      "1764\n",
      "198\n",
      "677\n",
      "334\n",
      "1248\n",
      "475\n",
      "978\n",
      "407\n",
      "1553\n",
      "247\n",
      "1071\n",
      "352\n",
      "1034\n",
      "450\n",
      "1541\n",
      "235\n",
      "799\n",
      "289\n",
      "897\n",
      "371\n",
      "1200\n",
      "284\n",
      "793\n",
      "156\n",
      "749\n",
      "363\n",
      "1087\n",
      "253\n",
      "1069\n",
      "245\n",
      "763\n",
      "473\n",
      "1254\n",
      "200\n",
      "778\n",
      "99\n",
      "324\n",
      "392\n",
      "1534\n",
      "223\n",
      "1066\n",
      "291\n",
      "1079\n",
      "203\n",
      "946\n",
      "170\n",
      "683\n",
      "268\n",
      "1309\n",
      "210\n",
      "809\n",
      "315\n",
      "1419\n",
      "178\n",
      "821\n",
      "155\n",
      "920\n",
      "177\n",
      "797\n",
      "163\n",
      "864\n",
      "377\n",
      "1112\n",
      "449\n",
      "2211\n",
      "176\n",
      "783\n",
      "152\n",
      "680\n",
      "321\n",
      "1213\n",
      "157\n",
      "714\n",
      "289\n",
      "944\n",
      "122\n",
      "677\n",
      "160\n",
      "605\n",
      "169\n",
      "756\n",
      "419\n",
      "1252\n",
      "302\n",
      "1171\n",
      "415\n",
      "1088\n",
      "443\n",
      "980\n",
      "483\n",
      "1423\n",
      "257\n",
      "888\n",
      "208\n",
      "692\n",
      "340\n",
      "1095\n",
      "147\n",
      "1109\n",
      "294\n",
      "766\n",
      "425\n",
      "1436\n",
      "223\n",
      "571\n",
      "207\n",
      "750\n",
      "260\n",
      "784\n",
      "426\n",
      "1154\n",
      "379\n",
      "1128\n",
      "141\n",
      "1223\n",
      "299\n",
      "811\n",
      "253\n",
      "740\n",
      "441\n",
      "1142\n",
      "677\n",
      "1790\n",
      "185\n",
      "673\n",
      "173\n",
      "514\n",
      "43\n",
      "258\n",
      "128\n",
      "687\n",
      "191\n",
      "758\n",
      "408\n",
      "1203\n",
      "479\n",
      "1231\n",
      "244\n",
      "1041\n",
      "324\n",
      "1449\n",
      "640\n",
      "1965\n",
      "251\n",
      "1300\n",
      "162\n",
      "636\n",
      "225\n",
      "891\n",
      "200\n",
      "1055\n",
      "274\n",
      "711\n",
      "192\n",
      "733\n",
      "151\n",
      "686\n",
      "208\n",
      "907\n",
      "352\n",
      "1142\n",
      "236\n",
      "652\n",
      "247\n",
      "1658\n",
      "420\n",
      "1228\n",
      "378\n",
      "945\n",
      "367\n",
      "1790\n",
      "302\n",
      "1369\n",
      "426\n",
      "1684\n",
      "318\n",
      "971\n",
      "506\n",
      "1441\n",
      "496\n",
      "1459\n",
      "657\n",
      "1484\n",
      "359\n",
      "1039\n",
      "293\n",
      "1405\n",
      "359\n",
      "978\n",
      "400\n",
      "1156\n",
      "329\n",
      "1189\n",
      "229\n",
      "648\n",
      "270\n",
      "1170\n",
      "369\n",
      "1209\n",
      "320\n",
      "920\n",
      "295\n",
      "821\n",
      "198\n",
      "972\n",
      "353\n",
      "914\n",
      "360\n",
      "1022\n",
      "138\n",
      "923\n",
      "227\n",
      "861\n",
      "320\n",
      "951\n",
      "232\n",
      "687\n",
      "506\n",
      "1251\n",
      "290\n",
      "808\n",
      "178\n",
      "1334\n",
      "335\n",
      "1034\n",
      "229\n",
      "773\n",
      "149\n",
      "728\n",
      "259\n",
      "1409\n",
      "235\n",
      "1398\n",
      "193\n",
      "798\n",
      "380\n",
      "1049\n",
      "229\n",
      "940\n",
      "353\n",
      "992\n",
      "130\n",
      "707\n",
      "318\n",
      "1128\n",
      "114\n",
      "664\n",
      "464\n",
      "1178\n",
      "158\n",
      "715\n",
      "479\n",
      "1356\n",
      "267\n",
      "1100\n",
      "256\n",
      "951\n",
      "197\n",
      "770\n",
      "381\n",
      "1315\n",
      "166\n",
      "818\n",
      "330\n",
      "904\n",
      "197\n",
      "809\n",
      "144\n",
      "534\n",
      "265\n",
      "1026\n",
      "494\n",
      "1273\n",
      "94\n",
      "483\n",
      "218\n",
      "651\n",
      "252\n",
      "1140\n",
      "253\n",
      "903\n",
      "287\n",
      "844\n",
      "365\n",
      "1206\n",
      "158\n",
      "924\n",
      "195\n",
      "1015\n",
      "174\n",
      "1131\n",
      "518\n",
      "1320\n",
      "278\n",
      "1132\n",
      "413\n",
      "2060\n",
      "159\n",
      "822\n",
      "210\n",
      "621\n",
      "213\n",
      "1280\n",
      "179\n",
      "663\n",
      "303\n",
      "990\n",
      "360\n",
      "1997\n",
      "143\n",
      "1012\n",
      "535\n",
      "1621\n",
      "561\n",
      "1302\n",
      "434\n",
      "1326\n",
      "291\n",
      "1151\n",
      "107\n",
      "549\n",
      "187\n",
      "775\n",
      "437\n",
      "1262\n",
      "634\n",
      "2237\n",
      "191\n",
      "876\n",
      "139\n",
      "565\n",
      "147\n",
      "690\n",
      "167\n",
      "518\n",
      "250\n",
      "646\n",
      "231\n",
      "616\n",
      "158\n",
      "718\n",
      "323\n",
      "1154\n",
      "226\n",
      "1007\n",
      "136\n",
      "729\n",
      "356\n",
      "1275\n",
      "413\n",
      "1360\n",
      "498\n",
      "1146\n",
      "596\n",
      "1295\n",
      "250\n",
      "880\n",
      "442\n",
      "1326\n",
      "442\n",
      "1614\n",
      "497\n",
      "1338\n",
      "352\n",
      "1287\n",
      "198\n",
      "734\n",
      "154\n",
      "647\n",
      "342\n",
      "843\n",
      "273\n",
      "860\n",
      "124\n",
      "873\n",
      "452\n",
      "1311\n",
      "441\n",
      "1169\n",
      "473\n",
      "1241\n",
      "381\n",
      "1211\n",
      "237\n",
      "720\n",
      "260\n",
      "1027\n",
      "409\n",
      "1521\n",
      "147\n",
      "710\n",
      "108\n",
      "601\n",
      "219\n",
      "553\n",
      "417\n",
      "1055\n",
      "328\n",
      "1046\n",
      "475\n",
      "1604\n",
      "270\n",
      "739\n",
      "280\n",
      "843\n",
      "242\n",
      "950\n",
      "439\n",
      "1439\n",
      "352\n",
      "1386\n",
      "648\n",
      "1868\n",
      "393\n",
      "1850\n",
      "256\n",
      "733\n",
      "310\n",
      "838\n",
      "213\n",
      "725\n",
      "282\n",
      "1585\n",
      "376\n",
      "1152\n",
      "409\n",
      "1520\n",
      "105\n",
      "845\n",
      "166\n",
      "667\n",
      "144\n",
      "463\n",
      "375\n",
      "951\n",
      "133\n",
      "560\n",
      "58\n",
      "368\n",
      "253\n",
      "782\n",
      "287\n",
      "1216\n"
     ]
    }
   ],
   "source": [
    "def get_permitted_links(current_page : WikipediaPage) -> list[str]:\n",
    "    #Only certain links will be accessible, since the wikipedia api returns a list of ALL possible links (lots of which would not be included in the actual content of the wikipedia, and almost all of which would be banned according to most rules of wiki racing).\n",
    "    all_links = current_page.links\n",
    "    content = current_page.content\n",
    "    permitted_links = []\n",
    "    for i in all_links:\n",
    "        if i in content:\n",
    "            permitted_links.append(i)\n",
    "    return permitted_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Wrap links within the wikipedia page content\n",
    "```c\n",
    "Difficulty: üî¥üî¥üî¥‚ö™‚ö™\n",
    "Importance: üîµüîµ‚ö™‚ö™‚ö™\n",
    "\n",
    "You should spend up to 15-20 mins on this exercise.\n",
    "```\n",
    "\n",
    "We want to present the content to the wikipedia agent with the links flagged, so that they agent knows what pages it can move to from its current page by reading the content. Implement the `get_content` function below so that any accessible links are wrapped in `<link></link>` tags.\n",
    "\n",
    "<details><summary>Why not just present a list of links?</summary>\n",
    "\n",
    "We don't just present a list of the accessible links, as this is not very faithful to the wikipedia game. The agent does perform better if we just give it a list of links (as it generally has a rough idea of what links will be accessible from future pages), but the task of parsing the content of wikipedia pages and isolating the most important links is where the majority of the challenge of the wikipedia game comes from.\n",
    "\n",
    "</details>\n",
    "\n",
    "The advice for the `get_permitted_links` function above also applies here: we only need to get **something that *works***, and will enable the agent to play the wikipedia game. Come back and spend more time at the end if you want to make improvements to this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(page : WikipediaPage) -> str:\n",
    "    content = page.content\n",
    "    permitted_links = get_permitted_links(page)\n",
    "    for word in sorted(permitted_links, key=len, reverse = True):\n",
    "        content = re.sub(\" \" + word + \" \", \" \" + f\"<link>{word}</link>\" + \" \", content, flags = re.I)\n",
    "        content = re.sub(\" \" + word + \",\", \" \" + f\"<link>{word}</link>\" + \",\", content, flags=re.I)\n",
    "        content = re.sub(\" \" + word + \".\", \" \" + f\"<link>{word}</link>\" + \".\", content, flags=re.I)\n",
    "        content = re.sub(\"\\(\" + word + \"\\)\", \"(\" + f\"<link>{word}</link>\" + \")\", content, flags = re.I)\n",
    "        content = re.sub(\" \" + word + \"s\", \" \" + f\"<link>{word}</link>\" + \"s\", content, flags = re.I)\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Build a class for the Wikipedia game\n",
    "```c\n",
    "Difficulty: üî¥üî¥üî¥üî¥‚ö™\n",
    "Importance: üîµüîµüîµüîµ‚ö™\n",
    "\n",
    "You should spend up to 25-30 mins on this exercise.\n",
    "```\n",
    "\n",
    "Implement the following class that instantiates the wikipedia game. When the model uses tools it will be making calls to this class, so make sure that the functions return messages you're happy for the model to see as a tool response, such as error messages if the tool doesn't work.\n",
    "\n",
    "Use code from the `get_permitted_links` and `get_content` functions above in this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikipediaGame:\n",
    "    def __init__(self, starting_page : str, goal_page : str, rules : list | type[None] = None):\n",
    "        '''\n",
    "        Initialises the wikipedia game object\n",
    "\n",
    "        starting_page is the page the agent starts on.\n",
    "\n",
    "        goal_page is the page the agent is trying to get to.\n",
    "\n",
    "        rules is a list of dictionaries specifying any additional rules along with a description of that rule to be fed to the agent.\n",
    "\n",
    "        Rules that are handled currently:\n",
    "            - \"no country\" bans country articles.\n",
    "            - \"no backtrack\" bans backtracking.\n",
    "        '''\n",
    "        self.page_title_history=[starting_page]\n",
    "        self.starting_page = get_page(starting_page) # page the game starts on\n",
    "        self.goal_page = get_page(goal_page) # page the game ends on\n",
    "        self.rules = rules # any additional rules, (no countries, no articles above a certain length, no backtracking etc. Need to add functionality to deal with these which I haven't done yet)\n",
    "        self.current_page = get_page(starting_page) # current page the game state is on.\n",
    "\n",
    "    def get_page_summary(self, page : WikipediaPage) -> str:\n",
    "        '''\n",
    "        Get summary of a wikipedia page, to the last full stop within the first 500 characters.\n",
    "        '''\n",
    "        summary = page.content[0:500]\n",
    "        return summary[0: summary.rindex(\".\")+1]\n",
    "\n",
    "    def move_page(self, **args : dict) -> str:\n",
    "        '''\n",
    "        Changes the current page of the game. To be used when we want to move from Page A to Page B\n",
    "        '''\n",
    "        new_page = args[\"new_page\"]\n",
    "        if self.is_permitted_link(new_page.lower()):\n",
    "            self.current_page = get_page(new_page)\n",
    "            self.page_title_history.append(self.current_page.title)\n",
    "            return \"Moving page to \" + self.current_page.title\n",
    "        elif self.is_permitted_link(new_page.replace(\"_\",\" \")):\n",
    "            self.current_page = get_page(new_page.replace(\"_\",\" \"))\n",
    "            self.page_title_history.append(self.current_page.title)\n",
    "            return \"Moving page to \" + self.current_page.title\n",
    "        else:\n",
    "            return \"Couldn't move page to \" + new_page\n",
    "\n",
    "    def get_content(self,**args : dict) -> str:\n",
    "        '''\n",
    "        Gives the content of the wikipedia page. Make sure that accessible links are wrapped with <link> </link> tags.\n",
    "        '''\n",
    "        content = self.current_page.content\n",
    "        for word in sorted(self.get_permitted_links(), key=len, reverse = True):\n",
    "            content = re.sub(\" \" + word + \" \", \" \" + f\"<link>{word}</link>\" + \" \",content, flags = re.I)\n",
    "            content = re.sub(\" \" + word + \",\", \" \" + f\"<link>{word}</link>\" + \",\", content, flags=re.I)\n",
    "            content = re.sub(\" \" + word + \".\", \" \" + f\"<link>{word}</link>\" + \".\", content, flags=re.I)\n",
    "            content = re.sub(\"\\(\" + word + \"\\)\", \"(\" + f\"<link>{word}</link>\" + \")\", content, flags = re.I)\n",
    "            content = re.sub(\" \" + word + \"s\", \" \" + f\"<link>{word}</link>\" + \"s\", content, flags = re.I)\n",
    "        return content\n",
    "\n",
    "    def get_permitted_links(self) -> list[str]:\n",
    "        #Only certain links will be accessible, since the wikipedia api returns a list of ALL possible links (lots of which would not be included in the actual content of the wikipedia, and almost all of which would be banned according to most rules of wiki racing).\n",
    "        all_links = self.current_page.links\n",
    "        content = self.current_page.content\n",
    "        permitted_links = []\n",
    "        for i in all_links:\n",
    "            if i in content:\n",
    "                permitted_links.append(i)\n",
    "        return permitted_links\n",
    "\n",
    "    def is_permitted_link(self, link : str) -> bool:\n",
    "        if link.lower() in (x.lower() for x in self.get_permitted_links()):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def check_win(self) -> type[None]:\n",
    "        if self.current_page==self.goal_page:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Write a list of tools for this game.\n",
    "```c\n",
    "Difficulty: üî¥‚ö™‚ö™‚ö™‚ö™\n",
    "Importance: üîµüîµüîµ‚ö™‚ö™\n",
    "\n",
    "You should spend up to 5-10 mins on this exercise.\n",
    "```\n",
    "\n",
    "Fill in the following list of tools that the agent will need to use to accomplish this game. You should name the tools according to the names in the `WikipediaGame` class above. This will help us later when we write the code for the agent, as it will be easier for us to execute the correct tool.\n",
    "\n",
    "When formatting this tool list, refer back to the tools you wrote for the arithmetic game, or else the docs are [here](https://platform.openai.com/docs/guides/function-calling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_content_tool = {\n",
    "    \"type\" : \"function\",\n",
    "    \"function\" : {\n",
    "        \"name\" : \"get_content\",\n",
    "        \"description\" : \"Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select will be wrapped in <link></link> tags.\",\n",
    "        \"parameters\" : {\n",
    "            \"type\" : \"object\",\n",
    "            \"properties\" : {},\n",
    "            \"required\" : []\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "move_page_tool = {\n",
    "    \"type\" : \"function\",\n",
    "    \"function\" : {\n",
    "        \"name\" : \"move_page\",\n",
    "        \"description\" : \"Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"new_page\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The title of the new page you want to move to. This should be formatted the way the title appears on wikipedia (e.g. to move to the wikipedia page for the United States of America, you should enter \\\"United States\\\"). Underscores are not necessary.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"new_page\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "WikipediaGameTools = [get_content_tool, move_page_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Build an agent class for the wikipedia racer\n",
    "```c\n",
    "üî¥üî¥üî¥üî¥‚ö™\n",
    "üîµüîµüîµüîµüîµ\n",
    "\n",
    "You should spend up to 30-40 mins on this exercise.\n",
    "```\n",
    "\n",
    "Now that you have the `WikipediaGame` class and tools set up, build out a `WikipediaRacingAgent` that can access these tools and solve the Wikipedia game. Build the agent so that it can be thrown into an agent loop (similar to the one we had for the arithmetic game) without much additional scaffolding. \n",
    "\n",
    "There are a few further considerations in this case that we didn't have for the arithmetic game. \n",
    "\n",
    "<details>\n",
    "<summary>Context window considerations</summary>\n",
    "\n",
    "Since the agent will need to read (potentially very long) Wikipedia articles to interact with the game, the length of the context window becomes relevant. GPT-4o and GPT-4o-mini both have context windows of 128k tokens (which corresponds to ~96k words) for reference, the wikipedia page for the United States has around 10k words alone and the agent will often need to visit more than 10 articles in one run of the game, not counting its own output, which eventually adds up to be significant. We'll solve this for now by resetting the messages of the agent every time it reaches a new wikipedia page, and providing an updated `user_message` (and possibly `system_message`) so that the agent can locate itself, and then proceed with the game. We'll address different methods for solving this issue later, you can probably already think of some. So be careful to include the current page and goal page for the agent in the `user_message`.\n",
    "\n",
    "</details>\n",
    "<br>\n",
    "\n",
    "\n",
    "<details><summary>Providing information to the agent</summary>\n",
    "\n",
    "There shouldn't be much on Wikipedia that the agent is completely unfamiliar with (AI companies *will* have scraped wikipedia), but it may be easily confused with something else, or be an article that was added before the training cutoff, and models can't always accurately use things in their training data anyway if they only come up once or twice. So you should use the game's get_summary function to provide details of the goal page to the agent in its initial message.\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary> Getting output from the agent </summary>\n",
    "\n",
    "In this case we'll have a lot more moving pieces than the `arithmeticGame` agent. In that case we could just print output from the agent loop. In this case, we strongly recommend that you should print output as it comes up in the agent class. If there's some chance you might not want to see this output, you should use a flag to determine whether to print content or not.\n",
    "\n",
    "</details>\n",
    "\n",
    "When making calls to the wikipediaGame class, make use of Python's `getattr()` function ([explanation here](https://www.w3schools.com/python/ref_func_getattr.asp)).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikipediaRacingAgent:\n",
    "    def __init__(self, wikigame, model = \"gpt-4o-mini\", tools = WikipediaGameTools, printFlag = True):\n",
    "        # Initialises the agent\n",
    "        self.game=wikigame\n",
    "        self.model = model\n",
    "        self.client = OpenAI()\n",
    "        self.tools = tools\n",
    "        \n",
    "        self.messages = [self.system_message, self.user_message] # Messages that are currently in the chat history.\n",
    "        self.all_messages = [self.system_message, self.user_message] # All messages that have been sent in the chat history. We have to erase each time a new page is reached for context window reasons.\n",
    "        self.response=None\n",
    "        self.printFlag = printFlag\n",
    "\n",
    "        #print starting messages to watch what the agent is doing\n",
    "        if self.printFlag: print(\"\\nSYSTEM: \" + self.system_message[\"content\"] + \"\\n\\nUSER: \" + self.user_message[\"content\"])\n",
    "\n",
    "    @property\n",
    "    def system_message(self):\n",
    "        return {\n",
    "            \"role\" : \"system\", \n",
    "            \"content\" : \"You are a wikipedia-racing AI. Your goal is to reach \" + self.game.goal_page.title + \" by accessing links from a series of wikipedia pages. Your current page is \" + self.game.current_page.title + \".\"\n",
    "            }\n",
    "            \n",
    "    @property\n",
    "    def user_message(self):\n",
    "        return {\n",
    "            \"role\" : \"user\",\n",
    "            \"content\" : \"You are currently on page: \" + self.game.current_page.title + \". Make sure you start by reasoning about what steps you should take to get to the article on \" + self.game.goal_page.title + \". When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, \" + self.game.goal_page.title + \" has the following summary: \\n\\n[Begin Summary]\\n\" + self.game.get_page_summary(self.game.goal_page) + \"\\n[End Summary] \" \n",
    "            }\n",
    "    \n",
    "    @property\n",
    "    def next_step_message(self):\n",
    "        return {\n",
    "            \"role\" : \"user\",\n",
    "            \"content\" : \"What's your next step to get to \" + self.game.goal_page.title + \"?\"\n",
    "        }\n",
    "    \n",
    "    @retry_with_exponential_backoff\n",
    "    def generate_response_with_tools(self):\n",
    "        # Generate a response with tools and add it to the messages.\n",
    "        \n",
    "        new_response = self.client.chat.completions.create(\n",
    "            model = self.model,\n",
    "            messages = self.messages,\n",
    "            tools = self.tools,\n",
    "            tool_choice = \"auto\"\n",
    "        )\n",
    "\n",
    "        self.response = new_response.choices[0].message\n",
    "        self.messages.append(self.response)\n",
    "        self.all_messages.append(self.response)\n",
    "\n",
    "        #Print message to watch what the agent is doing\n",
    "        if self.printFlag: print(\"\\n\" + str(self.response.content))\n",
    "\n",
    "        return self.response\n",
    "\n",
    "    def do_tool_calls(self, output):\n",
    "        # Handle the tool calls and return the response and add the tool calls to the messages\n",
    "        tool_calls = output.tool_calls\n",
    "        move_page_count = 0\n",
    "        if tool_calls:\n",
    "            for tool_call in tool_calls:\n",
    "                func = getattr(self.game, tool_call.function.name)\n",
    "                arguments = json.loads(tool_call.function.arguments)\n",
    "                new_response = func(**arguments)\n",
    "                self.messages.append(tool_call_message(tool_call,new_response))\n",
    "                self.all_messages.append(tool_call_message(tool_call,new_response))\n",
    "                \n",
    "                #Print message to watch what the agent is doing\n",
    "                if self.printFlag: print(\"\\nTOOL CALL\" + tool_call.function.name, arguments)\n",
    "                if self.printFlag: print(\"\\nTOOL RESPONSE:\" + new_response[:300])\n",
    "\n",
    "                if tool_call.function.name == \"move_page\" and \"Moving page\" in new_response:\n",
    "                    self.new_state()\n",
    "\n",
    "                    # TODO: Absolutely NEED to fix this goddamn moving page issue. Really need to think of a non-awful way to solve this problem. (pop things from a list, maybe just learn more about how OpenAI stores these lists)\n",
    "\n",
    "                    return \"new state\"\n",
    "                '''\n",
    "                elif tool_call.function.name==\"move_page\" and \"Couldn't\" in new_response:\n",
    "                    self.messages.append(user_message(\"That is not a valid link.\"))\n",
    "                    self.all_messages.append(user_message(\"That is not a valid link.\"))\n",
    "                '''\n",
    "                \n",
    "            self.messages.append(self.next_step_message)\n",
    "            self.all_messages.append(self.next_step_message)\n",
    "            \n",
    "            #Print message to watch what the agent is doing\n",
    "            if self.printFlag: print(\"\\nUSER: What's your next step to get to \" + self.game.goal_page.title + \"?\")\n",
    "                \n",
    "                    \n",
    "\n",
    "    def new_state(self):\n",
    "        # Begin a new state when a new page is visited. Update user_message and system_message, and reset self.messages (for context window reasons).\n",
    "        self.messages = [self.system_message,self.user_message]\n",
    "        self.all_messages.extend([self.system_message,self.user_message])\n",
    "\n",
    "        #Print message to watch what the agent is doing\n",
    "        if self.printFlag: print((\"-\" * 50) + \"\\n\\nNEW STATE\\n\\n\" + \"HISTORY: \" + \" -> \".join(self.game.page_title_history) + \"\\n\\n\" + (\"-\"*50))\n",
    "        if self.printFlag: print(\"SYSTEM: \" + self.system_message[\"content\"] + \"\\n\\nUSER: \" + self.user_message[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Implement the `agent_loop` for the `wikipediaRacingAgent`\n",
    "```c\n",
    "Difficulty: üî¥‚ö™‚ö™‚ö™‚ö™\n",
    "Importance: üîµüîµ‚ö™‚ö™‚ö™\n",
    "\n",
    "You should spend up to 5 mins on this exercise.\n",
    "```\n",
    "\n",
    "Just like we did for the arithmetic agent, you should write an agent loop for the wikipedia agent (in this case you won't need to print output, as we handled it in the agent class so this function should be a very simple loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_loop(agent, game, num_loops = 10):\n",
    "    for i in range(num_loops):\n",
    "        if game.check_win():\n",
    "            print(\"Success\")\n",
    "            return \"\"\n",
    "        response = agent.generate_response_with_tools()\n",
    "        agent.do_tool_calls(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SYSTEM: You are a wikipedia-racing AI. Your goal is to reach Zal√≠ben√° by accessing links from a series of wikipedia pages. Your current page is 1511 Dal√©ra.\n",
      "\n",
      "USER: You are currently on page: 1511 Dal√©ra. Make sure you start by reasoning about what steps you should take to get to the article on Zal√≠ben√°. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Zal√≠ben√° has the following summary: \n",
      "\n",
      "[Begin Summary]\n",
      "Zal√≠ben√° is a village and administrative part of Podveky in Kutn√° Hora District in the Central Bohemian Region of the Czech Republic. It has about 20 inhabitants.\n",
      "[End Summary] \n",
      "\n",
      "To reach the article on Zal√≠ben√°, I first need to explore the links available on the current page (1511 Dal√©ra) to find any relevant connections to the Czech Republic or the Central Bohemian Region. Since Zal√≠ben√° is a village in the Czech Republic, I should look for links leading to topics related to Czech geography, settlements, or possibly the Podveky administrative area.\n",
      "\n",
      "Here‚Äôs my plan:\n",
      "\n",
      "1. **Extract content**: Get the content of the page 1511 Dal√©ra to identify any links that could lead to regions, villages, or history related to the Czech Republic.\n",
      "2. **Evaluate links**: Look for any specific links that might lead towards Czech Republic-related topics.\n",
      "3. **Decide next move**: Based on the links found, choose one that appears to lead towards the area of interest (Czech Republic, villages, Podveky).\n",
      "\n",
      "Let me start by extracting the content from the page.\n",
      "[ChatCompletionMessageToolCall(id='call_dCBTf0f8inCxF3Jf7k9o9B6B', function=Function(arguments='{}', name='get_content'), type='function')]\n",
      "\n",
      "TOOL CALLget_content {}\n",
      "\n",
      "TOOL RESPONSE:1511 Dal√©ra, provisional designation 1939 FB, is an <link>Asteroid</link> from the inner regions of the <link>Asteroid</link> belt, approximately 12 kilometers in diameter. It was discovered on 22 March 1939, by French astronomer Louis Boyer at the Algerian <link>Algiers Observatory</link>, North Af\n",
      "\n",
      "USER: What's your next step to get to Zal√≠ben√°?\n",
      "\n",
      "The content of the page on 1511 Dal√©ra primarily discusses the asteroid and its various characteristics, such as its orbit, rotation period, and naming. Unfortunately, it does not include links that relate to the Czech Republic or any villages.\n",
      "\n",
      "Since the current page does not provide a pathway towards Zal√≠ben√°, I need to reconsider my strategy. I should explore an alternative approach by looking for a new page related to astronomy in the hopes of finding a link there that could eventually connect to the Czech Republic.\n",
      "\n",
      "I will check if there are any link opportunities from the Asteroid page that might connect to more general discussions about astronomy where links to geographical topics could potentially reside. \n",
      "\n",
      "Thus, my next step is to move to the page linked for \"Asteroid.\" \n",
      "[ChatCompletionMessageToolCall(id='call_WBMamRFeYX0CqIP0y9fhJFYs', function=Function(arguments='{\"new_page\":\"Asteroid\"}', name='move_page'), type='function')]\n",
      "\n",
      "TOOL CALLmove_page {'new_page': 'Asteroid'}\n",
      "\n",
      "TOOL RESPONSE:Moving page to Asteroid\n",
      "--------------------------------------------------\n",
      "\n",
      "NEW STATE\n",
      "\n",
      "HISTORY: 1511 Dal√©ra -> Asteroid\n",
      "\n",
      "--------------------------------------------------\n",
      "SYSTEM: You are a wikipedia-racing AI. Your goal is to reach Zal√≠ben√° by accessing links from a series of wikipedia pages. Your current page is Asteroid.\n",
      "\n",
      "USER: You are currently on page: Asteroid. Make sure you start by reasoning about what steps you should take to get to the article on Zal√≠ben√°. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Zal√≠ben√° has the following summary: \n",
      "\n",
      "[Begin Summary]\n",
      "Zal√≠ben√° is a village and administrative part of Podveky in Kutn√° Hora District in the Central Bohemian Region of the Czech Republic. It has about 20 inhabitants.\n",
      "[End Summary] \n",
      "\n",
      "To reach the page for Zal√≠ben√° from the Asteroid page, I‚Äôll need to identify relevant links that might lead me toward geographic or administrative topics, particularly related to the Czech Republic or villages. \n",
      "\n",
      "1. I should start by examining the content of the Asteroid page to find any links related to geography, celestial bodies, or possibly cultural references that could lead to countries or regions.\n",
      "2. If links to relevant subjects are not present, I might need to explore related astronomical topics, history, or science that could lead to Earth, geography, or regions globally.\n",
      "3. Once I identify links related to Earth, nations, or geographical areas, I will look specifically for Czech Republic or Central Bohemian Region.\n",
      "4. Ultimately, my goal is to find a path through various links until I can directly access the page for Zal√≠ben√°.\n",
      "\n",
      "Let‚Äôs begin by checking the content of the Asteroid page for links to potentially relevant topics. I will proceed with retrieving the content from the Asteroid page.\n",
      "[ChatCompletionMessageToolCall(id='call_q4fhvabaJFNG76Jprh8j8OLN', function=Function(arguments='{}', name='get_content'), type='function')]\n",
      "\n",
      "TOOL CALLget_content {}\n",
      "\n",
      "TOOL RESPONSE:An asteroid is a minor <link>Planet</link>.an object that is neither a true <link>Planet</link> nor an identified <link>Comet</link>. that orbits within the inner <link>Solar System</link>. They are rocky, metallic, or icy bodies with no atmosphere, classified as C-type (carbonaceous), M-type (metal\n",
      "\n",
      "USER: What's your next step to get to Zal√≠ben√°?\n",
      "\n",
      "The content from the Asteroid page doesn't provide direct links to geographical topics or the Czech Republic. However, there are links to significant subjects including \"Earth,\" \"Planet,\" and potentially \"Solar System,\" among others. \n",
      "\n",
      "Since Zal√≠ben√° is a village in the Central Bohemian Region of the Czech Republic, moving to the link for \"Earth\" may offer pathways to pages relating to geography, countries, or specific regions. Therefore, my next step will be to move to the page for **Earth**. \n",
      "\n",
      "I will now proceed to that page.\n",
      "[ChatCompletionMessageToolCall(id='call_KZqnjtUYuMNiLO8PHP1xj86X', function=Function(arguments='{\"new_page\":\"Earth\"}', name='move_page'), type='function')]\n",
      "\n",
      "TOOL CALLmove_page {'new_page': 'Earth'}\n",
      "\n",
      "TOOL RESPONSE:Moving page to Earth\n",
      "--------------------------------------------------\n",
      "\n",
      "NEW STATE\n",
      "\n",
      "HISTORY: 1511 Dal√©ra -> Asteroid -> Earth\n",
      "\n",
      "--------------------------------------------------\n",
      "SYSTEM: You are a wikipedia-racing AI. Your goal is to reach Zal√≠ben√° by accessing links from a series of wikipedia pages. Your current page is Earth.\n",
      "\n",
      "USER: You are currently on page: Earth. Make sure you start by reasoning about what steps you should take to get to the article on Zal√≠ben√°. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Zal√≠ben√° has the following summary: \n",
      "\n",
      "[Begin Summary]\n",
      "Zal√≠ben√° is a village and administrative part of Podveky in Kutn√° Hora District in the Central Bohemian Region of the Czech Republic. It has about 20 inhabitants.\n",
      "[End Summary] \n",
      "\n",
      "To reach the Wikipedia article on Zal√≠ben√° from Earth, I'll first need to identify relevant links that could guide me toward locations in the Czech Republic, as Zal√≠ben√° is a village there. Here‚Äôs a step-by-step approach to find an effective pathway:\n",
      "\n",
      "1. **Identify Geography Links:** I need to explore links related to geographic regions, countries, or administrative divisions that might lead me toward the Czech Republic or directly to information about it.\n",
      "\n",
      "2. **Look for the Czech Republic:** The next logical step is to find a link to the Czech Republic, its regions, or any towns or villages within it.\n",
      "\n",
      "3. **Explore Local Information:** Once I find the Czech Republic, I can look for specific information about regions like Central Bohemia, or even search for villages directly.\n",
      "\n",
      "Based on this strategy, I will first check the content of the current page (Earth) to find relevant links. Let's do that now.\n",
      "[ChatCompletionMessageToolCall(id='call_7vTfpUeoGYwrpSROo2iXcxKF', function=Function(arguments='{}', name='get_content'), type='function')]\n",
      "\n",
      "TOOL CALLget_content {}\n",
      "\n",
      "TOOL RESPONSE:Earth is the third planet from the <link>Sun</link> and the only astronomical object known to harbor <link>Life</link>. This is enabled by <link>Earth</link> being an <link>Ocean</link> world, the only one in the <link>Solar System</link> sustaining liquid surface water. Almost all of <link>Earth</l\n",
      "\n",
      "USER: What's your next step to get to Zal√≠ben√°?\n",
      "\n",
      "The next step is to move from the page on Earth to a page that is more specific to the Czech Republic. The goal is to find a link that should connect us to relevant geographic or political content related to the Czech Republic.\n",
      "\n",
      "From the content I reviewed, there are no direct links to the Czech Republic or related geographical regions. However, there are links to various items that could indirectly lead us to information about the Czech Republic, such as links to countries or concepts like \"Europe\".\n",
      "\n",
      "Given this, I will look for links that might lead to the overarching region or countries. The most relevant next step would be to click on the link to **\"Europe\"**, as this could lead to information about the countries, including the Czech Republic.\n",
      "\n",
      "Let's move to the page for Europe now.\n",
      "[ChatCompletionMessageToolCall(id='call_PqcjHkIMpQQwR5gd9A70kLwq', function=Function(arguments='{\"new_page\":\"Europe\"}', name='move_page'), type='function')]\n",
      "\n",
      "TOOL CALLmove_page {'new_page': 'Europe'}\n",
      "\n",
      "TOOL RESPONSE:Couldn't move page to Europe\n",
      "\n",
      "USER: What's your next step to get to Zal√≠ben√°?\n",
      "\n",
      "Since my attempt to move to the \"Europe\" page was unsuccessful, I need to reassess the options available on the current page (Earth) to find a relevant link that will lead me to the Czech Republic or related geopolitical content.\n",
      "\n",
      "Revisiting the content, I notice a few specific links that might be related to countries or regions, such as \"Africa,\" \"Asia,\" or \"Solar System.\" To advance towards Zal√≠ben√°, I should focus on the regions where the Czech Republic is located, which is part of Europe.\n",
      "\n",
      "The term \"Human\" and \"Human geography\" are mentioned as well, which might lead to a politically relevant context since the Czech Republic is linked to human activities and geography. \n",
      "\n",
      "To optimize my chances of reaching the Czech Republic or a relevant area, the best next step is to explore the link to **\"Human geography\"** as it could connect me to geographical contexts about nations, including the Czech Republic. Let's proceed with that.\n",
      "[ChatCompletionMessageToolCall(id='call_Oj0vBWgDWyITCyzAz6gXX9zr', function=Function(arguments='{\"new_page\":\"Human_geography\"}', name='move_page'), type='function')]\n",
      "\n",
      "TOOL CALLmove_page {'new_page': 'Human_geography'}\n",
      "\n",
      "TOOL RESPONSE:Moving page to Human geography\n",
      "--------------------------------------------------\n",
      "\n",
      "NEW STATE\n",
      "\n",
      "HISTORY: 1511 Dal√©ra -> Asteroid -> Earth -> Human geography\n",
      "\n",
      "--------------------------------------------------\n",
      "SYSTEM: You are a wikipedia-racing AI. Your goal is to reach Zal√≠ben√° by accessing links from a series of wikipedia pages. Your current page is Human geography.\n",
      "\n",
      "USER: You are currently on page: Human geography. Make sure you start by reasoning about what steps you should take to get to the article on Zal√≠ben√°. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Zal√≠ben√° has the following summary: \n",
      "\n",
      "[Begin Summary]\n",
      "Zal√≠ben√° is a village and administrative part of Podveky in Kutn√° Hora District in the Central Bohemian Region of the Czech Republic. It has about 20 inhabitants.\n",
      "[End Summary] \n",
      "\n",
      "To reach the Wikipedia page for Zal√≠ben√° from the page on Human Geography, I need to explore relevant links that lead me toward geographically focused content and ultimately to information about Czech villages.\n",
      "\n",
      "Here's the reasoning for my strategy:\n",
      "\n",
      "1. **Identify Relevant Links**: I need to first look for links on the Human Geography page that may be connected to geography, towns, or regions, particularly in Europe or the Czech Republic.\n",
      "\n",
      "2. **Focus Area**: Since Zal√≠ben√° is a village in the Czech Republic, I should specifically look for links related to:\n",
      "   - Regions or administrative divisions within the Czech Republic.\n",
      "   - General links about the Czech Republic.\n",
      "   - Related topics on villages or demographics.\n",
      "\n",
      "3. **Iterative Approach**: If the initial links do not lead directly to the target, I'll keep an eye out for secondary links that might provide better context or lead closer to Czech regional information.\n",
      "\n",
      "Let's start by fetching the content of the current page to visualize all accessible links.\n",
      "[ChatCompletionMessageToolCall(id='call_CJyGEQcsLilRL7M4TfWShdFY', function=Function(arguments='{}', name='get_content'), type='function')]\n",
      "\n",
      "TOOL CALLget_content {}\n",
      "\n",
      "TOOL RESPONSE:Human <link>Geography</link> or anthropogeography is the branch of <link>Geography</link> which studies spatial relationships between human communities, cultures, economies, and their interactions with the environment, examples of which include urban sprawl and urban redevelopment. It analyzes spati\n",
      "\n",
      "USER: What's your next step to get to Zal√≠ben√°?\n",
      "\n",
      "To get to the page for Zal√≠ben√°, my next step is to move towards a link that is geographically relevant, specifically targeting information about the Czech Republic or regions within it, as Zal√≠ben√° is a village in the Czech Republic.\n",
      "\n",
      "Looking through the content, there are links related to \"Geography,\" \"Settlement Geography,\" and also \"Population Geography.\" Since Zal√≠ben√° is a village, \"Settlement Geography\" would likely provide information about rural areas and villages, making it a good starting point.\n",
      "\n",
      "I'll move to the \"Settlement Geography\" page to explore further.\n",
      "[ChatCompletionMessageToolCall(id='call_r5ySFjHiRZ6Xa9mGd5H7VVsh', function=Function(arguments='{\"new_page\":\"Settlement Geography\"}', name='move_page'), type='function')]\n",
      "\n",
      "TOOL CALLmove_page {'new_page': 'Settlement Geography'}\n",
      "\n",
      "TOOL RESPONSE:Moving page to Settlement geography\n",
      "--------------------------------------------------\n",
      "\n",
      "NEW STATE\n",
      "\n",
      "HISTORY: 1511 Dal√©ra -> Asteroid -> Earth -> Human geography -> Settlement geography\n",
      "\n",
      "--------------------------------------------------\n",
      "SYSTEM: You are a wikipedia-racing AI. Your goal is to reach Zal√≠ben√° by accessing links from a series of wikipedia pages. Your current page is Settlement geography.\n",
      "\n",
      "USER: You are currently on page: Settlement geography. Make sure you start by reasoning about what steps you should take to get to the article on Zal√≠ben√°. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Zal√≠ben√° has the following summary: \n",
      "\n",
      "[Begin Summary]\n",
      "Zal√≠ben√° is a village and administrative part of Podveky in Kutn√° Hora District in the Central Bohemian Region of the Czech Republic. It has about 20 inhabitants.\n",
      "[End Summary] \n",
      "\n",
      "To navigate from the current page \"Settlement geography\" to the page \"Zal√≠ben√°,\" I need to identify relevant links that connect the concepts of geography, settlements, or regions to the specific area of Zal√≠ben√°, which mentions it is part of the Czech Republic.\n",
      "\n",
      "Here are my steps:\n",
      "\n",
      "1. **Check for Contextual Links**: The page on \"Settlement geography\" will probably have links related to geographical terminology, types of settlements, or specifics related to regions.\n",
      "\n",
      "2. **Identify Keywords and Regions**: Since Zal√≠ben√° is located in the Central Bohemian Region of the Czech Republic, I should look for links to topics that might lead towards this region, such as \"Czech Republic,\" \"Central Bohemian Region,\" or \"Kutn√° Hora District.\"\n",
      "\n",
      "3. **Follow Links Methodically**: If I find any relevant links about regions, I‚Äôll follow them to get closer to the specific area of Zal√≠ben√°.\n",
      "\n",
      "Let me first retrieve the content to find any relevant links.\n",
      "[ChatCompletionMessageToolCall(id='call_KQhchbNaqscdnvAZdGIRKkHW', function=Function(arguments='{}', name='get_content'), type='function')]\n",
      "\n",
      "TOOL CALLget_content {}\n",
      "\n",
      "TOOL RESPONSE:Settlement geography is a branch of human geography that investigates the <link>Earth's surface</link>.s part settled by humans. According to the <link>United Nations</link>. Vancouver Declaration on <link>Human settlement</link>. (1976), \"human settlements means the totality of the human community \n",
      "\n",
      "USER: What's your next step to get to Zal√≠ben√°?\n"
     ]
    }
   ],
   "source": [
    "game = WikipediaGame(\"1511 Dal√©ra\", \"Zal√≠ben√°\")\n",
    "agent = WikipediaRacingAgent(game,model=\"gpt-4o-mini\")\n",
    "agent_loop(agent, game, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': 'You are a wikipedia-racing AI. Your goal is to reach Zal√≠ben√° by accessing links from a series of wikipedia pages. Your current page is Settlement geography.'}\n",
      "{'role': 'user', 'content': \"You are currently on page: Settlement geography. Make sure you start by reasoning about what steps you should take to get to the article on Zal√≠ben√°. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Zal√≠ben√° has the following summary: \\n\\n[Begin Summary]\\nZal√≠ben√° is a village and administrative part of Podveky in Kutn√° Hora District in the Central Bohemian Region of the Czech Republic. It has about 20 inhabitants.\\n[End Summary] \"}\n",
      "ChatCompletionMessage(content='To navigate from the current page \"Settlement geography\" to the page \"Zal√≠ben√°,\" I need to identify relevant links that connect the concepts of geography, settlements, or regions to the specific area of Zal√≠ben√°, which mentions it is part of the Czech Republic.\\n\\nHere are my steps:\\n\\n1. **Check for Contextual Links**: The page on \"Settlement geography\" will probably have links related to geographical terminology, types of settlements, or specifics related to regions.\\n\\n2. **Identify Keywords and Regions**: Since Zal√≠ben√° is located in the Central Bohemian Region of the Czech Republic, I should look for links to topics that might lead towards this region, such as \"Czech Republic,\" \"Central Bohemian Region,\" or \"Kutn√° Hora District.\"\\n\\n3. **Follow Links Methodically**: If I find any relevant links about regions, I‚Äôll follow them to get closer to the specific area of Zal√≠ben√°.\\n\\nLet me first retrieve the content to find any relevant links.', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_KQhchbNaqscdnvAZdGIRKkHW', function=Function(arguments='{}', name='get_content'), type='function')], refusal=None)\n",
      "{'role': 'tool', 'tool_call_id': 'call_KQhchbNaqscdnvAZdGIRKkHW', 'name': 'get_content', 'content': 'Settlement geography is a branch of human geography that investigates the <link>Earth\\'s surface</link>.s part settled by humans. According to the <link>United Nations</link>. Vancouver Declaration on <link>Human settlement</link>. (1976), \"human settlements means the totality of the human community ‚Äì whether city, town or village ‚Äì with all the social, material, organizational, spiritual and cultural elements that sustain it.\"\\n\\n\\n== Classification ==\\nTraditionally, it belongs to cultural geography and is divided into the geography of urban settlements (cities and towns) and rural settlements (e.g. villages and hamlets). Thereby, settlements are mostly seen as elements of the cultural landscape that developed over time. Apart from <link>Australia</link>, <link>Europe</link> and <link>India</link>, the term is actually rarely used in English-speaking geography. One of the last English books on settlement geography was published by <link>Cambridge University Press</link> in the 1990s. However, it is a traditional and actual branch in many other countries (e.g., German Siedlungsgeographie, French Geographie de l\\'habitat, Italian Geografia insediativa, Polish Geografia osadnictwa).\\n\\n\\n== Actuality ==\\nDue to processes of urban sprawl such as counter urbanization, peri-urbanisation or postsuburbanisation the existing dichotomy between the urban and the rural is losing importance, especially in industrialized countries and newly industrialized countries. This point of view is already represented by many planning strategies such as  unified settlement planning. Hence, an integrative geography of settlements that considers the urban and the rural settlements as a continuum is regaining the importance lost during the 20th century. Further it is used in prehistoric, historic and present-focusing  geographic research.\\n\\n\\n== Definitions ==\\nReferring to Stone (1960), settlement geography is the description and analysis of the distribution of buildings by which people attach themselves to the land. Further, that the geography of settling designate the action of erecting buildings in order to occupy an area temporarily or permanently. It should be understood that buildings are one tangible expression of man-land relationships and that specification of this focus assumes study may be at any scale from quite general to most specific; there is no restriction to large-scale study of individual building plans or architectural details. Buildings are simply one representation of the process of people living in an area they are a mappable division of the landscape to which attention needs direction.\\nWith respect to Stone\\'s definition, Jordan (1966) emphasizes that settlement geography not exclusively investigates the distributions, but even more the structures, processes and interactions between settlements and its environment (such as soil, geomorphology, economy or society), which produce them. More recently, however,\\n\\nthe study of settlement has evolved into the interaction of humans with the physical and ecological world. This more holistic study is concerned with sustainability and seeks to better understand the present landscape and plan the future.\\nIn sum, settlement geography describes and explains the settlements\\' location, substance, form and structure, as well as the functions and processes that produced them over time (Genesis, from Greek Œ≥Œ≠ŒΩŒΩŒ∑œÉŒπœÇ, \"origin, birth\" or historical development). As an applied science, it projects future settlement development and contributes to the <link>Sustainable development</link> of human-environmental systems.\\n\\n\\n== See also ==\\nCircles of Sustainability\\nHuman settlement\\nSustainable development\\nUN-HABITAT\\nUrban geography\\n\\n\\n== References =='}\n",
      "{'role': 'user', 'content': \"What's your next step to get to Zal√≠ben√°?\"}\n"
     ]
    }
   ],
   "source": [
    "for i in agent.messages:\n",
    "    #try: print(i.content)\n",
    "    #except: print(i[\"content\"])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4Ô∏è‚É£ Elicitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conducting a capability evaluation is necessarily a very tricky task. This is because we're generally trying to show that the model does or dose not have a certain capability (which we're worried about). If the model does have this capability, then we should be able to demonstrate this, and we're done. However, even if we fail to demonstrate a capability, the model might still *have* this capability, perhaps:\n",
    "\n",
    "- We prompted the model poorly.\n",
    "\n",
    "- We stored the long-term history poorly.\n",
    "\n",
    "- We didn't give the model sufficient tools to accomplish the task.\n",
    "\n",
    "- There is some minor additional scaffolding that would drastically increase performance.\n",
    "\n",
    "It is easy to forget due to its ubiquity today, but it took *3.5 years* after the release of GPT-2 (and 2.5 years after the release of GPT-3) for people to discover that [Chain-of-thought reasoning improves model performance](https://arxiv.org/abs/2201.11903). A huge potential failure mode for the project of AI Safety is that people discover similar breakthroughs that push model-performance much higher with minimal additional training (and minimal additional alignment properties), so we want ensure we're trying really hard to elicit the best capability we possibly can, until we feel we've managed to gain [*evidence of absence*](https://en.wikipedia.org/wiki/Evidence_of_absence), not just *absence of evidence*.\n",
    "\n",
    "Broadly speaking, there are two categories of elicitation, narrow elicitation and general elicitation:\n",
    "\n",
    "- Narrow elicitation methods are those which will improve model performance on a particular task, or small class of tasks, but won't necessarily impact model performance in a more general way. A good example of narrow elicitation for the wikipedia game might be giving the agent access to the content of arbitrary wikipedia articles. This will improve performance on this task significantly, but wouldn't generalize to a broad array of tasks.\n",
    "\n",
    "- General elicitation methods are those which will improve model performance on a wide array of possible tasks. A good example of a general elicitation method is chain-of-thought. This tends to improve model performance on a wide array of tasks. These sorts of elicitation methods are the ones we're most interested in, as if researchers find an improvement to models that is roughly as easy and effective as chain-of-thought prompting, then we would see a very rapid increase in risk from AI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting\n",
    "\n",
    "You should already be aware that prompting can have a large impact on model performance. There are a large number of possible changes to prompts for this task. You should experiment first with more general elicitation methods such as getting the agent to think more deeply, and output plans in different ways. \n",
    "\n",
    "After this, you might try a wide array of narrow elicitation methods including:\n",
    "\n",
    "- Telling the agent how many pages it's visited.\n",
    "\n",
    "- Telling the agent if it's already visited the page it's on (and how many times).\n",
    "\n",
    "- Schedule different prompts and planning methods for the \"zoom out\" and \"zoom in\" sections of the game, since the general strategy for the wikipedia game looks like:\n",
    "\n",
    "    Specific article (with few links) -> General article (with many links) -> Specific article (with few links)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Try different prompts\n",
    "```c\n",
    "Difficulty: üî¥üî¥‚ö™‚ö™‚ö™\n",
    "Importance: üîµüîµüîµ‚ö™‚ö™\n",
    "\n",
    "You should spend up to 20-25 mins on this exercise.\n",
    "```\n",
    "\n",
    "Remember that your prompts obviously will have to be robust to: \n",
    "\n",
    "* Different tasks within the wikipedia game, \n",
    "\n",
    "* Different states within those tasks,\n",
    "\n",
    "* Different failure-modes the agent could encounter.\n",
    "\n",
    "Mess around with the prompting setup and see if you can significantly improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikipediaRacingAgentPrompting(WikipediaRacingAgent):\n",
    "\n",
    "    @property\n",
    "    def system_message(self):\n",
    "        return {\n",
    "            \"role\" : \"system\", \n",
    "            \"content\" : \"You are a wikipedia-racing AI. Your goal is to reach \" + self.game.goal_page.title + \" by accessing links from a series of wikipedia pages. Your current page is \" + self.game.current_page.title + \".\"\n",
    "            }\n",
    "    @property\n",
    "    def user_message(self):\n",
    "        return {\n",
    "            \"role\" : \"user\",\n",
    "            \"content\" : \"You are currently on page: \" + self.game.current_page.title + \". Make sure you start by reasoning about what steps you should take to get to the article on \" + self.game.goal_page.title + \". When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, \" + self.game.goal_page.title + \" has the following summary: \\n\\n[Begin Summary]\\n\" + self.game.get_page_summary(self.game.goal_page) + \"\\n[End Summary]\"\n",
    "            }\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = WikipediaGame(\"Aristotle\", \"Othello\")\n",
    "agent = WikipediaRacingAgentPrompting(game, model=\"gpt-4o-mini\")\n",
    "agent_loop(agent, game, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Implement the ReAct framework\n",
    "```c\n",
    "Difficulty: üî¥üî¥‚ö™‚ö™‚ö™\n",
    "Importance: üîµüîµüîµ‚ö™‚ö™\n",
    "\n",
    "You should spend up to 10-15 mins on this exercise.\n",
    "```\n",
    "\n",
    "Chain-of-thought prompting confers significant benefits to model performance, and you probably tried it when you messed around with prompting above. But when we're using LLMs as agents, we may want to provide a different structure to elicit reasoning. This is called the [**ReAct** framework](https://arxiv.org/abs/2210.03629); it consists of:\n",
    "\n",
    "- Getting the model to generate **Re**asoning about its current situation, and what sort of actions it should consider taking.\n",
    "\n",
    "- Then getting the model to perform an **Act**ion based on its outputted reasoning.\n",
    "\n",
    "Remember that if you're calling the model without tools, it won't have a description of the tools in its system message, so we'll have to ensure that the tool descriptions are in the `system_message` (this will lead to some redundancy when the model takes an action, but that's alright)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikipediaRacingAgentReAct(WikipediaRacingAgentPrompting):\n",
    "\n",
    "    @property\n",
    "    def system_message(self):\n",
    "        #You may or may not want to edit your standard system message\n",
    "        return {\n",
    "            \"role\" : \"system\",\n",
    "            \"content\" : \"You are a wikipedia-racing AI. Your goal is to reach \" + self.game.goal_page.title + \" by accessing links from wikipedia pages. Your current page is \" + self.game.current_page.title + \". You have access to \" + str(len(self.tools)) + \"tools:\" + \"\\n\".join([tool[\"function\"][\"name\"] + \": \" + tool[\"function\"][\"description\"] for tool in self.tools]) + \".\\n\"\n",
    "        } #Provided a description of the tools in the system message. When generate is called with tools this is redundant, but when generate is called without tools, this is useful.\n",
    "    \n",
    "    @property\n",
    "    def user_message(self):\n",
    "        #You may or may not want to edit your standard user message\n",
    "        return {\n",
    "            \"role\" : \"user\",\n",
    "            \"content\" : \"You are currently on page: \" + self.game.current_page.title + \". Make sure you start by reasoning about what steps you should take to get to the article on \" + self.game.goal_page.title + \". When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, \" + self.game.goal_page.title + \" has the following summary: \\n\\n[Begin Summary]\\n\" + self.game.get_page_summary(self.game.goal_page) + \"\\n[End Summary].\"\n",
    "        }\n",
    "    \n",
    "    @retry_with_exponential_backoff\n",
    "    def generate_response(self, use_tools=True):\n",
    "        # Generate a response with or without tools and add it to the messages\n",
    "        new_response = self.client.chat.completions.create(\n",
    "            model = self.model,\n",
    "            messages = self.messages,\n",
    "            tools = self.tools if use_tools else None,\n",
    "            tool_choice = \"auto\" if use_tools else None\n",
    "        )\n",
    "        return new_response.choices[0].message\n",
    "\n",
    "    def generate_reason(self):\n",
    "        # Get the model to reason about the current state of the game and add the response to the messages (you may not want to give it tools for this)\n",
    "        self.messages.append(user_message(\"Think carefully about your current situation and what actions you want to take to get closer to\" + self.game.goal_page.title + \".\"))\n",
    "        response = self.generate_response(use_tools=False)\n",
    "        self.messages.append(response)\n",
    "        return response\n",
    "        \n",
    "    def generate_action(self):\n",
    "        # Get the model to generate an action based on the reasoning and add the response to the messages\n",
    "        self.messages.append(user_message(\"What action do you want to take?\"))\n",
    "        response = self.generate_response()\n",
    "        self.messages.append(response)\n",
    "        return response\n",
    "    \n",
    "    def generate_reason_and_action(self):\n",
    "        # Generate a reason and then an action\n",
    "        reason = self.generate_reason()\n",
    "        print(reason.content)\n",
    "        action = self.generate_action()\n",
    "        print(action.content)\n",
    "        self.do_tool_calls(action)\n",
    "        return action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have to rewrite your `agent_loop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_loop_ReAct(game, agent, numLoops = 10):\n",
    "    for i in range(numLoops):\n",
    "        if game.check_win():\n",
    "            print(\"Success\")\n",
    "            return \"\"\n",
    "        agent.generate_reason_and_action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = WikipediaGame(\"Aristotle\", \"Othello\")\n",
    "agent = WikipediaRacingAgentReAct(game, model=\"gpt-4o-mini\", tools = WikipediaGameTools)\n",
    "agent_loop_ReAct(game, agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaffolding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the literature on AI agents, scaffolding is generally used to refer to everything that is not the language model itself. So prompting and tool use are both part of the scaffolding, as well as frameworks like ReAct or Reflexion, or providing the history. Since we'll be spending more time on prompt methods and tool usage, these have their own category, so \"scaffolding\" becomes essentially a category for things that are more \"structural\" than simple tool use or prompting methods. But you shouldn't be surprised when you people just talk about scaffolding as a catch-all in papers.\n",
    "\n",
    "In this section we will improve the scaffolding by:\n",
    "\n",
    "- Telling the agent its history.\n",
    "\n",
    "- Giving the agent a simple \"[reflexion tool](https://arxiv.org/pdf/2303.11366)\" \n",
    "\n",
    "- Telling the agent if it's already visited a page.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Implement an agent history property\n",
    "```c\n",
    "Difficulty: üî¥‚ö™‚ö™‚ö™‚ö™\n",
    "Importance: üîµüîµ‚ö™‚ö™‚ö™\n",
    "\n",
    "You should spend up to 5-10 mins on this exercise.\n",
    "```\n",
    "\n",
    "You may notice that the agent frequently gets stuck in loops. Since we're already storing a history of page titles in the game class, we should try providing this information to the agent and see if it improves the looping behavior. Implement this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikipediaRacingAgentHistory(WikipediaRacingAgentReAct):\n",
    "    @property\n",
    "    def system_message(self):\n",
    "        return {\n",
    "            \"role\" : \"system\",\n",
    "            \"content\" : \"You are a wikipedia-racing AI. Your goal is to reach \" + self.game.goal_page.title + \" by accessing links from a series of wikipedia pages. Your current page is \" + self.game.current_page.title + \". You have access to \" + str(len(self.tools)) + \"tools:\\n\" + \"\\n\".join([tool[\"function\"][\"name\"] + \": \" + tool[\"function\"][\"description\"] for tool in self.tools]) + \".\\n\"\n",
    "            }\n",
    "    \n",
    "    @property\n",
    "    def user_message(self):\n",
    "        return {\n",
    "            \"role\" : \"user\",\n",
    "            \"content\" : \"You are currently on page: \" + self.game.current_page.title + \". Make sure you start by reasoning about what steps you should take to get to the article on \" + self.game.goal_page.title + \". When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, \" + self.game.goal_page.title + \" has the following summary: \\n\\n[Begin Summary]\\n\" + self.game.get_page_summary(self.game.goal_page) + \"\\n[End Summary]\\n The pages you've visited so far has been: \" + \" -> \".join(self.game.page_title_history)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Implement a reflexion tool\n",
    "```c\n",
    "Difficulty: üî¥üî¥üî¥‚ö™‚ö™\n",
    "Importance: üîµüîµüîµ‚ö™‚ö™\n",
    "\n",
    "You should spend up to 10-15 mins on this exercise.\n",
    "```\n",
    "\n",
    "[This paper](https://arxiv.org/abs/2303.11366) finds better performance by LLMs on tasks when they can perform \"lookahead\" and get feedback on their plans. We will imitate this by allowing the agent to suggest candidate paths, and informing it where these paths go wrong (if they do). You'll need to add this tool to the list of tools.\n",
    "\n",
    "We don't want to provide the agent the links/content of every page when it does this lookahead, as then we'd just be reimplementing a smaller version of the game *inside the game*. Instead, we'll let the agent suggest paths without seeing any content or links, and then let it know if this path works. It's very likely that a suggested link will, at some point, not be accessible from one of the pages, but this should still help to guide the agent's plans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikipediaGameTestPath(WikipediaGame):\n",
    "    def __init__(self, starting_page : str, goal_page : str, rules : list | type[None] = None):\n",
    "        super().__init__(starting_page, goal_page, rules)\n",
    "\n",
    "    def get_permitted_links_any_page(self, title):\n",
    "        #Only certain links will be accessible, since the wikipedia api returns a list of ALL possible links (lots of which would not be included in the actual content of the wikipedia, and almost all of which would be banned according to most rules of wiki racing).\n",
    "        all_links = get_page(title).links\n",
    "        content = get_page(title).content\n",
    "        permitted_links = []\n",
    "        for i in all_links:\n",
    "            if i.lower() in content.lower():\n",
    "                permitted_links.append(i)\n",
    "        return permitted_links\n",
    "    def test_path(self, path : str) -> str:\n",
    "        '''\n",
    "        Reflexion test_path function, takes a dict like {\"path\": \"Barack Obama -> Indonesia -> India\"} and returns True if the path works, for a path like \"Barack Obama -> Indonesia -> Pink Floyd\" it would return \"This path works until Pink floyd, which is not accessible from Indonesia\".\n",
    "        '''\n",
    "        print(\"\\n\\n\\n\\n\\n\\n\\n\\n\\n Test path \\n\\n\\n\\n\\n\\n\\n\\n\\n\")\n",
    "        path = path.split(\"->\")\n",
    "        if path[0].strip() != self.current_page.title:\n",
    "            return \"ERROR: The title of the start page of this path is not the title of your current page.\"\n",
    "        for i in range(len(path)-1):\n",
    "            if path[i+1].strip().lower() in [link.lower() for link in self.get_permitted_links_any_page(path[i])]:\n",
    "                continue\n",
    "            else:\n",
    "                return \"This path works until \" + path[i+1].strip() + \", which is not accessible from \" +path[i].strip()\n",
    "        return \"This path completely works.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write a description of this tool and add it to the list of `WikipediaGameTools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path_tool = {\n",
    "    \"type\" : \"function\",\n",
    "    \"function\" : {\n",
    "        \"name\" : \"test_path\",\n",
    "        \"description\" : \"Accepts a test path string in the form \\\"current_page -> page1 -> page2 -> ... -> pageN\\\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \\\"success.\\\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\",\n",
    "        \"parameters\" : {\n",
    "            \"type\" : \"object\",\n",
    "            \"properties\": {\n",
    "                \"path\" : {\n",
    "                    \"type\" : \"string\",\n",
    "                    \"description\" : \"The path you want to test, formatted as \\\" current_page -> page1 -> page2 -> ... -> pageN\\\".\"\n",
    "                },\n",
    "            },\n",
    "            \"required\" : [\"path\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "WikipediaGameTools = [get_content_tool, move_page_tool, test_path_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = WikipediaGameTestPath(\"William Pitt the Younger\", \"Central Vietnam\")\n",
    "agent = WikipediaRacingAgentHistory(game, model=\"gpt-4o-mini\", tools = WikipediaGameTools)\n",
    "agent_loop_ReAct(game,agent, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also give the agent additional tools that may be useful for the wikipediaGame task, or more general tooling methods. \n",
    "\n",
    "\n",
    "#### **[JAMES COMMENT]** I still need to figure out what to say about tool use. If you have any ideas then open to suggestions :) Lilian Weng did a little \"humans use tools\" and so do some animals thing. A cute animal pic might actually go over quite well here IMO.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " but if you give the agent too many tools (especially with poor descriptions), then performance can often suffer. This happens most prominently when using more than 5-10 tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Implement a page summary tool\n",
    "```c\n",
    "Difficulty:üî¥üî¥‚ö™‚ö™‚ö™\n",
    "Importance:üîµüîµ‚ö™‚ö™‚ö™\n",
    "\n",
    "You should spend up to 10-15 mins on this exercise.\n",
    "```\n",
    "\n",
    "Implement a tool that allows an agent to get a summary of an accessible page. This imitates wikipedia's native 'hover summary' tool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_page_summary = {\n",
    "    \"type\" : \"function\",\n",
    "    \"function\" : {\n",
    "        \"name\" : \"get_page_summary\",\n",
    "        \"description\" : \"Get the summary of a wikipedia page you are considering moving to, to the last full stop within the first 500 characters. The page needs to be accessible via a link from the current page. Anything which corresponds to a link you can select will be wrapped in <link></link> tags\",\n",
    "        \"parameters\" : {\n",
    "            \"type\" : \"object\",\n",
    "            \"properties\" : {\n",
    "                \"page\" : {\n",
    "                    \"type\" : \"object\",\n",
    "                    \"description\" : \"The wikipedia page you want to get the summary of.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\" : [\"page\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "class WikipediaGamePageSummary(WikipediaGameTestPath):\n",
    "    def __init__(self, starting_page : str, goal_page : str, rules : list | type[None] = None):\n",
    "        super().__init__(starting_page, goal_page, rules)\n",
    "\n",
    "        \n",
    "    def get_page_summary(self, page : WikipediaPage) -> str:\n",
    "        if is_permitted_link(self, page):\n",
    "            summary = page.content[0:500]\n",
    "            return summary[0: summary.rindex(\".\")+1]\n",
    "        else:\n",
    "            return \"This page is not accessible from the current page, so a summary cannot be returned.\"\n",
    "\n",
    "WikipediaGameTools.append(get_page_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Implement an arbitrary page summary/content tool\n",
    "```c\n",
    "Difficulty:üî¥‚ö™‚ö™‚ö™‚ö™\n",
    "Importance:üîµüîµ‚ö™‚ö™‚ö™\n",
    "\n",
    "You should spend up to 5-10 mins on this exercise.\n",
    "```\n",
    "\n",
    "Now implement a tool that allows the agent to suggest any wikipedia page, and get a brief summary of it. This may be helpful for the agent to formulate plans into the future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_page_content = {\n",
    "    \"type\" : \"function\",\n",
    "    \"function\" : {\n",
    "        \"name\" : \"get_page_content\",\n",
    "        \"description\" : \"Get the content of a wikipedia page you are considering moving to. Anything which corresponds to a link you can select will be wrapped in <link></link> tags.\",\n",
    "        \"parameters\" : {\n",
    "            \"type\" : \"object\",\n",
    "            \"properties\" : {\n",
    "                \"page\" : {\n",
    "                    \"type\" : \"object\",\n",
    "                    \"description\" : \"The wikipedia page you want to get the content of.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\" : [\"page\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "class WikipediaGamePageContent(WikipediaGamePageSummary):\n",
    "    def __init__(self, starting_page : str, goal_page : str, rules : list | type[None] = None):\n",
    "        super().__init__(starting_page, goal_page, rules)\n",
    "    def get_page_content(self, arguments : dict) -> str:\n",
    "        page = arguments[\"page\"]\n",
    "        content = page.content\n",
    "        return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Implement a ctrl-F tool\n",
    "\n",
    "Still need to do this. Probably will though. Not super urgent. Might add more elicitation stuff later if I think of any that seem cool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Fine-Tuning\n",
    "\n",
    "We're not going to conduct supervised fine-tuning here. But it's worth mentioning as an elicitation method, just because it can be so powerful. [ADD MORE INFO HERE LATER]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5Ô∏è‚É£ Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Implement additional rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test agent performance on these tasks:\n",
    "- Task 1\n",
    "\n",
    "- Task 2\n",
    "\n",
    "- Task 3\n",
    "\n",
    "- Task 4\n",
    "\n",
    "- Task 5\n",
    "\n",
    "- Task 6\n",
    "\n",
    "- Task 7\n",
    "\n",
    "- Task 8\n",
    "\n",
    "- Task 9\n",
    "\n",
    "- Task 10\n",
    "\n",
    "See what combination of tools appears to work best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Rearrange so that each page is broken up by sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_WikipediaPage__continued_query', '_WikipediaPage__load', '_WikipediaPage__title_query_param', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'categories', 'content', 'coordinates', 'html', 'images', 'links', 'original_title', 'pageid', 'parent_id', 'references', 'revision_id', 'section', 'sections', 'summary', 'title', 'url']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = get_page(\"Aristotle\")\n",
    "print(dir(x))\n",
    "print(x.section(\"Metaphysics/Substance\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
