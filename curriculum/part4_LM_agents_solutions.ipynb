{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# [3.4] LLM Agent Evaluations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Setup (don't read just run)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 222,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    import google.colab  # type: ignore\n",
                "\n",
                "    IN_COLAB = True\n",
                "except:\n",
                "    IN_COLAB = False\n",
                "\n",
                "import os, sys\n",
                "\n",
                "chapter = \"chapter3_lm_evals\"\n",
                "repo = \"ARENA_3.0\"\n",
                "\n",
                "if IN_COLAB:\n",
                "    # Install packages\n",
                "    %pip install openai==0.28\n",
                "    %pip install anthropic\n",
                "    %pip install jaxtyping\n",
                "    %pip install time\n",
                "    %pip install wikipedia\n",
                "\n",
                "    # Code to download the necessary files (e.g. solutions, test funcs) => fill in later\n",
                "\n",
                "else:\n",
                "    pass  # fill in later\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 223,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import os\n",
                "\n",
                "import wikipedia\n",
                "from wikipedia import WikipediaPage\n",
                "from wikipedia import DisambiguationError, PageError\n",
                "from openai import OpenAI\n",
                "from openai.types.chat.chat_completion_message_tool_call import (\n",
                "    ChatCompletionMessageToolCall,\n",
                ")\n",
                "from openai.types.chat.chat_completion_message import ChatCompletionMessage\n",
                "from anthropic import Anthropic\n",
                "from utils import establish_client_OpenAI\n",
                "from utils import retry_with_exponential_backoff\n",
                "from typing import Literal, Optional, Dict, List, Any\n",
                "from abc import abstractmethod\n",
                "import math\n",
                "import re\n",
                "from utils import countrylist\n",
                "from utils import evaluate_expression, apply_user_format, apply_assistant_format\n",
                "\n",
                "# Test the function"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1️⃣ Intro to LLM Agents"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## What is an LLM agent?\n",
                "<!---\n",
                "Points to make:\n",
                "- \"LLM agent\" - a \"scaffolding\" program (i.e. Python program) that interacts with an LLM API. Include a version of METR \"Evaluating Language-Model Agents on Realistic Autonomous Tasks\" Figure 2\n",
                "    - Define scaffolding\n",
                "- More schematic breakdown of possible scaffolding: \"tools\" (describe what this means, what \"tool calling\" is), \"memory\" (Probably better move to \"Build Agent\" section! I've expanded this section there)\n",
                "- Mention list of examples of prominent LLM agents:\n",
                "    - [Minecraft LM Agent](https://arxiv.org/abs/2305.16291)\n",
                "    - [AutoGPT](https://autogpt.net/) and [LangChain](https://www.langchain.com/)\n",
                "\n",
                "==========================\n",
                "--->\n",
                "An LLM \"agent\" consists of **a scaffolding program interacting with an LLM API**. Initially, the scaffolding program sends instructions to the LLM on the task goal, the actions available to the LLM, and any relevant task information. The LLM then interacts with the scaffolding program in a sequence of steps, taking actions and observing their results. The scaffolding program will perform any actions or interactions with the task as instructed by the LLM; it will also return the outcome of these actions to the LLM agent. This allows the LLM to solve a task relatively autonomously (i.e. with little human input).\n",
                "\n",
                "The two main elements of scaffolding are:\n",
                "- Tool calling: This provides a description of a tool to the agent, which it can choose to use during the evauation. If it uses a tool then the scaffolding will execute this tool on the agent's behalf (usually consisting of running a python function), and return the result of this tool call to the agent.\n",
                "\n",
                "- Prompting: This is how the task state is described to the LLM. We can also use prompting to help assist the LLM in its tool use, or instruct it to use chain-of-thought to give the LLM more \"thinking time.\" \n",
                "\n",
                "The LLM interacts with scaffolding program to complete a task according to the following steps:\n",
                "\n",
                "1. The LLM receives input (task description, current state, available actions etc.) from the scaffolding program\n",
                "2. The LLM processes the input and outputs an action (e.g. \"Use calculator tool\")\n",
                "4. The scaffolding program executes the action the agent took and returns the outcome (e.g. it would run `calculate()` in the background for an LLM using a calculator, and then return the function output to the agent)\n",
                "5. The LLM receive the results and decides the next action\n",
                "6. Repeating the cycle until the task is complete\n",
                "\n",
                "\n",
                "[Insert METR diagram]\n",
                "\n",
                "Some examples of LLM agents are:\n",
                "\n",
                "- [Voyager](https://arxiv.org/abs/2305.16291) (Minecraft LLM Agent)\n",
                "\n",
                "- [AutoGPT](https://autogpt.net/)\n",
                "\n",
                "- [LangChain](https://www.langchain.com/)\n",
                "\n",
                "\n",
                "<!-- An LLM agent consists of 4 main things [I think a better list exists here, \"reasoning engine\" is quite unclear/vague and scaffolding doesn't make sense as a bullet point in how we've defined it; also maybe move this to start of section \"Build agent?\"].\n",
                "\n",
                "- A 'reasoner' or 'reasoning engine.' (Some people also call this a 'world model'). For LLM agents this is a large language model.\n",
                "\n",
                "- Tools which allow the agent to act in the environment.\n",
                "\n",
                "- Memory so that the agent can recall prior actions. This can either be:\n",
                "\n",
                "    - Short-term memory: In the context of LLM agents this is generally the context window\n",
                "\n",
                "    - Long-term memory: There are many cases where context-windows are too short, and we will need to give the agent high-level information about actions it took a long time ago. There are many methods to store this 'long-term memory' for agents (see some methods [here])\n",
                "\n",
                "- Scaffolding: This is essentially any structure which we provide to the 'reasoning engine' in order to help it to reason better, such as:\n",
                "\n",
                "    - Prompting frameworks.\n",
                "\n",
                "    - The ability to trial plans into the future.\n",
                "\n",
                "    - Using subagents to take care of subtasks.\n",
                "\n",
                "    - Subgoal decomposition.\n",
                "\n",
                "EXCALIDRAW!\n",
                "\n",
                "## How should we evaluate LLM agents?\n",
                "\n",
                "Points to make - \"Why evaluate LLM agents\":\n",
                "- overall note: I think this could heavily be based on this [video](https://www.youtube.com/watch?v=KO72xvYAP-w) from METR\n",
                "- The purpose of agent evals is to **unlock and measure the full capabilities of a model**, to avoid underestimating the model and to better estimate the **ceiling** of their capability and potential to cause harm. \n",
                "- Models often fail in easily-fixable ways. For example, when it is solving a hacking task, it\n",
                "    - Can refuse due to ethics or (claimed) inability \n",
                "    - Can give up and ask the user for help \n",
                "    - Can get stuck in loops \n",
                "    - Can hallucinate facts or conclusions [only partly fixable] \n",
                "    - Can be limited by primitive tools \n",
                "    - Can have bugs\n",
                "    - ...\n",
                "- For a model that fails to solve a hacking task, thus deemed safe, there might exist simple fixes (e.g. better prompts, better file manipulation tools) that unlock this dangerous capability. \n",
                "- \n",
                "- Final point about \"quantifying\" the amount of scaffolding to make eval results more quantitative\n",
                "    - Apollo \"Science of Evals\" \n",
                "    - GDM quantify bits\n",
                "==========================\n",
                "--->\n",
                "## How should we evaluate LLM agents?\n",
                "\n",
                "There are two possible purposes of LLM agent evaluations:\n",
                "\n",
                "- The first is to **unlock and measure the full capabilities of a model**. We don't want to underestimate current or future LLMs, so we want to establish the **ceiling** of their capabilties and potential to cause harm.\n",
                "- The second is to **determine the alignment properties of LLMs in agentic scenarios**. Most of our current alignment techniques (Supervised Fine-tuning, RLHF, ... ) are focused on Chatbot contexts for LLMs, however LLM agents have the potential to cause much greater harm, and we currently aren't as confident about how RLHF and Supervised Fine-tuning will work in these contexts.\n",
                "\n",
                "LLM agents generally fail in easy-to-fix ways, as you will see. For example:\n",
                "\n",
                "- They often claim to be incapable of tasks that they can actually perform.\n",
                "\n",
                "- They can easily get stuck in loops.\n",
                "\n",
                "- They can give up and ask the user for help\n",
                "\n",
                "- They can hallucinate facts, or even misunderstand their own prior reasoning and hallucinate a faulty conclusion.\n",
                "\n",
                "- They can be overly or underly sensitive to information in their prompts.\n",
                "\n",
                "- They can just have bugs\n",
                "\n",
                "This means that when models fail to accomplish tasks, there may exist simple fixes that will unlock a capability. Since we want to eliminate the potential of large capability improvements from relatively little effort, this means that we have to try quite hard to tune the promptings, tool descriptions, and tool outputs just right, so that we can see LLM agents at their *best*.\n",
                "<!--->\n",
                "We know today that LLMs are more than just chat-bots. In fact, since the release of ChatGPT, the use of LLMs as  for agentic systems has proliferated signficantly. These agents started off rather disappointingly initially, when they were based on GPT-3.5. However as more powerful LLMs come out and AI companies ensure their LLMs are better at tool-use, these agents are improving rapidly.\n",
                "\n",
                "\n",
                "The main concerns for LLM agents that we want to mitigate are:\n",
                "\n",
                "- Their capabilities may be signficantly greater than those of the base LLM (especially when augmented with tool use).\n",
                "\n",
                "- There are many possible improvements for increased performance from LLM agents, and these improvement methods are often signficantly cheaper and easier to implement than training the base model.\n",
                "\n",
                "- Current fine-tuning and RLHF/Constitutional AI methods are mostly targeted towards chatbot-style text output. We aren't as confident about how such methods will generalize to agentic scenarios.\n",
                "\n",
                "The first two issues here relate to the **capabilities** of LLM agents, and the last issue relates to the **alignment** properties of LLM agents. The agent we'll be building will be testing for the **capability** properties of agents.\n",
                "<!--->\n",
                "\n",
                "<details><summary>Further resources on LLM evaluations:</summary>\n",
                "\n",
                "- [OpenAI Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)\n",
                "\n",
                "- [Anthropic Function Calling Guide](https://docs.anthropic.com/en/docs/build-with-claude/tool-use)\n",
                "\n",
                "- [Evaluating Language-Model Agents on Realistic Autonomous Tasks](https://evals.alignment.org/Evaluating_LMAs_Realistic_Tasks.pdf) (Kinniment et al., ARC Evaluations Team (now METR), 2023)\n",
                "\n",
                "- [Large Language Models can Strategically Deceive their Users when Put Under Pressure](https://arxiv.org/pdf/2311.07590) (Scheurer et al., Apollo Research, ICLR 2024)\n",
                "\n",
                "- [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/) (Lilian Weng, OpenAI Safety Team, 2023)\n",
                "\n",
                "- [AXRP Episode 34 - AI Evaluations with Beth Barnes](https://www.alignmentforum.org/posts/vACr4DExfeRMaCoo7/axrp-episode-34-ai-evaluations-with-beth-barnes) (Daniel Filan, 2024)\n",
                "\n",
                "- [Reflexion: Language Agents with Verbal Reinforcement Learning](https://arxiv.org/pdf/2303.11366) (Shinn et al., 2023)\n",
                "\n",
                "- [Answering Questions by Meta-Reasoning over Multiple Chains of Thought](https://arxiv.org/pdf/2304.13007) (Yoran et al., 2024)\n",
                "\n",
                "- [Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/pdf/2302.04761) (Schick et al., META AI Research, 2023)\n",
                "</details>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2️⃣ Build a Simple LLM Arithemtic Agent"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will start by building a simple LLM agent that solves arithmetic problems. LLMs struggle with arithmetic, but we can drastically improve their performance by providing a simple calculation tool. We'll try the model with and without tools on this task, and see how significantly performance improves.\n",
                "\n",
                "To build this, we will implement 4 things:\n",
                "- The `ArithmeticTask` class handles arithmetic problem generation and solution verification.\n",
                "- The `CalculateTool`, a tool that LLM agents can use to solve the task.\n",
                "- The `ArithmeticAgent` class handles interacting with the LLM API, doing the calculation, and keeping track of the overall task progress.\n",
                "- The `agent_loop()` function defines the interaction loop between the task and the agent to execute the task.\n",
                "\n",
                "In general, ... [description of how to think about designing task and agent in generation, include decision factors] probably good to include a diagram here (or maybe earlier)\n",
                "\n",
                "We build task\n",
                "We build tool\n",
                "\n",
                "We build scaffold\n",
                "We build agent\n",
                "\n",
                "We loop things."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Defining the Task"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Build a simple arithmetic problem\n",
                "```c\n",
                "Difficulty: 🔴🔴🔴⚪⚪\n",
                "Importance: 🔵🔵⚪⚪⚪\n",
                "\n",
                "You should spend up to 20-25 minutes on this exercise.\n",
                "```\n",
                "\n",
                "In an LLM agent eval, there will usually be a `Task` class, which interacts with the `Agent`. In general, the `Task` class will:\n",
                "\n",
                "- Prepare and provide the task instruction (and necessary files, functions etc) to the agent,\n",
                "\n",
                "- Parse and score the agent's output,\n",
                "\n",
                "- Update the task state accordingly (e.g. proceeds onto the next step of the task, ends the task).\n",
                "\n",
                "We will build a toy task called `ArithmeticTask`. This task takes in two numbers and create a list of arithmetic calculation problems with these two numbers, using arithmetic operations defined in `operations`. It should have methods to do the following:\n",
                "\n",
                "- Get the current problem (e.g. at the start this will be `\"Calculate num1 + num2\"`),\n",
                "\n",
                "- Check if a given answer is correct,\n",
                "\n",
                "- Update the current problem (depending on whether the answer generated by the model was correct),\n",
                "\n",
                "- Check if all problems have been solved,\n",
                "\n",
                "<details><summary>Aside: Handling calculations</summary>\n",
                "\n",
                "When we handle the calculations for the model, technically we could use Python's `eval()` function (this is what [Anthropic did](https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/calculator_tool.ipynb)(!)). However, this function evaluates an arbitrary string expression, and so allows AI models to run arbitrary code. In the long-run, we're trying to do these evaluations on models which we suspect of being dangerous; so even though we could probably trust the current suite of language models offered by OpenAI and Anthropic, we should get into the good habit of not running arbitrary code outputted by language models (except in very carefully set-up environments). It's also just plain bad coding practice.\n",
                "\n",
                "To this end, we've implemented an `evaluate_expression()` function for you to use instead which should accomplish. It should already be imported from `utils`.\n",
                " \n",
                " </details>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 224,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "10 + 15 = 25\n",
                        "10 - 15 = -5\n",
                        "10 * 15 = 150\n",
                        "10 / 15 = 0.6666666666666666\n",
                        "10 % 15 = 10\n",
                        "10 // 15 = 0\n"
                    ]
                }
            ],
            "source": [
                "class ArithmeticTask:\n",
                "    def __init__(self, num1: int | float, num2: int | float):\n",
                "        self.num1 = num1\n",
                "        self.num2 = num2\n",
                "        self.operations: List[str] = [\"+\", \"-\", \"*\", \"/\", \"%\", \"//\"]\n",
                "        self.correct_answers: Dict[str, float] = self._generate_answers()\n",
                "        self.is_solved: Dict[str, bool] = {expr: False for expr in self.correct_answers}\n",
                "        self.current_task_number = 0\n",
                "\n",
                "    def _generate_answers(self) -> Dict[str, float]:\n",
                "        \"\"\"\n",
                "        Generates a dictionary the correct answers for all possible tasks\n",
                "\n",
                "        Returns:\n",
                "            Dict[str, float]: A dictionary with the expression as key and the correct answer as value\n",
                "        \"\"\"\n",
                "        return {\n",
                "            f\"{self.num1} {op} {self.num2}\": eval(f\"{self.num1} {op} {self.num2}\")\n",
                "            for op in self.operations\n",
                "        }\n",
                "\n",
                "    @property\n",
                "    def get_current_task(self) -> str:\n",
                "        \"\"\"\n",
                "        Gets the current task for the agent\n",
                "\n",
                "        Returns:\n",
                "            str: A string containing the current task\n",
                "        \"\"\"\n",
                "        return f\"{str(self.num1)} {self.operations[self.current_task_number]} {str(self.num2)}\"\n",
                "\n",
                "    @property\n",
                "    def current_task_instruction(self) -> str:\n",
                "        \"\"\"\n",
                "        Gets a string containing instructions for the current task for the agent. (This will be fed to the agent as a user prompt)\n",
                "\n",
                "        Returns:\n",
                "            str: A string containing the instructions for the current task\n",
                "        \"\"\"\n",
                "        return f\"Calculate the result of the following expression: {self.get_current_task}. Give your final answer in the format: <answer>NUMBER</answer>, where NUMBER is a numerical value\"\n",
                "\n",
                "    def check_solved(self) -> bool:\n",
                "        \"\"\"\n",
                "        Checks if all tasks have been solved\n",
                "\n",
                "        Returns:\n",
                "            bool: True if all tasks have been solved, False otherwise\n",
                "        \"\"\"\n",
                "        return all(self.is_solved.values())\n",
                "\n",
                "    def check_answer(self, model_answer: str) -> bool:\n",
                "        \"\"\"\n",
                "        Checks if the model's answer is correct\n",
                "\n",
                "        Args:\n",
                "            model_answer (str): The model's answer\n",
                "\n",
                "        Returns:\n",
                "            bool: True if the model's answer is correct, False otherwise\n",
                "        \"\"\"\n",
                "\n",
                "        correct_answer = self.correct_answers[self.get_current_task]\n",
                "        return math.isclose(\n",
                "            float(model_answer), correct_answer, rel_tol=1e-5, abs_tol=1e-8\n",
                "        )\n",
                "\n",
                "    def update_current_task(self):\n",
                "        \"\"\"\n",
                "        Sets is_solved for the current task to True and increments self.current_task_number by one\n",
                "        \"\"\"\n",
                "        self.is_solved[self.get_current_task] = True\n",
                "        self.current_task_number = (self.current_task_number + 1) % len(self.operations)\n",
                "\n",
                "\n",
                "x = ArithmeticTask(10, 15)\n",
                "for problem, answer in x.correct_answers.items():\n",
                "    print(f\"{problem} = {answer}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<details><summary>Aside - What is @property?</summary>\n",
                "\n",
                "The `@property` decorator in python is used to define methods that behave like they were attributes.\n",
                "\n",
                "1. It allows you to access a method as though it were an attribute, without parentheses.\n",
                "2. It allows you to perform functions when calling attributes, e.g. adding validation or performing any necessary calculations (in our case incorporating class attributes which frequently change).\n",
                "\n",
                "For example, if we defined a `Square` class as follows:\n",
                "\n",
                "```python\n",
                "class Square:\n",
                "    def __init__(self, side_length):\n",
                "        self.side_length = side_length\n",
                "\n",
                "    @property\n",
                "    def perimeter(self):\n",
                "        return self.side_length*4\n",
                "```\n",
                "\n",
                "Then we could access `perimeter` as if it were an attribute:\n",
                "\n",
                "```python \n",
                "s = Square(4)\n",
                "print(s.perimeter) # Output: 16\n",
                "```\n",
                "\n",
                "Using `@property` in this case helps with:\n",
                "1. Making the intent of the code clearer\n",
                "2. Making it slightly easier to access these \"properties\" of the class\n",
                "\n",
                "</details>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Function Calling\n",
                "\n",
                "**Function calling** is a feature of LLM Chat APIs that allows the LLM to use external \"tools\" (i.e. Python functions, APIs) by simply receiving and outputing text. There are 5 simple steps to function calling:\n",
                "\n",
                "1. Pick a function in your codebase that the model should be able to call (in this case, we will pick the function `calculate()` from our task class)\n",
                "\n",
                "2. Describe your function to the model (following the syntax of the model's API) so it knows how to call it\n",
                "\n",
                "3. Pass your function definitions as available “tools” to the model, along with the messages (following the syntax of the model's API)\n",
                "\n",
                "4. Receive and handle the model response\n",
                "\n",
                "5. Provide the function call result back to the model \n",
                "\n",
                "Chat models like ChatGPT and Claude are fine-tuned to recognize and respond to `tool` descriptions appropriately (just like `user` and `system` messages). In this way, you can allow LLMs to do complex actions like run code, make calls to other APIs, manipulate files etc. We do this by parsing their response output, executing the functions they've called ourselves, and then feeding the results back into the model so it can reason about them and take the next steps. This function-calling loop is the simplest version of a LLM agent, but more advanced LLM agents follow the same logic (except with more advanced tools and more complex task structures to pemirt more autonomous actions etc.).\n",
                "\n",
                "[DIAGRAM]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Write a tool class for function calling\n",
                "```c\n",
                "Difficulty: 🔴🔴⚪⚪⚪\n",
                "Importance: 🔵🔵🔵🔵⚪\n",
                "\n",
                "You should spend up to 10-15 minutes on this exercise.\n",
                "```\n",
                "\n",
                "When writing tools, there will be two methods that need to be defined. The first is the `execute()` function. This should take in an arithmetical expression (e.g. `\"3+5\"`) and output the result of this expression (also as a string). The `execute()` function should always take the task as a variable (as often tools will need to be able to make significant changes to the task).\n",
                "\n",
                "<details><summary>Aside: Handling calculations</summary><br> When we handle the calculations for the model, technically we could use Python's <code>eval()</code> function (this is what <a href = \"https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/calculator_tool.ipynb\">Anthropic did</a>(!)). However, this function evaluates an arbitrary string expression, and so allows AI models to run arbitrary code. In the long-run, we're trying to do these evaluations on models which we suspect of being dangerous; so even though we could probably trust the current suite of language models offered by OpenAI and Anthropic, we should get into the good habit of not running arbitrary code outputted by language models (except in *very* carefully set-up environments). To this end, we've implemented an <code>evaluate_expression</code> function for you to use instead. It should already be imported from <code>utils</code>.</details>\n",
                "\n",
                "We then need to write the `description` property of our `\"calculator\"` function, so we can give it to our LLM agent as a tool. The syntax may differ between APIs (e.g. the OpenAI API has a different syntax than Anthropic API). Read OpenAI's [function calling guide](https://platform.openai.com/docs/guides/function-calling) to learn the syntax. The `description` property should just return a tool description (in the necessary json format). \n",
                "\n",
                "So ultimately your tool should be defined according to the following structure:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 225,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Tool:\n",
                "    @abstractmethod\n",
                "    def execute(task: Any, input: str) -> str: ...\n",
                "\n",
                "    @property\n",
                "    def description(self) -> str: ..."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here are some good practices for writing tool descriptions for Claude (according to Anthropic), they should generalize to other chat models:\n",
                "- Provide extremely detailed descriptions. This is by far the most important factor in tool performance. Your descriptions should explain every aspect of the tool, including:\n",
                "\n",
                "    - What the tool does\n",
                "\n",
                "    - When it should be used (and when it shouldn’t)\n",
                "\n",
                "    - What each parameter means and how it affects the tool’s behavior\n",
                "\n",
                "    - Any important caveats or limitations, such as what information the tool does not return if the tool name is unclear. The more context you can give Claude about your tools, the better it will be at deciding when and how to use them. Aim for at least 3-4 sentences per tool description, more if the tool is complex.\n",
                "    \n",
                "- Prioritize descriptions over examples. While you can include examples of how to use a tool in its description or in the accompanying prompt, this is less important than having a clear and comprehensive explanation of the tool’s purpose and parameters. Only add examples after you’ve fully fleshed out the description.\n",
                "\n",
                "Read Anthropic's examples of what good and bad tool calling looks like [here](https://docs.anthropic.com/en/docs/build-with-claude/tool-use#example-of-a-good-tool-description). \n",
                "\n",
                "Now write your tool class for the `CalculateTool` below. Inherit from the general `Tool` class defined above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 226,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CalculateTool(Tool):\n",
                "    name = \"calculate\"\n",
                "\n",
                "    @staticmethod\n",
                "    def execute(expression: str, task: Any = None) -> str:\n",
                "        \"\"\"\n",
                "        Evaluates the string expression in Python using `evaluate_expression()` and returns the result as a string\n",
                "\n",
                "        Args:\n",
                "            expression (str): The arithmetic expression to evaluate\n",
                "            task (Any): Not used in this function\n",
                "\n",
                "        Returns:\n",
                "            str: The result of the arithmetical expression as a string\n",
                "        \"\"\"\n",
                "        try:\n",
                "            return str(evaluate_expression(expression))\n",
                "        except (SyntaxError, NameError, ZeroDivisionError) as e:\n",
                "            return f\"Error: {str(e)}\"\n",
                "\n",
                "    @property\n",
                "    def description(self):\n",
                "        \"\"\"\n",
                "        Provides the description of the tool\n",
                "\n",
                "        Returns:\n",
                "            str: The description of the tool\n",
                "        \"\"\"\n",
                "\n",
                "        return {\n",
                "            \"type\": \"function\",\n",
                "            \"function\": {\n",
                "                \"name\": self.name,\n",
                "                \"description\": 'Calculates the result of an arithmetic expression. For example, you could provide an input in the form \"2+3\" and the function would return 5. Or you could provide an expression like \"10/3\" and the function would return 3.3333333333333335.',\n",
                "                \"parameters\": {\n",
                "                    \"type\": \"object\",\n",
                "                    \"properties\": {\n",
                "                        \"expression\": {\n",
                "                            \"type\": \"string\",\n",
                "                            \"description\": \"The arithmetic expression that you want to be evaluated.\",\n",
                "                        }\n",
                "                    },\n",
                "                    \"required\": [\"expression\"],\n",
                "                    \"additionalProperties\": False,\n",
                "                },\n",
                "            },\n",
                "        }\n",
                "\n",
                "\n",
                "Calculator = CalculateTool()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<details><summary> Aside - What is a @staticmethod?</summary>\n",
                "\n",
                "The `@staticmethod` decorator in Python is used to define a static method within a class. Here are some key points about static methods:\n",
                "1. They don't use instance- or class-specific data, thus does not require a first parameter `self` or `cls`.\n",
                "2. They're often used for utility functions related to the class.\n",
                "\n",
                "For example, if we defined a class of `MathOperations` as follows:\n",
                "\n",
                "```python\n",
                "class MathOperations:\n",
                "    @staticmethod\n",
                "    def add(x : int | float, y : int | float) -> int | float:\n",
                "        \"\"\"Evaluates the string expression and returns the result as a string.\"\"\"\n",
                "        return x + y\n",
                "```\n",
                "\n",
                "The `add()` method could be called on the class itself without creating an instance:\n",
                "\n",
                "   ```python\n",
                "   result = MathOperations.add(2, 3)\n",
                "   ```\n",
                "\n",
                "You can also call it on an instance of the class, but it doesn't utilize the instance in any way (it doesn't have access to `self`):\n",
                "   ```python\n",
                "   operation = MathOperations()\n",
                "   result = operation.add(2, 3)\n",
                "   ```\n",
                "\n",
                "Typically, you would make \"stand-alone\" functions that do not depend on class methods or class/instance attributes a static method. Using `@staticmethod` in this case helps with the following:\n",
                "1. Makes the code's intent clearer (this method doesn't need class or instance data).\n",
                "2. Slightly improves performance (no `self` argument needs to be passed).\n",
                "3. Allows the method to be used without creating an instance of the class.\n",
                "\n",
                "</details>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You can include the tool description in the API call simply by giving it as an arg to `tools` (the description has to be in a list, as the `create()` function's `tools` argument only accepts lists of tool descriptions): "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 227,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "None\n",
                        "[ChatCompletionMessageToolCall(id='call_xRDnuNWN4B6fG24mkPmW1HV6', function=Function(arguments='{\"expression\":\"2+3\"}', name='calculate'), type='function')]\n"
                    ]
                }
            ],
            "source": [
                "messages = [{\"role\": \"user\", \"content\": \"Calculate 2+3\"}]\n",
                "client = establish_client_OpenAI()\n",
                "\n",
                "response = client.chat.completions.create(\n",
                "    model=\"gpt-4o-mini\",\n",
                "    messages=messages,\n",
                "    tools=[Calculator.description],\n",
                "    tool_choice=\"auto\",\n",
                ")\n",
                "\n",
                "print(response.choices[0].message.content)\n",
                "print(response.choices[0].message.tool_calls)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<details><summary>Why is <code>message.content = None</code>?</summary>\n",
                "\n",
                "When LLMs use tools, they often don't generate any text output. This can be a problem later when you try to get the model to do chain-of-thought reasoning. To get around this, it can be better to make two calls to the model for more complex tool use: one call to get the model to reason about the actions it should take, and then another to get the model to use a tool to take those actions.\n",
                "\n",
                "</details> "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Return tool call results to the model\n",
                "```c\n",
                "Difficulty: 🔴🔴⚪⚪⚪\n",
                "Importance: 🔵🔵🔵🔵⚪\n",
                "\n",
                "You should spend up to 15-20 minutes on this exercise.\n",
                "```\n",
                "\n",
                "In order to return the response of tools to OpenAI LLMs, you'll need to add **two** items to the `messages` list after the model has made a tool call in a `ChatCompletionMessage` output:\n",
                "1. The `ChatCompletionMessage` object itself (containing the original tool call message generated by the model). \n",
                "\n",
                "2. The tool response (containing the results of the tool call), in a specific format.\n",
                "\n",
                "Each tool response has to respond to a specific tool call in a `ChatCompletionMessage`, and if we ever try to get the model to generate a response with an unanswered tool call in `messages`, the API will raise an error.\n",
                "\n",
                "Below is the typical `response.choices[0]` output you will being generated by `chat.completions.create()`. The ChatCompletionMessage is accessed via `response.choices[0].message`. You can access the tool calls via `response.choices[0].tool_calls`, which will return a list of `ChatCompletionMessageToolCall` objects.\n",
                "\n",
                "```python\n",
                "Choice(\n",
                "    finish_reason=\"tool_calls\",\n",
                "    index=0,\n",
                "    logprobs=None,\n",
                "    message=chat.completionsMessage(\n",
                "        content=None,\n",
                "        role=\"assistant\",\n",
                "        function_call=None,\n",
                "        tool_calls=[\n",
                "            chat.completionsMessageToolCall(\n",
                "                id=\"call_62136354\",\n",
                "                function=Function(arguments='{\"expression\":\"2+3\"}', name=\"calculate\"),\n",
                "                type=\"function\",\n",
                "            )\n",
                "        ],\n",
                "    ),\n",
                ")\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We have provided a function that formats the tool response in the correct syntax to be returned to the model. Read the format to understand what it looks like (you don't need to memorize it though, as you can always find it on OpenAI's [function calling guide](https://platform.openai.com/docs/guides/function-calling).)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 228,
            "metadata": {},
            "outputs": [],
            "source": [
                "def apply_tool_call_format(\n",
                "    tool_call: ChatCompletionMessageToolCall, content: str\n",
                ") -> dict:\n",
                "    \"\"\"\n",
                "    Formats the response of a tool call to be returned to the model.\n",
                "    Args:\n",
                "        - tool_call (ChatCompletionMessageToolCall) : The tool call object\n",
                "        - content (str) : This is the tool response (i.e. results from executing the tool)\n",
                "\n",
                "    Returns:\n",
                "        - dict : The formatted tool response to be returned to the model\n",
                "    \"\"\"\n",
                "    return {\n",
                "        \"role\": \"tool\",\n",
                "        \"tool_call_id\": tool_call.id,\n",
                "        \"name\": tool_call.function.name,\n",
                "        \"content\": content,  # e.g. \"5\"\n",
                "    }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we can generate a message and return the tool call response to the model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 229,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The result of \\( \\frac{5}{3} \\) is approximately 1.6666666666666667.\n"
                    ]
                }
            ],
            "source": [
                "messages = [{\"role\": \"user\", \"content\": \"Calculate 5/3. Be precise.\"}]\n",
                "response = client.chat.completions.create(\n",
                "    model=\"gpt-4o-mini\",\n",
                "    messages=messages,\n",
                "    tools=[Calculator.description],\n",
                "    tool_choice=\"auto\",\n",
                ")\n",
                "\n",
                "messages.extend(\n",
                "    [\n",
                "        response.choices[0].message,\n",
                "        apply_tool_call_format(\n",
                "            response.choices[0].message.tool_calls[0],\n",
                "            Calculator.execute(\n",
                "                json.loads(\n",
                "                    response.choices[0].message.tool_calls[0].function.arguments\n",
                "                )[\"expression\"]\n",
                "            ),\n",
                "        ),\n",
                "    ]\n",
                ")\n",
                "\n",
                "response_to_tool_calls = client.chat.completions.create(\n",
                "    model=\"gpt-4o-mini\",\n",
                "    messages=messages,\n",
                "    tools=[Calculator.description],\n",
                "    tool_choice=\"auto\",\n",
                ")\n",
                "print(response_to_tool_calls.choices[0].message.content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Building the Agent"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "REwork this\n",
                "\n",
                "Most LLM agents share these core components:\n",
                "\n",
                "1. **LLM API interface**: A basic function (e.g. `get_response()`) that makes the API calls to the LLM and return its responses. (IN AGENT)\n",
                "\n",
                "2. **Actions**: A set of actions (i.e. functions) the agent can take. (MOSTLY IN TASK)\n",
                "\n",
                "3. **Task State Management**: Keeping track of the current state of the task and any relevant context. (IN TASK MOSTLY)\n",
                "\n",
                "4. **Memory**: A system for storing and retrieving relevant information from past interactions (i.e. chat history). The simplest implemention is usually a `self.chat_history` class attribute that stores a list of past chat messages. (IN AGENT)\n",
                "\n",
                "5. **Observation Parser**: Functions to parse and interpret the results of actions and update the state. (IN TASK MOSTLY)\n",
                "\n",
                "6. **Decision/Execution Logic**: The rules or algorithms used to choose actions based on the current state and LLM output. (KIND OF IN BETWEEN)\n",
                "\n",
                "7. **Task-Specific Information**: Any additional information or functions specific to the task at hand. (IN TASK)\n",
                "\n",
                "[Diagram]\n",
                "\n",
                "We will first implement a `SimpleAgent` class that is not specific to the `ArithmeticTask`, so that we can see the key components of an generic LLM agent."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Implement `SimpleAgent`\n",
                "```c\n",
                "Difficulty: 🔴🔴🔴🔴⚪\n",
                "Importance: 🔵🔵🔵🔵🔵\n",
                "\n",
                "You should spend up to 20-25 minutes on this exercise.\n",
                "```\n",
                "\n",
                "Build out the following simple agent class by filling in `get_response()` and `execute_tool_calls()` functions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 230,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleAgent:\n",
                "    def __init__(\n",
                "        self,\n",
                "        task: Any = None,\n",
                "        model: Literal[\"gpt-4o-mini\"] = \"gpt-4o-mini\",\n",
                "        tools: Optional[List[Any]] = None,\n",
                "        chat_history: Optional[List[dict]] = None,\n",
                "    ):\n",
                "        self.model = model\n",
                "        self.task = task\n",
                "        self.tools = tools\n",
                "        self.client = OpenAI()\n",
                "        self.chat_history = chat_history if chat_history else []\n",
                "\n",
                "    @retry_with_exponential_backoff\n",
                "    def get_response(self, use_tool: bool = True) -> ChatCompletionMessage:\n",
                "        \"\"\"\n",
                "        Get the response from the model via an API call, with the option of tool calling.\n",
                "\n",
                "        Args:\n",
                "            use_tool (bool): Whether to use tool calling or not\n",
                "\n",
                "        Returns:\n",
                "            ChatCompletionMessage: The response from the model\n",
                "        \"\"\"\n",
                "        response = self.client.chat.completions.create(\n",
                "            model=self.model,\n",
                "            messages=self.chat_history,\n",
                "            tools=[tool.description for tool in self.tools] if use_tool else None,\n",
                "            tool_choice=\"auto\" if use_tool else None,\n",
                "        )\n",
                "        return response.choices[0].message\n",
                "\n",
                "    def execute_tool_calls(self, message: ChatCompletionMessage) -> List[str]:\n",
                "        \"\"\"\n",
                "        Execute the tool calls in the message and return a list of tool_responses.\n",
                "\n",
                "        Args:\n",
                "            message (ChatCompletionMessage): The message containing the tool calls\n",
                "\n",
                "        Returns:\n",
                "            List[str]: A list of tool responses (as strings)\n",
                "        \"\"\"\n",
                "        tool_calls = message.tool_calls\n",
                "\n",
                "        tool_responses = []\n",
                "        for tool_call in tool_calls:\n",
                "            if not self.task:\n",
                "                raise ValueError(\"Task is not set. Cannot execute tool calls.\")\n",
                "            func = next(\n",
                "                (tool for tool in self.tools if tool.name == tool_call.function.name),\n",
                "            )\n",
                "            arguments = json.loads(tool_call.function.arguments)\n",
                "            tool_response = func.execute(**arguments, task=self.task)\n",
                "            tool_responses.append(tool_response)\n",
                "\n",
                "        return tool_responses\n",
                "\n",
                "    def run(self, with_tool: bool = True) -> ChatCompletionMessage:\n",
                "        \"\"\"\n",
                "        Default implementation of run method.\n",
                "        This can be overridden in subclasses for specific behavior.\n",
                "\n",
                "        Args:\n",
                "            with_tool (bool): Whether to use tool calling or not\n",
                "\n",
                "        Returns:\n",
                "            str: The response from the model\n",
                "        \"\"\"\n",
                "        print(f\"Running SimpleAgent...\")\n",
                "        instruction = self.task.current_task_instruction\n",
                "        self.chat_history.append(apply_user_format(instruction))\n",
                "        response = self.get_response(use_tool=with_tool)\n",
                "        return response"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 231,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Running SimpleAgent...\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_V9QlcHhryiNLWFdm4OYLniPB', function=Function(arguments='{\"expression\":\"10 + 15\"}', name='calculate'), type='function')], refusal=None)"
                        ]
                    },
                    "execution_count": 231,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "my_simple_agent = SimpleAgent(ArithmeticTask(10, 15), tools=[Calculator])\n",
                "my_simple_agent.run()\n",
                "\n",
                "# Try execute the tool calls\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Build an `ArithmeticAgent`\n",
                "```c\n",
                "Difficulty: 🔴🔴🔴🔴⚪\n",
                "Importance: 🔵🔵🔵🔵🔵\n",
                "\n",
                "You should spend up to 20-25 minutes on this exercise.\n",
                "```\n",
                "\n",
                "Add instructions here:\n",
                "1. work out the decision tree of the task for ~10min; we give a half-filled task tree, then the full task tree in a drop down\n",
                "2. write `run()` - they will implement everything after \"# Handle the response\" in run(); we will give them parse_answer."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 232,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ArithmeticAgent(SimpleAgent):\n",
                "    \"\"\"\n",
                "    ArithmeticAgent class for doing simple arithmetic tasks.\n",
                "\n",
                "    Inherits from SimpleAgent which includes the following attributes and methods:\n",
                "\n",
                "    Attributes:\n",
                "        model (str): The model used for generating responses (inherited)\n",
                "        tool_descriptions (List[dict]): List of tool descriptions (inherited)\n",
                "        client (OpenAI): OpenAI client for API calls (inherited)\n",
                "        task (Any): The current task being executed (inherited)\n",
                "        chat_history (List[dict]): History of interactions (inherited)\n",
                "\n",
                "    Methods:\n",
                "        get_response(use_tool: bool = True) -> ChatCompletionMessage:\n",
                "            Get response from the model (inherited)\n",
                "\n",
                "        execute_tool_calls(message: ChatCompletionMessage) -> List[str]:\n",
                "            Execute tool calls from the model's response (inherited)\n",
                "\n",
                "        run(with_tool: bool = True) -> bool:\n",
                "            Run one loop of the Wikipedia agent\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        model: Literal[\"gpt-4o-mini\"] = \"gpt-4o-mini\",\n",
                "        task: Any = None,\n",
                "        tools: Optional[List[Any]] = [Calculator],\n",
                "        chat_history: List[dict] = None,\n",
                "        verbose: bool = True,\n",
                "    ):\n",
                "        super().__init__(model=model, task=task, tools=tools, chat_history=chat_history)\n",
                "        self.verbose = verbose\n",
                "\n",
                "    def handle_tool_calls(self, response: ChatCompletionMessage):\n",
                "        \"\"\"\n",
                "        Handle the tool calls from the model response. This function should:\n",
                "        - Execute the tool calls\n",
                "        - Append the tool calls and responses to the chat history\n",
                "\n",
                "        Args:\n",
                "            response (ChatCompletionMessage): The response from the model\n",
                "        \"\"\"\n",
                "        if self.verbose:\n",
                "            print(\"\\nTool calls:\", response.tool_calls)\n",
                "\n",
                "        # Append response to chat history\n",
                "        self.chat_history.append(response)\n",
                "\n",
                "        # Execute the tool calls and append tool responses to chat history\n",
                "        tool_calls = response.tool_calls\n",
                "        try:\n",
                "            tool_responses = self.execute_tool_calls(response)\n",
                "            for tool_call, tool_response in zip(tool_calls, tool_responses):\n",
                "                self.chat_history.append(\n",
                "                    apply_tool_call_format(tool_call, tool_response)\n",
                "                )\n",
                "        except Exception as e:\n",
                "            print(f\"\\nError handling tool calls: {e}\")\n",
                "\n",
                "    def handle_refusal(self, response: ChatCompletionMessage):\n",
                "        \"\"\"\n",
                "        Handle the refusal from the model response. This function should only be called if the model refuses to answer and should:\n",
                "        - Append the refusal to the chat history\n",
                "        - Update the task state\n",
                "\n",
                "        Args:\n",
                "            response (ChatCompletionMessage): The response from the model\n",
                "        \"\"\"\n",
                "        if self.verbose:\n",
                "            print(\"\\nModel Refusal:\", response.refusal)\n",
                "        self.chat_history.append(apply_assistant_format(response.refusal))\n",
                "        self.task.update_current_task()\n",
                "\n",
                "    def generate_and_check_final_answer(self) -> Literal[\"Correct\", \"Incorrect\"]:\n",
                "        \"\"\"\n",
                "        This function should:\n",
                "        - Get the model to generate a final answer to the question (after it has seen the tool response)\n",
                "        - Then check this final answer against the correct answer.\n",
                "        - If the answer is correct, update the task state.\n",
                "        - Then append to chat history (and return) \"Correct\" if the answer is correct and \"Incorrect\" if the answer is incorrect.\n",
                "\n",
                "        Args:\n",
                "            None\n",
                "\n",
                "        Returns:\n",
                "            str: \"Correct\" or \"Incorrect\"\n",
                "        \"\"\"\n",
                "\n",
                "        # Get the final response from the model after tool responses\n",
                "\n",
                "        response = self.get_response(use_tool=False)\n",
                "        self.chat_history.append(apply_assistant_format(response.content))\n",
                "\n",
                "        if self.verbose:\n",
                "            print(\"\\nModel response:\", response.content)\n",
                "\n",
                "        # Check the answer\n",
                "        try:\n",
                "            model_answer = self.parse_answer(response)\n",
                "\n",
                "            if self.task.check_answer(model_answer):\n",
                "                self.chat_history.append(apply_user_format(\"Correct.\"))\n",
                "\n",
                "                if self.verbose:\n",
                "                    print(\"\\nUser: Correct.\")\n",
                "\n",
                "                # Update to the next task\n",
                "                self.task.update_current_task()\n",
                "\n",
                "                return \"Correct\"\n",
                "\n",
                "            else:\n",
                "                self.chat_history.append(apply_user_format(\"Incorrect.\"))\n",
                "                if self.verbose:\n",
                "                    print(\"\\nUser: Incorrect.\")\n",
                "                return \"Incorrect\"\n",
                "                # Retry the task\n",
                "\n",
                "        # Ends the task if there's an error parsing the model answer\n",
                "        except Exception as e:\n",
                "            if self.verbose:\n",
                "                print(f\"\\nError parsing model answer: {e}\")\n",
                "            raise\n",
                "\n",
                "    def run(self, with_tool: bool):\n",
                "        \"\"\"\n",
                "        Run one loop of the agent, which involves:\n",
                "        - getting a task\n",
                "        - getting a response from the model\n",
                "        - handling the model response, including tool calls, refusals, no tool calls, parsing and checking final answers, errors.\n",
                "        - managing memory: storing the history of messages to self.chat_history\n",
                "        - managing task state: staying on the same task or moving to the next task at the end of the loop\n",
                "        \"\"\"\n",
                "        # Get the task instruction\n",
                "        instruction = self.task.current_task_instruction\n",
                "        if self.verbose:\n",
                "            print(\"\\nUSER:\", instruction)\n",
                "        self.chat_history.append(apply_user_format(instruction))\n",
                "\n",
                "        # Get the response from the model\n",
                "        response = self.get_response(use_tool=with_tool)\n",
                "\n",
                "        if self.verbose:\n",
                "            print(\"\\nModel response:\", response.content)\n",
                "\n",
                "        # Handle the response\n",
                "        ## If model makes tool calls, handle the tool calls\n",
                "        if response.tool_calls:\n",
                "            self.handle_tool_calls(response)\n",
                "\n",
                "            # Then get the final answer from the model\n",
                "            self.generate_and_check_final_answer()\n",
                "\n",
                "        ## If no tool call: Handle edge cases\n",
                "\n",
                "        ### Check if there's a refusal to answer:\n",
                "        elif response.refusal:\n",
                "            self.handle_refusal(response)\n",
                "\n",
                "        else:\n",
                "            self.generate_and_check_final_answer()\n",
                "\n",
                "    def parse_answer(self, message: ChatCompletionMessage) -> float:\n",
                "        \"\"\"\n",
                "        Extract the numerical answer from the string output of the model\n",
                "\n",
                "        Args:\n",
                "            message (ChatCompletionMessage): The response from the model\n",
                "\n",
                "        Returns:\n",
                "            float: The numerical answer extracted from the model\n",
                "        \"\"\"\n",
                "        response = message.content\n",
                "        if response.find(\"<answer>\") != -1:\n",
                "            startpoint = response.find(\"<answer>\") + 8\n",
                "            endpoint = response.find(\"</answer>\")\n",
                "            return float(response[startpoint:endpoint])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Execute the task via an agent_loop \n",
                "```c\n",
                "Difficulty: 🔴⚪⚪⚪⚪\n",
                "Importance: 🔵🔵🔵🔵⚪\n",
                "\n",
                "You should spend up to 5-10 minutes on this exercise.\n",
                "```\n",
                "\n",
                "Try implementing the agent_loop below with and without tools, to see how much better the model does when we give it tools.\n",
                "\n",
                "> WARNING! \n",
                ">\n",
                ">When you're making API calls to LLMs to tasks, it can be tempting to use a while loop, and run the model until it finishes the task. But since every time we run a model we make an API call, this would allow us to spend arbitrarily large amounts of money on API calls. For this reason, ***always use a for loop when making API calls!!!*** It would be really unfortunate if you blew all your API budget on one mistake!\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 233,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "USER: Calculate the result of the following expression: 31.1 + 8. Give your final answer in the format: <answer>NUMBER</answer>, where NUMBER is a numerical value\n",
                        "\n",
                        "Model response: <answer>39.1</answer>\n",
                        "\n",
                        "Model response: <answer>39.1</answer>\n",
                        "\n",
                        "User: Correct.\n",
                        "\n",
                        "USER: Calculate the result of the following expression: 31.1 - 8. Give your final answer in the format: <answer>NUMBER</answer>, where NUMBER is a numerical value\n",
                        "\n",
                        "Model response: <answer>23.1</answer>\n",
                        "\n",
                        "Model response: <answer>23.1</answer>\n",
                        "\n",
                        "User: Correct.\n",
                        "\n",
                        "USER: Calculate the result of the following expression: 31.1 * 8. Give your final answer in the format: <answer>NUMBER</answer>, where NUMBER is a numerical value\n",
                        "\n",
                        "Model response: <answer>248.8</answer>\n",
                        "\n",
                        "Model response: <answer>248.8</answer>\n",
                        "\n",
                        "User: Correct.\n",
                        "\n",
                        "USER: Calculate the result of the following expression: 31.1 / 8. Give your final answer in the format: <answer>NUMBER</answer>, where NUMBER is a numerical value\n",
                        "\n",
                        "Model response: <answer>3.8875</answer>\n",
                        "\n",
                        "Model response: <answer>3.8875</answer>\n",
                        "\n",
                        "User: Correct.\n",
                        "\n",
                        "USER: Calculate the result of the following expression: 31.1 % 8. Give your final answer in the format: <answer>NUMBER</answer>, where NUMBER is a numerical value\n",
                        "\n",
                        "Model response: <answer>7.1</answer>\n",
                        "\n",
                        "Model response: <answer>7.1</answer>\n",
                        "\n",
                        "User: Correct.\n",
                        "\n",
                        "USER: Calculate the result of the following expression: 31.1 // 8. Give your final answer in the format: <answer>NUMBER</answer>, where NUMBER is a numerical value\n",
                        "\n",
                        "Model response: <answer>3.0</answer>\n",
                        "\n",
                        "Model response: <answer>3.0</answer>\n",
                        "\n",
                        "User: Correct.\n",
                        "\n",
                        "All tasks solved.\n"
                    ]
                }
            ],
            "source": [
                "Arithmetic_Task_1 = ArithmeticTask(31.1, 8)\n",
                "Arithmetic_Agent_1 = ArithmeticAgent(\n",
                "    task=Arithmetic_Task_1, verbose=True, tools=[Calculator]\n",
                ")\n",
                "\n",
                "\n",
                "def agent_loop(agent, task, num_loops: int = 10):\n",
                "    \"\"\"\n",
                "    Run the agent loop for a given number of loops\n",
                "\n",
                "    Args:\n",
                "        agent (ArithmeticAgent): The agent to run\n",
                "        task (ArithmeticTask): The task to solve\n",
                "        num_loops (int): The number of loops to run\n",
                "    \"\"\"\n",
                "    for i in range(num_loops):\n",
                "        if not task.check_solved():\n",
                "            agent.run(with_tool=False)\n",
                "        else:\n",
                "            print(\"\\nAll tasks solved.\")\n",
                "            break\n",
                "\n",
                "\n",
                "agent_loop(Arithmetic_Agent_1, Arithmetic_Task_1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can print all the messages from the `ChatHistory` as follows:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 234,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " user:\n",
                        " Calculate the result of the following expression: 31.1 + 8. Give your final answer in the format: <answer>NUMBER</answer>, where NUMBER is a numerical value\n",
                        "\n",
                        " assistant:\n",
                        " <answer>39.1</answer>\n",
                        "\n",
                        " user:\n",
                        " Correct.\n",
                        "\n",
                        " user:\n",
                        " Calculate the result of the following expression: 31.1 - 8. Give your final answer in the format: <answer>NUMBER</answer>, where NUMBER is a numerical value\n",
                        "\n",
                        " assistant:\n",
                        " <answer>23.1</answer>\n",
                        "\n",
                        " user:\n",
                        " Correct.\n",
                        "\n",
                        " user:\n",
                        " Calculate the result of the following expression: 31.1 * 8. Give your final answer in the format: <answer>NUMBER</answer>, where NUMBER is a numerical value\n",
                        "\n",
                        " assistant:\n",
                        " <answer>248.8</answer>\n",
                        "\n",
                        " user:\n",
                        " Correct.\n",
                        "\n",
                        " user:\n",
                        " Calculate the result of the following expression: 31.1 / 8. Give your final answer in the format: <answer>NUMBER</answer>, where NUMBER is a numerical value\n",
                        "\n",
                        " assistant:\n",
                        " <answer>3.8875</answer>\n",
                        "\n",
                        " user:\n",
                        " Correct.\n",
                        "\n",
                        " user:\n",
                        " Calculate the result of the following expression: 31.1 % 8. Give your final answer in the format: <answer>NUMBER</answer>, where NUMBER is a numerical value\n",
                        "\n",
                        " assistant:\n",
                        " <answer>7.1</answer>\n",
                        "\n",
                        " user:\n",
                        " Correct.\n",
                        "\n",
                        " user:\n",
                        " Calculate the result of the following expression: 31.1 // 8. Give your final answer in the format: <answer>NUMBER</answer>, where NUMBER is a numerical value\n",
                        "\n",
                        " assistant:\n",
                        " <answer>3.0</answer>\n",
                        "\n",
                        " user:\n",
                        " Correct.\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "for message in Arithmetic_Agent_1.chat_history:\n",
                "    try:\n",
                "        print(f\"\"\"{str(message.role)}:\\n {str(message.content)}\\n\"\"\")\n",
                "    except:\n",
                "        print(f\"\"\" {message[\"role\"]}:\\n {message[\"content\"]}\\n\"\"\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3️⃣ Building a More Complex Task: WikiGame\n",
                "\n",
                "Now that we know how to do function calling and how to design an LLM agent in general, we will build a more complicated task. This task won't be instantly solvable by LLMs with simple tool use and will require us to elicit better capabilities from models.\n",
                "\n",
                "The task we will build and elicit behavior for will be the [Wikipedia Game](https://en.wikipedia.org/wiki/Wikipedia:Wiki_Game): Players use wiki-links to travel from one Wikipedia page to another and the first person who reaches the destination page wins the race. This is not directly related to any dangerous capabilities, and if GPT-N+1 could do this task, but GPT-N couldn't, we wouldn't tell OpenAI to be particularly careful about the release of GPT-N+1 as a result. However, it makes a useful test case for elicitation methods, since there are many strategies for deciding what path to take and we can create a scale of difficulty by choosing different articles to navigate to/from.\n",
                "\n",
                "To add:\n",
                "- Description of MVP Goal\n",
                "- EXCALIDRAW! (describing wikipedia game.)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Quick Intro to the Wikipedia API"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Our agent will interact with Wikipedia by making tool calls to the [Wikipedia API](https://wikipedia.readthedocs.io/en/latest/quickstart.html), which is simple to use. We will only need to learn the following key functions for the game. \n",
                "\n",
                "1. `wikipedia.page` - Returns a Wikipedia page object, whcih contains various attributes adn methods to access page content. (See [page docs](https://wikipedia-api.readthedocs.io/en/latest/API.html#wikipediapage) for these attributes.)\n",
                "2. `wikipedia.page.title` - Returns the title of the page\n",
                "3. `wikipedia.page.contents` - Returns the full text content of the page (this can be very long, make sure to take snippets when you can as to not use up the context length of the LLM)\n",
                "4. `wikipedia.page.summary` - Returns a summary of the page (i.e. all the text in the first section of the Wikipage).\n",
                "5. `wikipedia.page.links` - Returns a list of all links as strings\n",
                "\n",
                "Kwargs:\n",
                "- `auto_suggest` - Let Wikipedia find a valid page title for the query. \n",
                "- `redirect` - Allow redirection without raising RedirectError\n",
                "\n",
                "Refer to the [docs](https://wikipedia-api.readthedocs.io/en/latest/API.html#) for more information. \n",
                "\n",
                "<details><summary> Aside: Wikipedia API content can be weird!</summary>\n",
                "\n",
                "The wikipedia API often outputs content in unintuitive ways. For example, articles that are essentially just a big list become near useless, since the content omits the list (for example, see the wikipedia API content for <a href = \"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population\">List of countries and dependencies by population</a>). Another issue that you might encounter is that the API formats mathematical expressions in $\\LaTeX$ pretty poorly (for example, see the wikipedia API content for <a href = \"https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\">Kullback-Leibler divergence</a>). This is why it's important to determine what content the wikipedia API produces when `.content` is called — and why you want to make sure you're testing a large diversity of wikipedia articles.\n",
                "\n",
                "</details>\n",
                "<br>\n",
                "<details><summary> Aside: Wikipedia \"summaries\" can be long!</summary>\n",
                "\n",
                "The wikipedia API accesses summaries of pages by presenting all the information before the first titled section. For certain (generally obscure) wikipedia pages, this summary itself can be extremely long, and contain lots of information that is unnecessary to determine the key information about the page the model should be trying to access. We'll handle this later when it comes up by truncating wikipedia's summary to just the first ~1000 characters\n",
                "\n",
                "</details>\n",
                "\n",
                "Now run the following code to see how these wikipedia API functions work!\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 236,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Title: Large language model\n",
                        "\n",
                        "URL https://en.wikipedia.org/wiki/Large_language_model\n",
                        "\n",
                        "Summary (word count 172): A large language model (LLM) is a computational model capable of language generation or other natural language processing tasks. As language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised training process.\n",
                        "The largest and most capable LLMs, as of August 2024, are artificial neural networks built with a decoder-only transformer-based architecture, which enables efficient processing and generation of large-scale text data. Modern models can be fine-tuned for specific tasks or can be guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained on.\n",
                        "Some notable LLMs are OpenAI's GPT series of models (e.g., GPT-3.5, GPT-4 and GPT-4o; used in ChatGPT and Microsoft Copilot), Google's Gemini (the latter of which is currently used in the chatbot of the same name), Meta's LLaMA family of models, IBM's Granite models initially released with Watsonx, Anthropic's Claude models, and Mistral AI's models.\n",
                        "\n",
                        "\n",
                        "\n",
                        "Content (word count 6327): A large language model (LLM) is a computational model capable of language generation or other natural language processing tasks. As language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised training process.\n",
                        "The largest and most capable LLMs, as of August 2024, are artificial neural networks built with a decoder-only transformer-based architecture, which enables efficient processing and generation of large-scale text data. Modern models can be fine-tuned for specific tasks or can be guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained on.\n",
                        "Some notable LLMs are OpenAI's GPT series of models (e.g., GPT-3.5, GPT-4 and GPT-4o; used in ChatGPT and Microsoft Copilot), Google's Gemini (the latter of which is currently used ......\n",
                        "\n",
                        "Links (link count 428): [AI-complete, AI21 Labs, API, Active learning (machine learning), Aidan Gomez, AlexNet, Algorithmic bias, ......]\n"
                    ]
                }
            ],
            "source": [
                "# Retrieve a Wikipedia page from its title\n",
                "page = wikipedia.page(\"Large language model\")\n",
                "\n",
                "# Access basic page information\n",
                "print(\"Title:\", page.title)\n",
                "print(\"\\nURL\", page.url)\n",
                "print(f\"\\nSummary (word count {len( page.summary.split())}):\", page.summary)\n",
                "print(\n",
                "    f\"\\nContent (word count {len( page.content.split())}):\",\n",
                "    page.content[:1000],\n",
                "    \"......\",\n",
                ")\n",
                "print(\n",
                "    f\"\"\"\\nLinks (link count {len(page.links)}): [{\", \".join(page.links[:7])}, ......]\"\"\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now run these two lines (you should see a `DisambiguationError` for the first, and a `PageError` for the second):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 237,
            "metadata": {},
            "outputs": [
                {
                    "ename": "DisambiguationError",
                    "evalue": "\"Python\" may refer to: \nPythonidae\nPython (genus)\nPython (mythology)\nPython (programming language)\nCMU Common Lisp\nPERQ 3\nPython of Aenus\nPython (painter)\nPython of Byzantium\nPython of Catana\nPython Anghelo\nPython (Efteling)\nPython (Busch Gardens Tampa Bay)\nPython (Coney Island, Cincinnati, Ohio)\nPython (automobile maker)\nPython (Ford prototype)\nPython (missile)\nPython (nuclear primary)\nColt Python\nPython (codename)\nPython (film)\nMonty Python\nPython (Monty) Pictures\nTimon of Phlius\nPyton\nPithon",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mDisambiguationError\u001b[0m                       Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[237], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m page \u001b[38;5;241m=\u001b[39m \u001b[43mwikipedia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPython\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\wikipedia\\wikipedia.py:276\u001b[0m, in \u001b[0;36mpage\u001b[1;34m(title, pageid, auto_suggest, redirect, preload)\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m       \u001b[38;5;66;03m# if there is no suggestion or search results, the page doesn't exist\u001b[39;00m\n\u001b[0;32m    275\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m PageError(title)\n\u001b[1;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWikipediaPage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pageid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    278\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m WikipediaPage(pageid\u001b[38;5;241m=\u001b[39mpageid, preload\u001b[38;5;241m=\u001b[39mpreload)\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\wikipedia\\wikipedia.py:299\u001b[0m, in \u001b[0;36mWikipediaPage.__init__\u001b[1;34m(self, title, pageid, redirect, preload, original_title)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEither a title or a pageid must be specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 299\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preload:\n\u001b[0;32m    302\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m prop \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreferences\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinks\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msections\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\wikipedia\\wikipedia.py:393\u001b[0m, in \u001b[0;36mWikipediaPage.__load\u001b[1;34m(self, redirect, preload)\u001b[0m\n\u001b[0;32m    390\u001b[0m   filtered_lis \u001b[38;5;241m=\u001b[39m [li \u001b[38;5;28;01mfor\u001b[39;00m li \u001b[38;5;129;01min\u001b[39;00m lis \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtocsection\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(li\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m, []))]\n\u001b[0;32m    391\u001b[0m   may_refer_to \u001b[38;5;241m=\u001b[39m [li\u001b[38;5;241m.\u001b[39ma\u001b[38;5;241m.\u001b[39mget_text() \u001b[38;5;28;01mfor\u001b[39;00m li \u001b[38;5;129;01min\u001b[39;00m filtered_lis \u001b[38;5;28;01mif\u001b[39;00m li\u001b[38;5;241m.\u001b[39ma]\n\u001b[1;32m--> 393\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m DisambiguationError(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m, page[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]), may_refer_to)\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    396\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpageid \u001b[38;5;241m=\u001b[39m pageid\n",
                        "\u001b[1;31mDisambiguationError\u001b[0m: \"Python\" may refer to: \nPythonidae\nPython (genus)\nPython (mythology)\nPython (programming language)\nCMU Common Lisp\nPERQ 3\nPython of Aenus\nPython (painter)\nPython of Byzantium\nPython of Catana\nPython Anghelo\nPython (Efteling)\nPython (Busch Gardens Tampa Bay)\nPython (Coney Island, Cincinnati, Ohio)\nPython (automobile maker)\nPython (Ford prototype)\nPython (missile)\nPython (nuclear primary)\nColt Python\nPython (codename)\nPython (film)\nMonty Python\nPython (Monty) Pictures\nTimon of Phlius\nPyton\nPithon"
                    ]
                }
            ],
            "source": [
                "page = wikipedia.page(\"Python\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 238,
            "metadata": {},
            "outputs": [
                {
                    "ename": "PageError",
                    "evalue": "Page id \"Animalss\" does not match any pages. Try another id!",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mPageError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[238], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m page \u001b[38;5;241m=\u001b[39m \u001b[43mwikipedia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAnimalss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_suggest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\wikipedia\\wikipedia.py:276\u001b[0m, in \u001b[0;36mpage\u001b[1;34m(title, pageid, auto_suggest, redirect, preload)\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m       \u001b[38;5;66;03m# if there is no suggestion or search results, the page doesn't exist\u001b[39;00m\n\u001b[0;32m    275\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m PageError(title)\n\u001b[1;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWikipediaPage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pageid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    278\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m WikipediaPage(pageid\u001b[38;5;241m=\u001b[39mpageid, preload\u001b[38;5;241m=\u001b[39mpreload)\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\wikipedia\\wikipedia.py:299\u001b[0m, in \u001b[0;36mWikipediaPage.__init__\u001b[1;34m(self, title, pageid, redirect, preload, original_title)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEither a title or a pageid must be specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 299\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preload:\n\u001b[0;32m    302\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m prop \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreferences\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinks\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msections\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\wikipedia\\wikipedia.py:345\u001b[0m, in \u001b[0;36mWikipediaPage.__load\u001b[1;34m(self, redirect, preload)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m page:\n\u001b[0;32m    344\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PageError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtitle)\n\u001b[0;32m    346\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PageError(pageid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpageid)\n",
                        "\u001b[1;31mPageError\u001b[0m: Page id \"Animalss\" does not match any pages. Try another id!"
                    ]
                }
            ],
            "source": [
                "page = wikipedia.page(\"Animalss\", auto_suggest=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can handle these errors using the following code:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 239,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Animal\n",
                        "Pythonidae\n"
                    ]
                }
            ],
            "source": [
                "# Fixes PageError by allowing redirects\n",
                "\n",
                "page = wikipedia.page(\"Animalss\", redirect=True)\n",
                "print(page.title)\n",
                "\n",
                "# Fixes DisambiguationError by selecting the first option\n",
                "\n",
                "try:\n",
                "    page = wikipedia.page(\"Python\")\n",
                "except DisambiguationError as e:\n",
                "    page = wikipedia.page(e.options[0])\n",
                "print(page.title)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The above code gives a `DisambiguationError` because the title \"Python\" can correspond to multiple pages. Then there is a `PageError` for \"Animalss\" as there is no Wikipedia name with that title.\n",
                "\n",
                "To handle these errors, we have implemented a simple function `get_page` for you to get the page object for a particular page title. This handles `RedirectError` (and in some cases `PageError`) by setting `redirect=True`. The function also handles `DisambiguationError` by choosing the first option in the list of potential pages we could be referring to.\n",
                "\n",
                "We handle any `PageError` not fixed by the above by setting `auto_suggest=True`, and letting wikipedia guess at the page we mean (this is a last resort, and hopefully won't be necessary).\n",
                "\n",
                "<details><summary>What do <code>redirect</code> and <code>auto_suggest</code> do?</summary>\n",
                "\n",
                "**Redirect**\n",
                "\n",
                "The keyword `redirect` tells the API to allow Wikipedia to provide redirections. This happens when you reference an article in a manner which is slightly different than how it is stored in Wikipedia. This rarely happens when we will use the wikipedia API, as we will access pages based on how they are stored in Wikipedia, but as an example:\n",
                "```python\n",
                "page = wikipedia.page(\"huMan\", redirect = True, auto_suggest=False)\n",
                "```\n",
                "will return a `WikipediaPage` object for the \"Human\" page. However,\n",
                "```python\n",
                "page = wikipedia.page(\"huMan\", redirect=False, auto_suggest=False)\n",
                "```\n",
                "will return a `PageError` (since there is a page called \"Human\" but not \"huMan\"). The Wikipedia API will generally access the correct page if there is a capitalization issue on the first letter, but a capitalization error in the middle of the word will raise an error (unless `redirect=True`).\n",
                "\n",
                "<br>\n",
                "\n",
                "**Auto suggest**\n",
                "\n",
                "The keyword `auto_suggest` tells the API to allow Wikipedia to provide suggestions. This allows a lot more than `redirect` does, since `redirect` is only for the \"obvious\" cases (e.g. \"huMan\" → \"Human\", \"U.S. President\" → \"President of the United States\", etc.). When `auto_suggest` is true, it would allow something like \"president of states\" → \"President of the United States\", \"gogle\" → \"Google\"; both of which would raise an error if `redirect = True, auto_suggest = False`.\n",
                "\n",
                "However, `auto_suggest` can sometimes be *too* permissive and lead to errors, for example:\n",
                "\n",
                "```python\n",
                "page = wikipedia.page(\"Human\", redirect= False, auto_suggest=True)\n",
                "```\n",
                "will return a `WikipediaPage` object for the \"Man\" page. This is clearly not what we were trying to access, and the `auto_suggest` has gotten carried away in this case.\n",
                "\n",
                "If `redirect = True` and `auto_suggest=True`, then `auto_suggest` takes priority.\n",
                "</details>\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 240,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_page(title: str) -> WikipediaPage:\n",
                "    \"\"\"\n",
                "    Get a Wikipedia page object given a title. If the title is ambiguous, choose the first option. If the title is not found, try to find a similar title.\n",
                "\n",
                "    Args:\n",
                "        title (str): The title of the Wikipedia page\n",
                "\n",
                "    Returns:\n",
                "        WikipediaPage: The Wikipedia page\n",
                "    \"\"\"\n",
                "    try:\n",
                "        return wikipedia.page(title, auto_suggest=False, redirect=True)\n",
                "    except DisambiguationError as e:\n",
                "        return wikipedia.page(e.options[0], auto_suggest=False, redirect=True)\n",
                "    except PageError as e:\n",
                "        return wikipedia.page(title, auto_suggest=True, redirect=True)\n",
                "\n",
                "\n",
                "def get_word_count(text: str) -> int:\n",
                "    return len(text.split())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Get permitted links from a wikipedia page\n",
                "```c\n",
                "Difficulty: 🔴⚪⚪⚪⚪\n",
                "Importance: 🔵🔵⚪⚪⚪\n",
                "\n",
                "You should spend up to 5-10 mins on this exercise.\n",
                "```\n",
                "\n",
                "When you get the links from a page using `page.links`, this will include every possible Wikipedia link that is accessible from the HTML on that page, including those that are not in the main page content (e.g. links in sidebars, links in footnotes etc.), which are either irrelevant or not permitted by the rules of the Wiki game. Write a simple `get_permitted_links` function, that only returns the links that can be found inside the main content. The resulting list of permitted links should be about a third as long as the list of links from the wikipedia API (with more variance for shorter articles as you would expect). \n",
                "<!-- When writing this function, if you manage to get the links in a very effective way, then do that. But remember that Wikipedia is written by a large number of different contributors, often adhering to inconsistent stylings (especially for smaller articles). We just need to get something that **works well enough**. Put more time into doing this effectively if you want at the end, but as soon as something plausibly works, you should move on.\n",
                "\n",
                "<img src=\"https://imgs.xkcd.com/comics/code_lifespan_2x.png\" width=\"400px\" style = \"margin-left: auto; margin-right: auto;display:block\"></img> -->"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 241,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_permitted_links(current_page: WikipediaPage) -> list[str]:\n",
                "    \"\"\"\n",
                "    Get \"permitted\" links (i.e. links that are in the content of the page) from a Wikipedia page.\n",
                "\n",
                "    Args:\n",
                "        current_page (WikipediaPage): The current Wikipedia page\n",
                "\n",
                "    Returns:\n",
                "        list[str]: A list of permitted links from current_page\n",
                "\n",
                "    \"\"\"\n",
                "    all_links = current_page.links\n",
                "    content = current_page.content\n",
                "    permitted_links = [link for link in all_links if link in content]\n",
                "    return permitted_links"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Finally, we've implemented a `get_content` function, which the agent will use to get the content of a Wikipedia page. This wraps all the texts that correspond to links in `<link></link>` tags (since otherwise they are presented as strings and indistinguishable from normal text.). \n",
                "\n",
                "TODO: DELETE THIS SINCE IT'S IN TOOL STUFF LATER ON?\n",
                "\n",
                "<details><summary>Why not just use `page.links` to get a list of links directly?</summary>\n",
                "\n",
                "We don't just present a list of the accessible links, as this is not very faithful to the wikipedia game. The agent does perform somewhat better if we just give it a list of links, but the task of parsing the content of wikipedia pages and isolating the most important links is where the majority of the challenge of the wikipedia game lies.\n",
                "\n",
                "</details>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 242,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "58\n",
                        "428\n",
                        "A large <link>language model</link> (LLM) is a computational <link>model</link> capable of language generation or other natural language processing tasks. As language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised training process.\n",
                        "The largest and most capable LLMs, as of August 2024, are artificial neural networks built with a decoder-only transformer-based architecture, which enables efficient processing and generation of large-scale text data. Modern models can be fine-tuned for specific tasks or can be guided by <link>prompt engineering</link>. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained on.\n",
                        "Some notable LLMs are <link>OpenAI</link>'s GPT series of models (e.g., <link>GPT-3.5</link>, <link>GPT-4</link> and <link>GPT-4o</link>; used in <link>ChatGPT</link> and <link>Microsoft Copilot</link>), <link>Google</link>'s Gemini (the latter of which is currently used in the <link>chatbot</link> of the same name), Meta's <link>LLaMA</link> family of models, <link>IBM</link>'s Granite models initially released with <link>Watsonx</link>, <link>Anthropic</link>'s Claude models, and <link>Mistral AI</link>'s models.\n",
                        "\n",
                        "\n",
                        "== History ==\n",
                        "Before 2017, there were a few language models that were large as compared to capacities then available. In the 1990s, the <link>IBM alignment models</link> pioneered statistical language modelling. A smoothed n-gram model in 2001 trained on 0.3 billion words achieved then-SOTA (state of the art) <link>perplexity</link>. In the 2000s, as Internet use became prevalent, some researchers constructed Internet-scale language datasets (\"web as corpus\"), upon which they trained statistical language models. In 2009, in most language processing tasks, statistical language models dominated over symbolic language models, as they can usefully ingest large datasets.\n",
                        "\n",
                        "After neural networks became dominant in image processing around 2012, they were applied to language modelling as well. Google converted its translation service to Neural Machine Translation in 2016. As it was before Transformers, it was done by <link>seq2seq</link> deep LSTM networks.\n",
                        "At the 2017 <link>NeurIPS</link> conference, Google researchers introduced the <link>transformer architecture</link> in their landmark paper \"<link>Attention Is All You Need</link>\". This paper's goal was to improve upon 2014 Seq2seq technology, and was based mainly on the attention mechanism developed by Bahdanau et al. in 2014. The following year in 2018, BERT was introduced and quickly became \"ubiquitous\". Though the original transformer has both encoder and decoder blocks, BERT is an encoder-only model.\n",
                        "Although decoder-only <link>GPT-1</link> was introduced in 2018, it was <link>GPT-2</link> in 2019 that caught widespread attention because OpenAI at first deemed it too powerful to release publicly, out of fear of malicious use. <link>GPT-3</link> in 2020 went a step further and as of 2024 is available only via <link>API</link> with no offering of downloading the model to execute locally. But it was the 2022 consumer-facing browser-based ChatGPT that captured the imaginations of the general population and caused some media hype and online buzz. The 2023 GPT-4 was praised for its increased accuracy and as a \"holy grail\" for its multimodal capabilities. OpenAI did not reveal high-level architecture and the number of parameters of GPT-4.\n",
                        "Competing language models have for the most part been attempting to equal the GPT series, at least in terms of number of parameters.\n",
                        "Since 2022, source-available models have been gaining popularity, especially at first with BLOOM and LLaMA, though both have restrictions on the field of use. Mistral AI's models Mistral 7B and Mixtral 8x7b have the more permissive <link>Apache License</link>. As of June 2024, The Instruction fine tuned variant of the Llama 3 70 billion parameter model is the most powerful open LLM according to the LMSYS Chatbot Arena Leaderboard, being more powerful than GPT-3.5 but not as powerful as GPT-4.\n",
                        "As of 2024, the largest and most capable models are all based on the Transformer architecture. Some recent implementations are based on other architectures, such as recurrent neural network variants and Mamba (a state space model).\n",
                        "\n",
                        "\n",
                        "== Dataset preprocessing ==\n",
                        "\n",
                        "\n",
                        "=== Tokenization ===\n",
                        "Because machine learning algorithms process numbers rather than text, the text must be converted to numbers. In the first step, a vocabulary is decided upon, then integer indices are arbitrarily but uniquely assigned to each vocabulary entry, and finally, an embedding is associated to the integer index. Algorithms include byte-pair encoding (BPE) and WordPiece. There are also special tokens serving as control characters, such as [MASK] for masked-out token (as used in BERT), and [UNK] (\"unknown\") for characters not appearing in the vocabulary. Also, some special symbols are used to denote special text formatting. For example, \"Ġ\" denotes a preceding whitespace in RoBERTa and GPT. \"##\" denotes continuation of a preceding <link>word</link>. in BERT.\n",
                        "For example, the BPE tokenizer used by GPT-3 (Legacy) would split tokenizer: texts -> series of numerical \"tokens\" as\n",
                        "\n",
                        "Tokenization also compresses the datasets. Because LLMs generally require input to be an array that is not jagged, the shorter texts must be \"padded\" until they match the length of the longest one. How many tokens are, on average, needed per word depends on the language of the dataset.\n",
                        "\n",
                        "\n",
                        "==== BPE ====\n",
                        "\n",
                        "As an example, consider a tokenizer based on byte-pair encoding. In the first step, all unique characters (including blanks and punctuation marks) are treated as an initial set of n-grams (i.e. initial set of uni-grams). Successively the most frequent pair of adjacent characters is merged into a bi-gram and all instances of the pair are replaced by it. All occurrences of adjacent pairs of (previously merged) n-grams that most frequently occur together are then again merged into even lengthier n-gram, until a vocabulary of prescribed size is obtained (in case of GPT-3, the size is 50257). After a tokenizer is trained, any text can be tokenized by it, as long as it does not contain characters not appearing in the initial-set of uni-grams.\n",
                        "\n",
                        "\n",
                        "==== Problems ====\n",
                        "A token vocabulary based on the frequencies extracted from mainly English corpora uses as few tokens as possible for an average English word. An average word in another language encoded by such an English-optimized tokenizer is however split into suboptimal amount of tokens. GPT-2 tokenizer can use up to 15 times more tokens per word for some languages, for example for the <link>Shan language</link> from <link>Myanmar</link>. Even more widespread languages such as Portuguese and German have \"a premium of 50%\" compared to English.\n",
                        "Greedy tokenization also causes subtle problems with text completion.\n",
                        "\n",
                        "\n",
                        "=== Dataset cleaning ===\n",
                        "\n",
                        "In the context of training LLMs, datasets are typically cleaned by removing toxic passages from the dataset, discarding low-quality data, and de-duplication. Cleaned datasets can increase training efficiency and lead to improved downstream performance. A trained LLM can be used to clean datasets for training a further LLM.\n",
                        "With the increasing proportion of LLM-generated content on the web, data cleaning in the future may include filtering out such content. LLM-generated content can pose a problem if the content is similar to human text (making filtering difficult) but of lower quality (degrading performance of models trained on it).\n",
                        "\n",
                        "\n",
                        "=== <link>Synthetic data</link> ===\n",
                        "\n",
                        "Training of largest language models might need more linguistic data than naturally available, or that the naturally occurring data is of insufficient quality. In these cases, synthetic data might be used. <link>Microsoft</link>'s Phi series of LLMs is trained on textbook-like data generated by another LLM.\n",
                        "\n",
                        "\n",
                        "== Training and architecture ==\n",
                        "\n",
                        "\n",
                        "=== <link>Reinforcement learning from human feedback</link> (RLHF) ===\n",
                        "\n",
                        "<link>Reinforcement learning</link> from human feedback (RLHF) through algorithms, such as proximal policy optimization, is used to further fine-tune a model based on a dataset of human preferences.\n",
                        "\n",
                        "\n",
                        "=== Instruction tuning ===\n",
                        "Using \"self-instruct\" approaches, LLMs have been able to bootstrap correct responses, replacing any naive responses, starting from human-generated corrections of a few cases. For example, in the instruction \"Write an essay about the main themes represented in Hamlet,\" an initial naive completion might be \"If you submit the essay after March 17, your grade will be reduced by 10% for each day of delay,\" based on the frequency of this textual sequence in the corpus.\n",
                        "\n",
                        "\n",
                        "=== <link>Mixture of experts</link> ===\n",
                        "\n",
                        "The largest LLM may be too expensive to train and use directly. For such models, mixture of experts (MoE) can be applied, a line of research pursued by Google researchers since 2017 to train models reaching up to 1 trillion parameters.\n",
                        "\n",
                        "\n",
                        "=== Prompt engineering, attention mechanism, and context window ===\n",
                        "\n",
                        "Most results previously achievable only by (costly) fine-tuning, can be achieved through prompt engineering, although limited to the scope of a single conversation (more precisely, limited to the scope of a context window).\n",
                        "\n",
                        "In order to find out which tokens are relevant to each other within the scope of the context window, the attention mechanism calculates \"soft\" weights for each token, more precisely for its embedding, by using multiple attention heads, each with its own \"relevance\" for calculating its own soft weights. For example, the small (i.e. 117M parameter sized) GPT-2 model has had twelve attention heads and a context window of only 1k token. In its medium version it has 345M parameters and contains 24 layers, each with 12 attention heads. For the training with gradient descent a batch size of 512 was utilized.\n",
                        "The largest models, such as Google's Gemini 1.5, presented in February 2024, can have a context window sized up to 1 million (context window of 10 million was also \"successfully tested\"). Other models with large context windows includes Anthropic's Claude 2.1, with a context window of up to 200k tokens. Note that this maximum refers to the number of input tokens and that the maximum number of output tokens differs from the input and is often smaller. For example, the GPT-4 Turbo model has a maximum output of 4096 tokens.\n",
                        "Length of a conversation that the model can take into account when generating its next answer is limited by the size of a context window, as well. If the length of a conversation, for example with ChatGPT, is longer than its context window, only the parts inside the context window are taken into account when generating the next answer, or the model needs to apply some algorithm to summarize the too distant parts of conversation.\n",
                        "The shortcomings of making a context window larger include higher computational cost and possibly diluting the focus on local context, while making it smaller can cause a model to miss an important long-range dependency. Balancing them are a matter of experimentation and domain-specific considerations.\n",
                        "A model may be pre-trained either to predict how the segment continues, or what is missing in the segment, given a segment from its training dataset. It can be either\n",
                        "\n",
                        "autoregressive (i.e. predicting how the segment continues, the way GPTs do it): for example given a segment \"I like to eat\", the model predicts \"ice cream\", or \"sushi\".\n",
                        "\"masked\" (i.e. filling in the parts missing from the segment, the way \"BERT\" does it): for example, given a segment \"I like to [__] [__] cream\", the model predicts that \"eat\" and \"ice\" are missing.\n",
                        "Models may be trained on auxiliary tasks which test their understanding of the data distribution, such as Next Sentence Prediction (NSP), in which pairs of sentences are presented and the model must predict whether they appear consecutively in the training corpus. During training, regularization loss is also used to stabilize training. However regularization loss is usually not used during testing and evaluation.\n",
                        "\n",
                        "\n",
                        "=== Infrastructure ===\n",
                        "Substantial infrastructure is necessary for training the largest models.\n",
                        "\n",
                        "\n",
                        "== Training cost ==\n",
                        "\n",
                        "Advances in software and hardware have reduced the cost substantially since 2020, such that in 2023 training of a 12-billion-parameter LLM computational cost is 72,300 A100-GPU-hours, while in 2020 the cost of training a 1.5-billion-parameter LLM (which was two orders of magnitude smaller than the state of the art in 2020) was between $80 thousand and $1.6 million. Since 2020, large sums were invested in increasingly large models. For example, training of the GPT-2 (i.e. a 1.5-billion-parameters model) in 2019 cost $50,000, while training of the <link>PaLM</link> (i.e. a 540-billion-parameters model) in 2022 cost $8 million, and Megatron-Turing NLG 530B (in 2021) cost around $11 million.\n",
                        "For Transformer-based LLM, training cost is much higher than inference cost. It costs 6 FLOPs per parameter to train on one token, whereas it costs 1 to 2 FLOPs per parameter to infer on one token.\n",
                        "\n",
                        "\n",
                        "== Tool use ==\n",
                        "There are certain tasks that, in principle, cannot be solved by any LLM, at least not without the use of external tools or additional software. An example of such a task is responding to the user's input '354 * 139 = ', provided that the LLM has not already encountered a continuation of this calculation in its training corpus. In such cases, the LLM needs to resort to running program code that calculates the result, which can then be included in its response. Another example is 'What is the time now? It is ', where a separate program interpreter would need to execute a code to get system time on the computer, so LLM could include it in its reply. This basic strategy can be sophisticated with multiple attempts of generated programs, and other sampling strategies.\n",
                        "Generally, in order to get an LLM to use tools, one must finetune it for tool-use. If the number of tools is finite, then finetuning may be done just once. If the number of tools can grow arbitrarily, as with online API services, then the LLM can be fine-tuned to be able to read API documentation and call API correctly.\n",
                        "A simpler form of tool use is retrieval-augmented generation: the augmentation of an LLM with document retrieval. Given a query, a document retriever is called to retrieve the most relevant documents. This is usually done by encoding the query and the documents into vectors, then finding the documents with vectors (usually stored in a vector database) most similar to the vector of the query. The LLM then generates an output based on both the query and context included from the retrieved documents.\n",
                        "\n",
                        "\n",
                        "== Agency ==\n",
                        "An LLM is a language model, which is not an agent as it has no goal, but it can be used as a component of an intelligent agent. Researchers have described several methods for such integrations.\n",
                        "The <link>ReAct pattern</link>, a portmanteau of \"Reason + Act\", constructs an agent out of an LLM, using the LLM as a planner. The LLM is prompted to \"think out loud\". Specifically, the language model is prompted with a textual description of the environment, a goal, a list of possible actions, and a record of the actions and observations so far. It generates one or more thoughts before generating an action, which is then executed in the environment. The linguistic description of the environment given to the LLM planner can even be the LaTeX code of a paper describing the environment.\n",
                        "In the DEPS (\"Describe, Explain, Plan and Select\") method, an LLM is first connected to the visual world via image descriptions, then it is prompted to produce plans for complex tasks and behaviors based on its pretrained knowledge and environmental feedback it receives.\n",
                        "The Reflexion method constructs an agent that learns over multiple episodes. At the end of each episode, the LLM is given the record of the episode, and prompted to think up \"lessons learned\", which would help it perform better at a subsequent episode. These \"lessons learned\" are given to the agent in the subsequent episodes.\n",
                        "<link>Monte Carlo tree search</link> can use an LLM as rollout heuristic. When a programmatic world model is not available, an LLM can also be prompted with a description of the environment to act as world model.\n",
                        "For open-ended exploration, an LLM can be used to score observations for their \"interestingness\", which can be used as a reward signal to guide a normal (non-LLM) reinforcement learning agent. Alternatively, it can propose increasingly difficult tasks for curriculum learning. Instead of outputting individual actions, an LLM planner can also construct \"skills\", or functions for complex action sequences. The skills can be stored and later invoked, allowing increasing levels of abstraction in planning.\n",
                        "LLM-powered agents can keep a long-term memory of its previous contexts, and the memory can be retrieved in the same way as Retrieval Augmented Generation. Multiple such agents can interact socially.\n",
                        "\n",
                        "\n",
                        "== Compression ==\n",
                        "Typically, LLMs are trained with single- or half-precision floating point numbers (float32 and float16). One float16 has 16 bits, or 2 bytes, and so one billion parameters require 2 gigabytes. The largest models typically have 100 billion parameters, requiring 200 gigabytes to load, which places them outside the range of most consumer electronics.\n",
                        "Post-training quantization aims to decrease the space requirement by lowering precision of the parameters of a trained model, while preserving most of its performance. The simplest form of quantization simply truncates all numbers to a given number of bits. It can be improved by using a different quantization codebook per layer. Further improvement can be done by applying different precisions to different parameters, with higher precision for particularly important parameters (\"outlier weights\"). See  for a visual guide.\n",
                        "While quantized models are typically frozen, and only pre-quantized models are fine-tuned, quantized models can still be fine-tuned.\n",
                        "\n",
                        "\n",
                        "== Multimodality ==\n",
                        "\n",
                        "Multimodality means \"having several modalities\", and a \"modality\" refers to a type of input or output, such as video, image, audio, text, proprioception, etc. There have been many AI models trained specifically to ingest one modality and output another modality, such as <link>AlexNet</link> for image to label, visual question answering for image-text to text, and speech recognition for speech to text.\n",
                        "A common method to create multimodal models out of an LLM is to \"tokenize\" the output of a trained encoder. Concretely, one can construct an LLM that can understand images as follows: take a trained LLM, and take a trained image encoder \n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        E\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle E}\n",
                        "  \n",
                        ". Make a small multilayered perceptron \n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        f\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle f}\n",
                        "  \n",
                        ", so that for any image \n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        y\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle y}\n",
                        "  \n",
                        ", the post-processed vector \n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        f\n",
                        "        (\n",
                        "        E\n",
                        "        (\n",
                        "        y\n",
                        "        )\n",
                        "        )\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle f(E(y))}\n",
                        "  \n",
                        " has the same dimensions as an encoded token. That is an \"image token\". Then, one can interleave text tokens and image tokens. The compound model is then fine-tuned on an image-text dataset. This basic construction can be applied with more sophistication to improve the model. The image encoder may be frozen to improve stability.\n",
                        "Flamingo demonstrated the effectiveness of the tokenization method, finetuning a pair of pretrained language model and image encoder to perform better on visual question answering than models trained from scratch. Google PaLM model was fine-tuned into a multimodal model PaLM-E using the tokenization method, and applied to robotic control. LLaMA models have also been turned multimodal using the tokenization method, to allow image inputs, and video inputs.\n",
                        "GPT-4 can use both text and image as inputs (although the vision component was not released to the public until GPT-4V); <link>Google DeepMind</link>'s Gemini is also multimodal. \n",
                        "\n",
                        "\n",
                        "== Properties ==\n",
                        "\n",
                        "\n",
                        "=== Scaling laws ===\n",
                        "\n",
                        "The following four hyper-parameters characterize an LLM:\n",
                        "\n",
                        "cost of (pre-)training (\n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        C\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle C}\n",
                        "  \n",
                        "),\n",
                        "size of the artificial neural network itself, such as number of parameters \n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        N\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle N}\n",
                        "  \n",
                        " (i.e. amount of neurons in its layers, amount of weights between them and biases),\n",
                        "size of its (pre-)training dataset (i.e. number of tokens in corpus, \n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        D\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle D}\n",
                        "  \n",
                        "),\n",
                        "performance after (pre-)training.\n",
                        "They are related by simple statistical laws, called \"scaling laws\". One particular scaling law (\"Chinchilla scaling\") for LLM autoregressively trained for one epoch, with a log-log learning rate schedule, states that:\n",
                        "\n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        \n",
                        "          \n",
                        "            {\n",
                        "            \n",
                        "              \n",
                        "                \n",
                        "                  C\n",
                        "                  =\n",
                        "                  \n",
                        "                    C\n",
                        "                    \n",
                        "                      0\n",
                        "                    \n",
                        "                  \n",
                        "                  N\n",
                        "                  D\n",
                        "                \n",
                        "              \n",
                        "              \n",
                        "                \n",
                        "                  L\n",
                        "                  =\n",
                        "                  \n",
                        "                    \n",
                        "                      A\n",
                        "                      \n",
                        "                        N\n",
                        "                        \n",
                        "                          α\n",
                        "                        \n",
                        "                      \n",
                        "                    \n",
                        "                  \n",
                        "                  +\n",
                        "                  \n",
                        "                    \n",
                        "                      B\n",
                        "                      \n",
                        "                        D\n",
                        "                        \n",
                        "                          β\n",
                        "                        \n",
                        "                      \n",
                        "                    \n",
                        "                  \n",
                        "                  +\n",
                        "                  \n",
                        "                    L\n",
                        "                    \n",
                        "                      0\n",
                        "                    \n",
                        "                  \n",
                        "                \n",
                        "              \n",
                        "            \n",
                        "            \n",
                        "          \n",
                        "        \n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle {\\begin{cases}C=C_{0}ND\\\\[6pt]L={\\frac {A}{N^{\\alpha }}}+{\\frac {B}{D^{\\beta }}}+L_{0}\\end{cases}}}\n",
                        "  \n",
                        " where the variables are\n",
                        "\n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        C\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle C}\n",
                        "  \n",
                        " is the cost of training the model, in FLOPs.\n",
                        "\n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        N\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle N}\n",
                        "  \n",
                        " is the number of parameters in the model.\n",
                        "\n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        D\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle D}\n",
                        "  \n",
                        " is the number of tokens in the training set.\n",
                        "\n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        L\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle L}\n",
                        "  \n",
                        " is the average negative log-likelihood loss per token (nats/token), achieved by the trained LLM on the test dataset.\n",
                        "and the statistical hyper-parameters are\n",
                        "\n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        \n",
                        "          C\n",
                        "          \n",
                        "            0\n",
                        "          \n",
                        "        \n",
                        "        =\n",
                        "        6\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle C_{0}=6}\n",
                        "  \n",
                        ", meaning that it costs 6 FLOPs per parameter to train on one token. Note that training cost is much higher than inference cost, where it costs 1 to 2 FLOPs per parameter to infer on one token.\n",
                        "\n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        α\n",
                        "        =\n",
                        "        0.34\n",
                        "        ,\n",
                        "        β\n",
                        "        =\n",
                        "        0.28\n",
                        "        ,\n",
                        "        A\n",
                        "        =\n",
                        "        406.4\n",
                        "        ,\n",
                        "        B\n",
                        "        =\n",
                        "        410.7\n",
                        "        ,\n",
                        "        \n",
                        "          L\n",
                        "          \n",
                        "            0\n",
                        "          \n",
                        "        \n",
                        "        =\n",
                        "        1.69\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle \\alpha =0.34,\\beta =0.28,A=406.4,B=410.7,L_{0}=1.69}\n",
                        "  \n",
                        "\n",
                        "\n",
                        "=== Emergent abilities ===\n",
                        "\n",
                        "Performance of bigger models on various tasks, when plotted on a log-log scale, appears as a linear extrapolation of performance achieved by smaller models. However, this linearity may be punctuated by \"break(s)\" in the scaling law, where the slope of the line changes abruptly, and where larger models acquire \"emergent abilities\". They arise from the complex interaction of the model's components and are not explicitly programmed or designed.\n",
                        "The most intriguing among emergent abilities is <link>in-context learning</link> from example demonstrations. In-context learning is involved in tasks, such as:\n",
                        "\n",
                        "reported arithmetics, decoding the <link>International Phonetic Alphabet</link>, unscrambling a word's letters, disambiguate word in context, converting spatial words, cardinal directions (for example, replying \"northeast\" upon [0, 0, 1; 0, 0, 0; 0, 0, 0]), color terms represented in text.\n",
                        "chain-of-thought prompting: Model outputs are improved by chain-of-thought prompting only when model size exceeds 62B. Smaller models perform better when prompted to answer immediately, without chain of thought.\n",
                        "identifying offensive content in paragraphs of <link>Hinglish</link> (a combination of Hindi and English), and generating a similar English equivalent of <link>Kiswahili</link> proverbs.\n",
                        "Schaeffer et. al. argue that the emergent abilities are not unpredictably acquired, but predictably acquired according to a smooth scaling law. The authors considered a toy statistical model of an LLM solving multiple-choice questions, and showed that this statistical model, modified to account for other types of tasks, applies to these tasks as well.\n",
                        "Let \n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        x\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle x}\n",
                        "  \n",
                        " be the number of parameter count, and \n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        y\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle y}\n",
                        "  \n",
                        " be the performance of the model.\n",
                        "\n",
                        "\n",
                        "== Interpretation ==\n",
                        "Large language models by themselves are \"black boxes\", and it is not clear how they can perform linguistic tasks. There are several methods for understanding how LLM work.\n",
                        "Mechanistic interpretability aims to reverse-engineer LLM by discovering symbolic algorithms that approximate the inference performed by LLM. One example is Othello-GPT, where a small Transformer is trained to predict legal Othello moves. It is found that there is a linear representation of Othello board, and modifying the representation changes the predicted legal Othello moves in the correct way. In another example, a small Transformer is trained on Karel programs. Similar to the Othello-GPT example, there is a linear representation of Karel program semantics, and modifying the representation changes output in the correct way. The model also generates correct programs that are on average shorter than those in the training set.\n",
                        "In another example, the authors trained small transformers on modular arithmetic addition. The resulting models were reverse-engineered, and it turned out they used discrete Fourier transform.\n",
                        "\n",
                        "\n",
                        "=== Understanding and intelligence ===\n",
                        "NLP researchers were evenly split when asked, in a 2022 survey, whether (untuned) LLMs \"could (ever) understand natural language in some nontrivial sense\". Proponents of \"LLM understanding\" believe that some LLM abilities, such as mathematical reasoning, imply an ability to \"understand\" certain concepts. A Microsoft team argued in 2023 that GPT-4 \"can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more\" and that GPT-4 \"could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence system\": \"Can one reasonably say that a system that passes exams for software engineering candidates is not really intelligent?\" Some researchers characterize LLMs as \"alien intelligence\". For example, Conjecture CEO Connor Leahy considers untuned LLMs to be like inscrutable alien \"Shoggoths\", and believes that RLHF tuning creates a \"smiling facade\" obscuring the inner workings of the LLM: \"If you don't push it too far, the smiley face stays on. But then you give it [an unexpected] prompt, and suddenly you see this massive underbelly of insanity, of weird thought processes and clearly non-human understanding.\"\n",
                        "In contrast, some proponents of the \"LLMs lack understanding\" school believe that existing LLMs are \"simply remixing and recombining existing writing\", a phenomenon known as stochastic parrot, or they point to the deficits existing LLMs continue to have in prediction skills, reasoning skills, agency, and explainability. For example, GPT-4 has natural deficits in planning and in real-time learning. Generative LLMs have been observed to confidently assert claims of fact which do not seem to be justified by their training data, a phenomenon which has been termed \"hallucination\". Specifically, hallucinations in the context of LLMs correspond to the generation of text or responses that seem syntactically sound, fluent, and natural but are factually incorrect, nonsensical, or unfaithful to the provided source input. Neuroscientist <link>Terrence Sejnowski</link> has argued that \"The diverging opinions of experts on the intelligence of LLMs suggests that our old ideas based on natural intelligence are inadequate\".\n",
                        "The matter of LLM's exhibiting intelligence or understanding has two main aspects – the first is how to model thought and language in a computer system, and the second is how to enable the computer system to generate human like language. These aspects of language as a model of cognition have been developed in the field of cognitive linguistics. American linguist <link>George Lakoff</link> presented Neural Theory of Language (NTL) as a computational basis for using language as a model of learning tasks and understanding. The NTL Model outlines how specific neural structures of the human brain shape the nature of thought and language and in turn what are the computational properties of such neural systems that can be applied to model thought and language in a computer system. After a framework for modeling language in a computer systems was established, the focus shifted to establishing frameworks for computer systems to generate language with acceptable grammar. In his 2014 book titled <link>The Language Myth</link>: Why Language Is Not An Instinct, British cognitive linguist and digital communication technologist <link>Vyvyan Evans</link> mapped out the role of probabilistic context-free grammar (PCFG) in enabling NLP to model cognitive patterns and generate human like language.\n",
                        "\n",
                        "\n",
                        "== Evaluation ==\n",
                        "\n",
                        "\n",
                        "=== Perplexity ===\n",
                        "The most commonly used measure of a language model's performance is its perplexity on a given text corpus. Perplexity is a measure of how well a model is able to predict the contents of a dataset; the higher the likelihood the model assigns to the dataset, the lower the perplexity. Mathematically, perplexity is defined as the exponential of the average negative log likelihood per token:\n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        log\n",
                        "        ⁡\n",
                        "        (\n",
                        "        \n",
                        "          Perplexity\n",
                        "        \n",
                        "        )\n",
                        "        =\n",
                        "        −\n",
                        "        \n",
                        "          \n",
                        "            1\n",
                        "            N\n",
                        "          \n",
                        "        \n",
                        "        \n",
                        "          ∑\n",
                        "          \n",
                        "            i\n",
                        "            =\n",
                        "            1\n",
                        "          \n",
                        "          \n",
                        "            N\n",
                        "          \n",
                        "        \n",
                        "        log\n",
                        "        ⁡\n",
                        "        (\n",
                        "        Pr\n",
                        "        (\n",
                        "        \n",
                        "          \n",
                        "            token\n",
                        "          \n",
                        "          \n",
                        "            i\n",
                        "          \n",
                        "        \n",
                        "        ∣\n",
                        "        \n",
                        "          \n",
                        "            context for token\n",
                        "          \n",
                        "          \n",
                        "            i\n",
                        "          \n",
                        "        \n",
                        "        )\n",
                        "        )\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle \\log({\\text{Perplexity}})=-{\\frac {1}{N}}\\sum _{i=1}^{N}\\log(\\Pr({\\text{token}}_{i}\\mid {\\text{context for token}}_{i}))}\n",
                        "  \n",
                        "here \n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        N\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle N}\n",
                        "  \n",
                        " is the number of tokens in the text corpus, and \"context for token \n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        i\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle i}\n",
                        "  \n",
                        "\" depends on the specific type of LLM used. If the LLM is autoregressive, then \"context for token \n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        i\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle i}\n",
                        "  \n",
                        "\" is the segment of text appearing before token \n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        i\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle i}\n",
                        "  \n",
                        ". If the LLM is masked, then \"context for token \n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        i\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle i}\n",
                        "  \n",
                        "\" is the segment of text surrounding token \n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        i\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle i}\n",
                        "  \n",
                        ".\n",
                        "Because language models may overfit to their training data, models are usually evaluated by their perplexity on a test set of unseen data. This presents particular challenges for the evaluation of large language models. As they are trained on increasingly large corpora of text largely scraped from the web, it becomes increasingly likely that models' training data inadvertently includes portions of any given test set.\n",
                        "\n",
                        "\n",
                        "==== BPW, BPC, and BPT ====\n",
                        "In information theory, the concept of entropy is intricately linked to perplexity, a relationship notably established by <link>Claude Shannon</link>. This relationship is mathematically expressed as \n",
                        "  \n",
                        "    \n",
                        "      \n",
                        "        \n",
                        "          Entropy\n",
                        "        \n",
                        "        =\n",
                        "        \n",
                        "          log\n",
                        "          \n",
                        "            2\n",
                        "          \n",
                        "        \n",
                        "        ⁡\n",
                        "        (\n",
                        "        \n",
                        "          Perplexity\n",
                        "        \n",
                        "        )\n",
                        "      \n",
                        "    \n",
                        "    {\\displaystyle {\\text{Entropy}}=\\log _{2}({\\text{Perplexity}})}\n",
                        "  \n",
                        ".\n",
                        "Entropy, in this context, is commonly quantified in terms of bits per word (BPW) or bits per character (BPC), which hinges on whether the language model utilizes word-based or character-based tokenization.\n",
                        "Notably, in the case of larger language models that predominantly employ sub-word tokenization, bits per token (BPT) emerges as a seemingly more appropriate measure. However, due to the variance in tokenization methods across different Large Language Models (LLMs), BPT does not serve as a reliable metric for comparative analysis among diverse models. To convert BPT into BPW, one can multiply it by the average number of tokens per word.\n",
                        "In the evaluation and comparison of language models, cross-entropy is generally the preferred metric over entropy. The underlying principle is that a lower BPW is indicative of a model's enhanced capability for compression. This, in turn, reflects the model's proficiency in making accurate predictions.\n",
                        "\n",
                        "\n",
                        "=== Task-specific datasets and benchmarks ===\n",
                        "A large number of testing datasets and benchmarks have also been developed to evaluate the capabilities of language models on more specific downstream tasks. Tests may be designed to evaluate a variety of capabilities, including general knowledge, commonsense reasoning, and mathematical problem-solving.\n",
                        "One broad category of evaluation dataset is question answering datasets, consisting of pairs of questions and correct answers, for example, (\"Have the San Jose Sharks won the Stanley Cup?\", \"No\"). A question answering task is considered \"open book\" if the model's prompt includes text from which the expected answer can be derived (for example, the previous question could be adjoined with some text which includes the sentence \"The Sharks have advanced to the Stanley Cup finals once, losing to the Pittsburgh Penguins in 2016.\"). Otherwise, the task is considered \"closed book\", and the model must draw on knowledge retained during training. Some examples of commonly used question answering datasets include TruthfulQA, Web Questions, TriviaQA, and SQuAD.\n",
                        "Evaluation datasets may also take the form of text completion, having the model select the most likely word or sentence to complete a prompt, for example: \"Alice was friends with Bob. Alice went to visit her friend, ____\".\n",
                        "Some composite benchmarks have also been developed which combine a diversity of different evaluation datasets and tasks. Examples include GLUE, SuperGLUE, <link>MMLU</link>, BIG-bench, and HELM. OpenAI has released tools for running composite benchmarks, but noted that the eval results are sensitive to the prompting method. Some public datasets contain questions that are mislabeled, ambiguous, unanswerable, or otherwise of low-quality, which can be cleaned to give more reliable benchmark scores.\n",
                        "It was previously standard to report results on a heldout portion of an evaluation dataset after doing supervised fine-tuning on the remainder. It is now more common to evaluate a pre-trained model directly through prompting techniques, though researchers vary in the details of how they formulate prompts for particular tasks, particularly with respect to how many examples of solved tasks are adjoined to the prompt (i.e. the value of n in n-shot prompting).\n",
                        "\n",
                        "\n",
                        "==== Adversarially constructed evaluations ====\n",
                        "Because of the rapid pace of improvement of large language models, evaluation benchmarks have suffered from short lifespans, with state of the art models quickly \"saturating\" existing benchmarks, exceeding the performance of human annotators, leading to efforts to replace or augment the benchmark with more challenging tasks. In addition, there are cases of \"shortcut learning\" wherein AIs sometimes \"cheat\" on multiple-choice tests by using statistical correlations in superficial test question wording in order to guess the correct responses, without necessarily understanding the actual question being asked.\n",
                        "Some datasets have been constructed adversarially, focusing on particular problems on which extant language models seem to have unusually poor performance compared to humans. One example is the TruthfulQA dataset, a question answering dataset consisting of 817 questions which language models are susceptible to answering incorrectly by mimicking falsehoods to which they were repeatedly exposed during training. For example, an LLM may answer \"No\" to the question \"Can you teach an old dog new tricks?\" because of its exposure to the English idiom you can't teach an old dog new tricks, even though this is not literally true.\n",
                        "Another example of an adversarial evaluation dataset is Swag and its successor, HellaSwag, collections of problems in which one of multiple options must be selected to complete a text passage. The incorrect completions were generated by sampling from a language model and filtering with a set of classifiers. The resulting problems are trivial for humans but at the time the datasets were created state of the art language models had poor accuracy on them. For example:\n",
                        "\n",
                        "We see a fitness center sign. We then see a man talking to the camera and sitting and laying on a exercise ball. The man...\n",
                        "a) demonstrates how to increase efficient exercise work by running up and down balls.\n",
                        "b) moves all his arms and legs and builds up a lot of muscle.\n",
                        "c) then plays the ball and we see a graphics and hedge trimming demonstration.\n",
                        "d) performs sit ups while on the ball and talking.\n",
                        "\n",
                        "BERT selects b) as the most likely completion, though the correct answer is d).\n",
                        "\n",
                        "\n",
                        "== Wider impact ==\n",
                        "In 2023, <link>Nature Biomedical Engineering</link> wrote that \"it is no longer possible to accurately distinguish\" human-written text from text created by large language models, and that \"It is all but certain that general-purpose large language models will rapidly proliferate... It is a rather safe bet that they will change many industries over time.\" <link>Goldman Sachs</link> suggested in 2023 that generative language AI could increase global GDP by 7% in the next ten years, and could expose to automation 300 million jobs globally.\n",
                        "\n",
                        "\n",
                        "=== Memorization and copyright ===\n",
                        "\n",
                        "Memorization is an emergent behavior in LLMs in which long strings of text are occasionally output verbatim from training data, contrary to typical behavior of traditional artificial neural nets. Evaluations of controlled LLM output measure the amount memorized from training data (focused on GPT-2-series models) as variously over 1% for exact duplicates or up to about 7%.\n",
                        "\n",
                        "\n",
                        "=== Security ===\n",
                        "Some commenters expressed concern over accidental or deliberate creation of misinformation, or other forms of misuse. For example, the availability of large language models could reduce the skill-level required to commit bioterrorism; biosecurity researcher Kevin Esvelt has suggested that LLM creators should exclude from their training data papers on creating or enhancing pathogens.\n",
                        "A study by researchers at Google and several universities, including <link>Cornell University</link> and <link>University of California, Berkeley</link>, showed that there are potential security risks in language models such as ChatGPT. In their study, they examined and confirmed the possibility that questioners could get, from ChatGPT, the training data that the AI model used. For example, when asking ChatGPT 3.5 turbo to repeat the word \"poem\" forever, the AI model will say \"poem\" hundreds of times and then diverge, deviating from the standard dialogue style and spitting out nonsense phrases, thus spitting out the training data as it is. The researchers have seen more than 10,000 examples of the AI model exposing their training data in a similar method. The researchers said that it was hard to tell if the AI model was actually safe or not.\n",
                        "The potential presence of \"sleeper agents\" within LLM models is another emerging security concern. These are hidden functionalities built into the model that remain dormant until triggered by a specific event or condition. Upon activation, the LLM deviates from its expected behavior to make insecure actions.\n",
                        "Large language model (LLM) applications accessible to the public, like ChatGPT or Claude, typically incorporate safety measures designed to filter out harmful content. However, implementing these controls effectively has proven challenging. For instance, research by Kang et al.   demonstrated a method for circumventing LLM safety systems. Similarly, Wang\n",
                        " illustrated how a potential criminal could potentially bypass ChatGPT 4o's safety controls to obtain information on establishing a drug trafficking operation.\n",
                        "\n",
                        "\n",
                        "=== <link>Algorithmic bias</link> ===\n",
                        "\n",
                        "While LLMs have shown remarkable capabilities in generating human-like text, they are susceptible to inheriting and amplifying biases present in their training data. This can manifest in skewed representations or unfair treatment of different demographics, such as those based on race, gender, language, and cultural groups. Since English data is overrepresented in current large language models' training data, it may also downplay non-English views.\n",
                        "\n",
                        "\n",
                        "==== Stereotyping ====\n",
                        "AI models can reinforce a wide range of stereotypes, including those based on gender, ethnicity, age, nationality, religion, or occupation. This can lead to outputs that unfairly generalize or caricature groups of people, sometimes in harmful or derogatory ways.\n",
                        "Notably, gender bias refers to the tendency of these models to produce outputs that are unfairly prejudiced towards one gender over another. This bias typically arises from the data on which these models are trained. Large language models often assign roles and characteristics based on traditional gender norms. For example, it might associate nurses or secretaries predominantly with women and engineers or CEOs with men.\n",
                        "\n",
                        "\n",
                        "==== Political bias ====\n",
                        "Political bias refers to the tendency of algorithms to systematically favor certain political viewpoints, ideologies, or outcomes over others. Language models may also exhibit political biases. Since the training data includes a wide range of political opinions and coverage, the models might generate responses that lean towards particular political ideologies or viewpoints, depending on the prevalence of those views in the data.\n",
                        "\n",
                        "\n",
                        "== List ==\n",
                        "\n",
                        "For the training cost column, 1 petaFLOP-day = 1 petaFLOP/sec × 1 day = 8.64E19 FLOP. Also, only the largest model's cost is written.\n",
                        "\n",
                        "\n",
                        "== See also ==\n",
                        "<link>Foundation models</link>\n",
                        "\n",
                        "\n",
                        "== Notes ==\n",
                        "\n",
                        "\n",
                        "== References ==\n",
                        "\n",
                        "\n",
                        "== Further reading ==\n",
                        "Jurafsky, Dan, Martin, James. H. Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition, 3rd Edition draft, 2023.\n",
                        "Zhao, Wayne Xin; et al. (2023). \"A Survey of Large Language Models\". arXiv:2303.18223 [cs.CL].\n",
                        "Kaddour, Jean; et al. (2023). \"Challenges and Applications of Large Language Models\". arXiv:2307.10169 [cs.CL].\n",
                        "Yin, Shukang; Fu, Chaoyou; Zhao, Sirui; Li, Ke; Sun, Xing; Xu, Tong; Chen, Enhong (2023-06-01). \"A Survey on Multimodal Large Language Models\". arXiv:2306.13549 [cs.CV].\n",
                        "\"AI Index Report 2024 – Artificial Intelligence Index\". aiindex.stanford.edu. Retrieved 2024-05-05.\n",
                        "Frank, Michael C. (27 June 2023). \"Baby steps in evaluating the capacities of large language models\". Nature Reviews Psychology. 2 (8): 451–452. doi:10.1038/s44159-023-00211-x. ISSN 2731-0574. S2CID 259713140. Retrieved 2 July 2023.\n"
                    ]
                }
            ],
            "source": [
                "def get_content(page: WikipediaPage) -> str:\n",
                "    \"\"\"\n",
                "    Get the content of a Wikipedia page with links wrapped with <link></link> tags.\n",
                "\n",
                "    Args:\n",
                "        page (WikipediaPage): The Wikipedia page\n",
                "\n",
                "    Returns:\n",
                "        str: The content of the page with links wrapped with tags.\n",
                "    \"\"\"\n",
                "    content = page.content\n",
                "    permitted_links = get_permitted_links(page)\n",
                "    for word in sorted(permitted_links, key=len, reverse=True):\n",
                "        content = re.sub(\n",
                "            r\"\"\"(\\s|[,.)!?;:'\"])(\"\"\" + re.escape(word) + r\"\"\")(\\s|[,.)!?;:'\"\"])\"\"\",\n",
                "            r\"\\1<link>\\2</link>\\3\",\n",
                "            content,\n",
                "            count=1,\n",
                "            flags=re.IGNORECASE,\n",
                "        )\n",
                "    return content\n",
                "\n",
                "\n",
                "wiki_page = get_page(\"Large language model\")\n",
                "print(len(get_permitted_links(wiki_page)))\n",
                "print(len(wiki_page.links))\n",
                "print(get_content(wiki_page))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Build `WikiGame`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Build a class for the Wiki game\n",
                "```c\n",
                "Difficulty: 🔴🔴🔴🔴⚪\n",
                "Importance: 🔵🔵🔵🔵⚪\n",
                "\n",
                "You should spend up to 25-30 mins on this exercise.\n",
                "```\n",
                "\n",
                "Implement the following class that instantiates the wikipedia game. When the model uses tools it will be making calls to this class, so make sure that the functions return messages you're happy for the model to see as a tool response, such as error messages if the tool doesn't work.\n",
                "\n",
                "Use code from the `get_permitted_links` and `get_content` functions above in this class."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 243,
            "metadata": {},
            "outputs": [],
            "source": [
                "class BaseWikiGame:\n",
                "    def __init__(\n",
                "        self,\n",
                "        starting_page: str,\n",
                "        goal_page: str,\n",
                "    ):\n",
                "        \"\"\"\n",
                "        Initialize the Wikipedia game object.\n",
                "\n",
                "        Args:\n",
                "            starting_page (str): The page the agent starts on.\n",
                "            goal_page (str): The page the agent is trying to reach.\n",
                "        \"\"\"\n",
                "        self.page_history: List[str] = [starting_page]\n",
                "        self.starting_page: WikipediaPage = self.get_page(starting_page)\n",
                "        self.goal_page: WikipediaPage = self.get_page(goal_page)\n",
                "        self.current_page: WikipediaPage = self.starting_page\n",
                "\n",
                "    # ========================= Helper Functions (given) =========================\n",
                "\n",
                "    # Get page and page summary\n",
                "    @staticmethod\n",
                "    def get_page(title: str) -> WikipediaPage:\n",
                "        \"\"\"\n",
                "        Get a Wikipedia page object given a title. If the title is ambiguous, choose the first option. If the title is not found, try to find a similar title.\n",
                "\n",
                "        Args:\n",
                "            title (str): The title of the Wikipedia page\n",
                "\n",
                "        Returns:\n",
                "            WikipediaPage: The Wikipedia page\n",
                "        \"\"\"\n",
                "        try:\n",
                "            return wikipedia.page(title, auto_suggest=False, redirect=True)\n",
                "        except DisambiguationError as e:\n",
                "            return wikipedia.page(e.options[0], auto_suggest=False, redirect=True)\n",
                "        except PageError as e:\n",
                "            return wikipedia.page(title, auto_suggest=True, redirect=True)\n",
                "\n",
                "    def get_page_summary(self, page: WikipediaPage | None = None) -> str:\n",
                "        \"\"\"\n",
                "        Get summary of a wikipedia page, to the last full stop within the first 500 characters. This is used to give a brief overview of the page to the agent.\n",
                "\n",
                "        Args:\n",
                "            page (WikipediaPage): The Wikipedia page object.\n",
                "\n",
                "        Returns:\n",
                "            str: The summary of the Wikipedia page.\n",
                "        \"\"\"\n",
                "        page = page if page else self.goal_page\n",
                "        summary = page.content[:500]\n",
                "        last_period_index = summary.rfind(\".\")\n",
                "        return summary[: last_period_index + 1] if last_period_index != -1 else summary\n",
                "\n",
                "    # Get and check permitted links\n",
                "    def get_permitted_links(self, title: Optional[str] = None) -> list[str]:\n",
                "        \"\"\"\n",
                "        Returns a list of permitted links (i.e. links in the main page content) for the current page.\n",
                "\n",
                "        Args:\n",
                "            title (Optional[str]): The title of the Wikipedia page. If None, uses the current page.\n",
                "\n",
                "        Returns:\n",
                "            list[str]: The permitted links.\n",
                "        \"\"\"\n",
                "        if title:\n",
                "            page = self.get_page(title)\n",
                "            all_links = page.links\n",
                "            content = page.content\n",
                "            permitted_links = [link for link in all_links if link in content]\n",
                "            if title in permitted_links:\n",
                "                permitted_links.remove(title)\n",
                "        else:\n",
                "            all_links = self.current_page.links\n",
                "            content = self.current_page.content\n",
                "            permitted_links = [link for link in all_links if link in content]\n",
                "            if self.current_page.title in permitted_links:\n",
                "                permitted_links.remove(self.current_page.title)\n",
                "        return permitted_links\n",
                "\n",
                "    def is_permitted_link(self, link: str) -> bool:\n",
                "        \"\"\"\n",
                "        Returns True if the link is in the permitted links for the current page, False otherwise.\n",
                "\n",
                "        Args:\n",
                "            link (str): The link to check.\n",
                "\n",
                "        Returns:\n",
                "            bool: True if the link is permitted, False otherwise\n",
                "        \"\"\"\n",
                "        return link.lower() in (x.lower() for x in self.get_permitted_links())\n",
                "\n",
                "    # ========================= Task State Management (to implement) =========================\n",
                "\n",
                "    @property\n",
                "    def system_instruction(self) -> dict:\n",
                "        \"\"\"\n",
                "        Generate the starting instructions for the game.\n",
                "\n",
                "        Returns:\n",
                "            dict: The starting instructions. \"role\" is \"system\" for system messages.\n",
                "        \"\"\"\n",
                "        return {\n",
                "            \"role\": \"system\",\n",
                "            \"content\": \"You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages.\",\n",
                "        }\n",
                "\n",
                "    @property\n",
                "    def on_page_instruction(self) -> dict:\n",
                "        \"\"\"\n",
                "        Generate instructions for the current page.\n",
                "\n",
                "        Returns:\n",
                "            dict: The instructions for the current page. \"role\" is \"user\" for user messages.\n",
                "        \"\"\"\n",
                "        return {\n",
                "            \"role\": \"user\",\n",
                "            \"content\": f\"\"\"You are currently on page: {self.current_page.title}. Your goal page is {self.goal_page.title}.\"\"\",\n",
                "        }\n",
                "\n",
                "    @property\n",
                "    def next_step_instruction(self) -> dict:\n",
                "        \"\"\"\n",
                "        Generate instructions for the next step.\n",
                "\n",
                "        Returns:\n",
                "            dict: The instructions for the next step. \"role\" is \"user\" for user messages.\n",
                "        \"\"\"\n",
                "        return {\n",
                "            \"role\": \"user\",\n",
                "            \"content\": f\"What's your next step?\",\n",
                "        }\n",
                "\n",
                "    def get_instructions(self, system: bool, on_page: bool, next_step: bool) -> str:\n",
                "        \"\"\"\n",
                "        Generate instruction messages based on the current game state.\n",
                "\n",
                "        Args:\n",
                "            system (bool): Whether to include system instructions.\n",
                "            on_page (bool): Whether to include on-page instructions.\n",
                "            next_step (bool): Whether to include next-step instructions.\n",
                "\n",
                "        Returns:\n",
                "            list[str]: A list of instruction messages.\n",
                "        \"\"\"\n",
                "        messages = []\n",
                "        if system:\n",
                "            messages.append(self.system_instruction)\n",
                "        if on_page:\n",
                "            messages.append(self.on_page_instruction)\n",
                "        if next_step:\n",
                "            messages.append(self.next_step_instruction)\n",
                "        return messages\n",
                "\n",
                "    def check_win(self) -> bool:\n",
                "        return self.current_page == self.goal_page\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Build Tools for the Wiki Game\n",
                "```c\n",
                "Difficulty: 🔴⚪⚪⚪⚪\n",
                "Importance: 🔵🔵🔵⚪⚪\n",
                "\n",
                "You should spend up to 5-10 mins on this exercise.\n",
                "```\n",
                "\n",
                "Fill in the following tool classes that the agent will need to use to accomplish this game.\n",
                "- For the `get_content_tool`, you should just fill in the description, since we've implemented the functionality for you.\n",
                "- For the `move_page_tool`, you should implement both the `execute()` function and the `description()` property.\n",
                "\n",
                "When formatting this tool list, refer back to the solution for you wrote for the arithmetic game, or else the docs are [here](https://platform.openai.com/docs/guides/function-calling).\n",
                "\n",
                "<details><summary>Notes on the <code>get_content()</code> tool</summary>\n",
                "\n",
                "We've implemented it in a hacky way etc. need to fill this in later.\n",
                "\n",
                "</details>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 244,
            "metadata": {},
            "outputs": [],
            "source": [
                "class get_content_tool(Tool):\n",
                "    name = \"get_content\"\n",
                "\n",
                "    @staticmethod\n",
                "    def execute(task: BaseWikiGame | Any) -> str:\n",
                "        \"\"\"\n",
                "        Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link is wrapped in <link></link> tags.\n",
                "\n",
                "        Args:\n",
                "            task (BaseWikiGame | Any): The current task object.\n",
                "\n",
                "        Returns:\n",
                "            str: The content of the page with links wrapped\n",
                "        \"\"\"\n",
                "        content = task.current_page.content\n",
                "        permitted_links = get_permitted_links(task.current_page)\n",
                "        for word in sorted(permitted_links, key=len, reverse=True):\n",
                "            content = re.sub(\n",
                "                r\"\"\"(\\s|[,.)!?;:'\"])(\"\"\" + re.escape(word) + r\"\"\")(\\s|[,.)!?;:'\"s])\"\"\",\n",
                "                r\"\\1<link>\\2</link>\\3\",\n",
                "                content,\n",
                "                count=1,\n",
                "                flags=re.IGNORECASE,\n",
                "            )\n",
                "        return content\n",
                "\n",
                "    @property\n",
                "    def description(self):\n",
                "        \"\"\"\n",
                "        Provides the description of the get_content tool\n",
                "\n",
                "        Returns:\n",
                "            dict: The description of the tool for the API\n",
                "        \"\"\"\n",
                "        return {\n",
                "            \"type\": \"function\",\n",
                "            \"function\": {\n",
                "                \"name\": self.name,\n",
                "                \"description\": \"Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select to move to will be wrapped in <link></link> tags.\",\n",
                "                \"parameters\": {\n",
                "                    \"type\": \"object\",\n",
                "                    \"properties\": {},\n",
                "                    \"required\": [],\n",
                "                },\n",
                "            },\n",
                "        }\n",
                "\n",
                "\n",
                "class move_page_tool(Tool):\n",
                "    name = \"move_page\"\n",
                "\n",
                "    @staticmethod\n",
                "    def execute(new_page: str, task: Any) -> str:\n",
                "        \"\"\"\n",
                "        Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n",
                "\n",
                "        Args:\n",
                "            task (BaseWikiGame): The current task object.\n",
                "            new_page (str): The title of the new page to move to.\n",
                "\n",
                "        Returns:\n",
                "            str: A message indicating the result of the move\n",
                "        \"\"\"\n",
                "        new_page_normalized = new_page.replace(\"_\", \" \")\n",
                "        if task.is_permitted_link(new_page_normalized):\n",
                "            task.current_page = task.get_page(new_page_normalized)\n",
                "            task.page_history.append(task.current_page.title)\n",
                "            return f\"Moving page to {task.current_page.title}\"\n",
                "        else:\n",
                "            return f\"Couldn't move page to {new_page}. This is not a valid link.\"\n",
                "\n",
                "    @property\n",
                "    def description(self):\n",
                "        \"\"\"\n",
                "        Provides the description of the move_page tool\n",
                "\n",
                "        Returns:\n",
                "            dict: The description of the move_page tool for the API\n",
                "        \"\"\"\n",
                "        return {\n",
                "            \"type\": \"function\",\n",
                "            \"function\": {\n",
                "                \"name\": self.name,\n",
                "                \"description\": \"Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\",\n",
                "                \"parameters\": {\n",
                "                    \"type\": \"object\",\n",
                "                    \"properties\": {\n",
                "                        \"new_page\": {\n",
                "                            \"type\": \"string\",\n",
                "                            \"description\": 'The title of the new page you want to move to. This should be formatted the way the title appears on wikipedia (e.g. to move to the wikipedia page for the United States of America, you should enter \"United States\"). Underscores are not necessary.',\n",
                "                        }\n",
                "                    },\n",
                "                    \"required\": [\"new_page\"],\n",
                "                },\n",
                "            },\n",
                "        }\n",
                "\n",
                "\n",
                "get_content_tool_inst = get_content_tool()\n",
                "move_page_tool_inst = move_page_tool()\n",
                "wiki_game_tools = [get_content_tool_inst, move_page_tool_inst]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Build a WikiAgent\n",
                "```c\n",
                "🔴🔴🔴🔴⚪\n",
                "🔵🔵🔵🔵🔵\n",
                "\n",
                "You should spend up to 30-40 mins on this exercise.\n",
                "```\n",
                "\n",
                "\n",
                "Insturctions to give:\n",
                "1. again, work out task decision tree \n",
                "2. let them implement handle_tool_call(), run(), start()\n",
                "\n",
                "===================\n",
                "\n",
                "Now that you have the `WikiGame` class and tools set up, build out a `WikiAgent` that can access these tools and solve the Wikipedia game. Build the agent so that it can be thrown into an agent loop (similar to the one we had for the arithmetic game) without much additional scaffolding. \n",
                "\n",
                "There are a few further considerations in this case that we didn't have for the arithmetic game. \n",
                "\n",
                "<details>\n",
                "<summary>Context window considerations</summary>\n",
                "\n",
                "Since the agent will need to read (potentially very long) Wikipedia articles to interact with the game, the length of the context window becomes relevant. GPT-4o and GPT-4o-mini both have context windows of 128k tokens (which corresponds to ~96k words). For reference, the wikipedia page for the United States has around 10k words alone and the agent will often need to visit more than 10 articles in one run of the game, not counting its own output, which eventually adds up to be significant. We'll solve this for now by resetting the messages of the agent every time it reaches a new wikipedia page, and providing an updated `user_message` (and possibly `system_message`) so that the agent can locate itself, and then proceed with the game. We'll address different methods for solving this issue later, you can probably already think of some. So be careful to include the current page and goal page for the agent in the `user_message`.\n",
                "\n",
                "</details>\n",
                "<br>\n",
                "\n",
                "\n",
                "<details><summary>Providing information to the agent</summary>\n",
                "\n",
                "There shouldn't be much on Wikipedia that the agent is completely unfamiliar with (AI companies *will* have scraped wikipedia), but it may be easily confused with something else, or be an article that was added before the training cutoff, and models can't always accurately recall information in their training data if they only come up once or twice. So you should use the game's get_summary function to provide details of the goal page to the agent in its initial message.\n",
                "\n",
                "</details>\n",
                "<br>\n",
                "\n",
                "<details><summary> Getting output from the agent </summary>\n",
                "\n",
                "In this case we'll have a lot more moving pieces than the `arithmeticGame` agent. In that case it was possible to just print output directly from the agent loop. In this case, you should print output as it comes up in the agent class. If there's some chance you might not want to see this output, you should use the `verbose` flag to determine whether to print content or not.\n",
                "\n",
                "</details>\n",
                "\n",
                "When making calls to the wikipediaGame class, make use of Python's `getattr()` function ([explanation here](https://www.w3schools.com/python/ref_func_getattr.asp)).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 245,
            "metadata": {},
            "outputs": [],
            "source": [
                "class WikiAgent(SimpleAgent):\n",
                "    \"\"\"\n",
                "    Inherits from SimpleAgent and adds the ability to handle tool calls and refusals in the Wikipedia game context.\n",
                "\n",
                "    Attributes:\n",
                "        model (str): The model used for generating responses (inherited)\n",
                "        tools (List[Any]): List of tools (inherited)\n",
                "        client (OpenAI): OpenAI client for API calls (inherited)\n",
                "        task (Any): The current task being executed\n",
                "        chat_history (List[dict]): History of interactions (inherited)\n",
                "\n",
                "    Methods:\n",
                "        get_response(use_tool: bool = True) -> ChatCompletionMessage:\n",
                "            Get response from the model (inherited)\n",
                "\n",
                "        execute_tool_calls(message: ChatCompletionMessage) -> List[str]:\n",
                "            Execute tool calls from the model's response (inherited)\n",
                "\n",
                "        run(with_tool: bool = True) -> bool:\n",
                "            Run one loop of the Wikipedia agent (modified below)\n",
                "\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        task: Any,\n",
                "        tools: List[Any],\n",
                "        model=\"gpt-4o-mini\",\n",
                "        chat_history: List[dict] = None,\n",
                "        verbose: bool = True,\n",
                "    ):\n",
                "        super().__init__(model=model, tools=tools, task=task)\n",
                "\n",
                "        self.chat_history = chat_history if chat_history else []\n",
                "        self.full_chat_history = (\n",
                "            chat_history if chat_history else []\n",
                "        )  # All messages that have been sent in the chat history. We have to erase each time a new page is reached for context window reasons.\n",
                "        self.verbose = verbose\n",
                "        self.start()\n",
                "\n",
                "    def update_history(\n",
                "        self, message: str | ChatCompletionMessage | List[str | ChatCompletionMessage]\n",
                "    ):\n",
                "        \"\"\"\n",
                "        Update self.chat_history and self.full_chat_history with a message or list of messages.\n",
                "\n",
                "        Args:\n",
                "            message (str | List[str]): The message to add to the chat history\n",
                "        \"\"\"\n",
                "        if isinstance(message, list):\n",
                "            self.chat_history.extend(message)\n",
                "            self.full_chat_history.extend(message)\n",
                "        else:\n",
                "            self.chat_history.append(message)\n",
                "            self.full_chat_history.append(message)\n",
                "\n",
                "    def reset_history(self):\n",
                "        \"\"\"\n",
                "        Empty self.chat_history of the agent.\n",
                "        \"\"\"\n",
                "        self.chat_history = []\n",
                "\n",
                "    def handle_tool_calls(self, response: ChatCompletionMessage):\n",
                "        \"\"\"\n",
                "        Handles tool_calls in the wikipedia game context:\n",
                "            - Executes the tool calls using execute_tool_calls\n",
                "            - Appends the original tool call & tool_responses to the chat_history\n",
                "            - If the agent has moved to a new page, resets the chat_history\n",
                "            - If not, get the next_step_message instruction from the task and append it to chat_history\n",
                "\n",
                "        Args:\n",
                "            response (ChatCompletionMessage): The response from the model\n",
                "        \"\"\"\n",
                "\n",
                "        # Update history\n",
                "        self.update_history(response)\n",
                "\n",
                "        # Execute the tool calls\n",
                "        tool_responses = self.execute_tool_calls(response)\n",
                "\n",
                "        # Add tool calls and responses to the history\n",
                "        for tool_call, tool_response in zip(response.tool_calls, tool_responses):\n",
                "            self.update_history(apply_tool_call_format(tool_call, tool_response))\n",
                "\n",
                "            if self.verbose:\n",
                "                print(\n",
                "                    f\"\\nTOOL CALL: \\nTool = {tool_call.function.name}, Args = {tool_call.function.arguments} \\nTOOL RESPONSE:\\n {tool_response[:300]}\"\n",
                "                )\n",
                "\n",
                "        # Move to new page if necessary\n",
                "        if any(\"Moving page\" in tool_response for tool_response in tool_responses):\n",
                "            self.reset_history()\n",
                "            print(\n",
                "                f\"\"\"{(\"-\" * 50)} \\n\\nMOVED TO PAGE \\n\\nPATH HISTORY (N={len(self.task.page_history)}): {\" -> \".join(self.task.page_history)} \\n\\n{(\"-\"*50)}\"\"\"\n",
                "            )\n",
                "\n",
                "            # Give starting instructions if moved to a new page\n",
                "            self.start()\n",
                "\n",
                "        # Otherwise ask the agent what the next step is\n",
                "\n",
                "        else:\n",
                "            next_step_message = self.task.next_step_instruction\n",
                "            self.update_history(next_step_message)\n",
                "            if self.verbose:\n",
                "                print(f\"\"\"\\nUSER: \\n{next_step_message[\"content\"]}\"\"\")\n",
                "\n",
                "    def handle_refusal(self, response: ChatCompletionMessage):\n",
                "        \"\"\"\n",
                "        Handles refusals in the wikipedia game context:\n",
                "\n",
                "        Args:\n",
                "            response (ChatCompletionMessage): The response from the model\n",
                "        \"\"\"\n",
                "        self.update_history(apply_assistant_format(response.refusal))\n",
                "        if self.verbose:\n",
                "            print(f\"\\nMODEL REFUSAL: {response.refusal}\")\n",
                "\n",
                "    def start(self):\n",
                "        \"\"\"\n",
                "        A function to put the starting instructions in agent.chat_history when the agent starts a new page or starts the game.\n",
                "        \"\"\"\n",
                "        instruction_messages = [\n",
                "            self.task.system_instruction,\n",
                "            self.task.on_page_instruction,\n",
                "        ]\n",
                "        self.update_history(instruction_messages)\n",
                "        if self.verbose:\n",
                "            print(\n",
                "                f\"\\nSYSTEM: \\n{instruction_messages[0]['content']} \\n\\nUSER: \\n{instruction_messages[1]['content']}\"\n",
                "            )\n",
                "\n",
                "    def run(self):\n",
                "        \"\"\"\n",
                "        This function runs the agent in the wikipedia game context. It:\n",
                "            - Gets the current task instruction\n",
                "            - Gets the response from the model\n",
                "            - Handles the response in the cases:\n",
                "                - tool calls (using handle_tool_calls)\n",
                "                - refusals (using handle_refusal)\n",
                "                - no tool calls (using update_history)\n",
                "        \"\"\"\n",
                "\n",
                "        # Get the response from the model\n",
                "        response = self.get_response()\n",
                "\n",
                "        # Handle the response\n",
                "        ## If tool calls, do the tool calls and return the response\n",
                "        if response.tool_calls:\n",
                "            self.handle_tool_calls(response)\n",
                "\n",
                "        ## If no tool call: Handle edge cases\n",
                "        ### Check if there's a refusal to answer:\n",
                "        elif response.refusal:\n",
                "            self.handle_refusal(response)\n",
                "\n",
                "        # Else response content does not contain tool calls or refusal, and we add it to the chat_history in an assistant format.\n",
                "        else:\n",
                "            self.update_history(apply_assistant_format(response.content))\n",
                "            if self.verbose:\n",
                "                print(f\"\\nMODEL RESPONSE: \\n{response.content}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Run the task\n",
                "```c\n",
                "Difficulty: 🔴⚪⚪⚪⚪\n",
                "Importance: 🔵🔵⚪⚪⚪\n",
                "\n",
                "You should spend up to 5 mins on this exercise.\n",
                "```\n",
                "\n",
                "Just like we did for the arithmetic agent, you should write an agent loop for the wikipedia agent (in this case you won't need to print output, as we handled it in the agent class so this function should be a very simple loop)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 246,
            "metadata": {},
            "outputs": [],
            "source": [
                "def agent_loop(agent, game, num_loops=10):\n",
                "    \"\"\"\n",
                "    Run the agent loop for a given number of loops\n",
                "\n",
                "    Args:\n",
                "        agent (WikiAgent): The agent to run\n",
                "        game (BaseWikiGame): The game to play\n",
                "        num_loops (int): The number of loops to run\n",
                "    \"\"\"\n",
                "    #agent.start()\n",
                "\n",
                "    for i in range(num_loops):\n",
                "        if game.check_win():\n",
                "            print(\"Success!\")\n",
                "            return\n",
                "        agent.run()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Your agent should be able to accomplish the following task:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 248,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Albert Einstein. Your goal page is Aristotle.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Albert <link>Einstein</link> ( EYEN-styne; German: [ˈalbɛɐt ˈʔaɪnʃtaɪn] ; 14 March 1879 – 18 April 1955) was a German-born theoretical physicist who is widely held as one of the most influential scientists. Best known for developing the theory of relativity, Einstein also made important contribution\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Quantum_mechanics\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Quantum mechanics\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Physics\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Physics. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Philosophy\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Philosophy\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Ancient_Greece\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Ancient Greece\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=4): Albert Einstein -> Quantum mechanics -> Philosophy -> Ancient Greece \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Ancient Greece. Your goal page is Aristotle.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Ancient <link>Greece</link> (Ancient Greek: Ἑλλάς, romanized: Hellás) was a northeastern Mediterranean civilization, existing from the <link>Greek Dark Ages</link> of the 12th–9th centuries BC to the end of <link>classical antiquity</link> (c. 600 AD), that comprised a loose collection of culturally\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Philosophy\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Philosophy\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=5): Albert Einstein -> Quantum mechanics -> Philosophy -> Ancient Greece -> Philosophy \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Philosophy. Your goal page is Aristotle.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Philosophy ('love of wisdom' in <link>Ancient Greek</link>) is a systematic study of general and fundamental questions concerning topics like existence, reason, knowledge, value, mind, and language. It is a <link>rational</link> and critical inquiry that reflects on its own methods and assumptions.\n",
                        "\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Aristotle\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Aristotle\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=6): Albert Einstein -> Quantum mechanics -> Philosophy -> Ancient Greece -> Philosophy -> Aristotle \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Aristotle. Your goal page is Aristotle.\n",
                        "Success!\n"
                    ]
                }
            ],
            "source": [
                "game = BaseWikiGame(\"Albert Einstein\", \"Aristotle\")\n",
                "agent = WikiAgent(task=game, tools=wiki_game_tools)\n",
                "agent_loop(agent, game, 10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Make sure to check the messages in the chat history to see the full conversation between the agent and the user, to ensure that the messages that are printed above are faithful to the actual chat history (it can be easy to make minor mistakes that mess up the agent's chat_history)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 249,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "system:\n",
                        " You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages.\n",
                        "user:\n",
                        " You are currently on page: Aristotle. Your goal page is Aristotle.\n"
                    ]
                }
            ],
            "source": [
                "for message in agent.chat_history:\n",
                "    try:\n",
                "        print(f\"{str(message.role)}:\\n {str(message.content)}\")\n",
                "    except:\n",
                "        print(f\"\"\"{message[\"role\"]}:\\n {message[\"content\"]}\"\"\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 4️⃣ Elicitation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You may have observed that while the above implementation of `WikiAgent` succeeds at Albert Einstein → Aristotle, it fails at more complex tasks. However, this doesn't mean that GPT-4o-mini does not have the capability to perform better on this task, but this capability might be blocked because we:\n",
                "\n",
                "- Prompted the model poorly\n",
                "\n",
                "- Stored the history poorly.\n",
                "\n",
                "- Didn't give the model sufficient tools to accomplish the task.\n",
                "\n",
                "- ...\n",
                "\n",
                "In general, it is hard to show that a model does not have a capability, even if *we* failed to demonstrate this capability. For example, it took *3.5 years* after the release of GPT-2 (and 2.5 years after the release of GPT-3) for people to discover that [chain-of-thought reasoning](https://arxiv.org/abs/2201.11903) massively improves model performance (which allows the completion of significantly more complex tasks). A potential failure case for AI safety is that people discover similar breakthroughs that significantly increase model performance with minimal additional training, and this is not accounted for in our safety evaluations. Thus, LLM agent evals aim to elicit the best capability we possibly can, until we feel we've managed to gain [**evidence of absence**](https://en.wikipedia.org/wiki/Evidence_of_absence), **not** just **absence of evidence**.\n",
                "\n",
                "\n",
                "Broadly speaking, there are two categories of elicitation, narrow elicitation and general elicitation:\n",
                "\n",
                "1. Narrow elicitation: methods that improve model performance on a particular task, or small class of tasks, but won't necessarily impact model performance in general across many tasks. \n",
                "    - E.g. Give the model access to the content of arbitrary wikipedia articles - This will improve performance on this task significantly, but wouldn't generalize to other tasks.\n",
                "\n",
                "2. General elicitation: methods that improve model performance on a wide array of possible tasks. \n",
                "    - E.g. Chain-of-thought prompting - This tends to improve model performance on a wide array of tasks. These sorts of elicitation methods are the ones we're most interested in, as if researchers find an improvement to models that is roughly as easy and effective as chain-of-thought prompting, then we would see a very rapid increase in risk from AI.\n",
                "\n",
                "\n",
                "We will try:\n",
                "1. Prompt engineering, including:\n",
                "    - Chain-of-thought prompting\n",
                "    \n",
                "    - The ReAct framework\n",
                "     \n",
                "2. Reflexion (allowing the model to cheaply explore future paths)\n",
                "\n",
                "3. Improved message histories\n",
                "\n",
                "Then you will be able to try further elicitation methods, including any of your own, as a bonus.\n",
                "\n",
                "<details><summary>Some notes on Wikipedia and Implementation</summary>\n",
                "\n",
                "You might start having a hard time coming up with wikipedia pages to test on. Luckily, Wikipedia offers a random page link, which is accessible via: https://en.wikipedia.org/wiki/special:random. Sometimes pages are *too* random, and won't be accessible by links between each other. One suggestion for coming up with \"random but sensible\" wikipedia pages is to go to a different language's wikipedia (which is generally much smaller than English wikipedia), and then use the \"special:random\" link (it works in every language). The majority of pages in other languages will also exist in English, but you'll want to switch languages back to English to check (and get the English title).\n",
                "\n",
                "If you want to test whether two pages are accessible via links from each other, then use this free online tool to see the possible paths between pages: https://www.sixdegreesofwikipedia.com/ (be somewhat careful with this though, as the paths that this website believes are accessible may not be accessible to our agent). \n",
                "\n",
                "</details>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Prompting\n",
                "\n",
                "You should already be aware that prompting can have a large impact on model performance. There are a wide variety of possible changes you could make for prompts in this task. You should experiment first with more general elicitation methods such as getting the agent to think more deeply, and output plans in different ways. After this, you might try a wide array of narrow elicitation methods including:\n",
                "\n",
                "- Telling the agent how many pages it's visited.\n",
                "\n",
                "- Telling the agent if it's already visited the page it's on (and how many times).\n",
                "\n",
                "- Schedule different prompts and planning methods for the \"zoom out\" and \"zoom in\" sections of the game, since we know that the general strategy for the wikipedia game looks like:\n",
                "\n",
                "    Specific article (with few links) -> General article (with many links) -> Specific article (with few links)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Engineer prompts\n",
                "```c\n",
                "Difficulty: 🔴🔴⚪⚪⚪\n",
                "Importance: 🔵🔵🔵⚪⚪\n",
                "\n",
                "You should spend up to 20-25 mins on this exercise.\n",
                "```\n",
                "\n",
                "Remember that your prompts will have to be robust to: \n",
                "\n",
                "* Different tasks within the wikipedia game, \n",
                "\n",
                "* Different states within those tasks,\n",
                "\n",
                "* Different failure-modes the agent could encounter.\n",
                "\n",
                "Mess around with the prompting setup and see if you can significantly improve performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 250,
            "metadata": {},
            "outputs": [],
            "source": [
                "class WikiGame(BaseWikiGame):\n",
                "    \"\"\"\n",
                "    Inherits from BaseWikiGame and adds improved prompting.\n",
                "\n",
                "    Attributes:\n",
                "        starting_page (str): The title of the starting page (inherited)\n",
                "        goal_page (str): The title of the goal page (inherited)\n",
                "        current_page (WikipediaPage): The current Wikipedia page (inherited)\n",
                "        page_history (List[str]): The history of pages visited (inherited)\n",
                "\n",
                "    Methods:\n",
                "        get_page(title: str) -> WikipediaPage: Get a Wikipedia page object given a title (inherited)\n",
                "\n",
                "        get_page_summary(page: WikipediaPage | None = None) -> str: Get the summary of a Wikipedia page (inherited)\n",
                "\n",
                "        get_permitted_links(title: Optional[str] = None) -> list[str]: Get permitted links for the current page (inherited)\n",
                "\n",
                "        is_permitted_link(link: str) -> bool: Check if a link is permitted (inherited)\n",
                "\n",
                "        system_instruction -> dict: Generate the starting instructions for the game (modified below)\n",
                "\n",
                "        on_page_instruction -> dict: Generate instructions for the current page (modified below)\n",
                "\n",
                "        next_step_instruction -> dict: Generate instructions for the next step (modified below)\n",
                "\n",
                "        get_instructions(system: bool, on_page: bool, next_step: bool) -> str: Generate instruction messages based on the current game state (inherited)\n",
                "\n",
                "        check_win() -> bool: Check if the game has been won (inherited)\n",
                "\n",
                "    \"\"\"\n",
                "\n",
                "    @property\n",
                "    def system_instruction(self):\n",
                "        \"\"\"\n",
                "        Provide improved starting instructions for the game.\n",
                "\n",
                "        Returns:\n",
                "            dict: The starting instructions. \"role\" is \"system\" for system messages.\n",
                "        \"\"\"\n",
                "        return {\n",
                "            \"role\": \"system\",\n",
                "            \"content\": f\"You are a wikipedia-racing AI. Your goal is to reach {self.goal_page.title} by accessing links from wikipedia pages. Your current page is {self.current_page.title}.\",\n",
                "        }\n",
                "\n",
                "    @property\n",
                "    def on_page_instruction(self):\n",
                "        \"\"\"\n",
                "        Provide improved instructions for the current page.\n",
                "\n",
                "        Returns:\n",
                "            dict: The instructions for the current page. \"role\" is \"user\" for user messages.\n",
                "        \"\"\"\n",
                "        return {\n",
                "            \"role\": \"user\",\n",
                "            \"content\": f\"\"\"You are currently on page: {self.current_page.title}. Make sure you start by reasoning about what steps you should take to get to the article on {self.goal_page.title}. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, {self.goal_page.title} has the following summary:\\n\\n[Begin Summary]\\n{self.get_page_summary(self.goal_page)}\\n[End Summary]\\n\\nThe path you have taken so far is {\" -> \".join(self.page_history)}.\n",
                "            \"\"\",\n",
                "        }\n",
                "\n",
                "    @property\n",
                "    def next_step_instruction(self):\n",
                "        \"\"\"\n",
                "        Provide improved instructions for the next step.\n",
                "\n",
                "        Returns:\n",
                "            dict: The instructions for the next step. \"role\" is \"user\" for user messages.\n",
                "        \"\"\"\n",
                "\n",
                "        return {\n",
                "            \"role\": \"user\",\n",
                "            \"content\": f\"What's your next step to get to {self.goal_page.title}?\",\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Your `BaseWikiGame` and `WikiAgent` might not work on the path \"Linux\" → \"Dana Carvey\". But with improved prompting, you should be able to get the agent to solve this task!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 251,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Linux. Your goal page is Dana Carvey.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Linux (, LIN-uuks) is a generic name for a family of open-source <link>Unix-like</link> operating systems based on the <link>Linux kernel</link>, an operating system kernel first released on September 17, 1991, by <link>Linus Torvalds</link>. Linux is typically packaged as a <link>Linux distribution\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Unix\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Unix\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Linus_Torvalds\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Linus Torvalds\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"GNU_Project\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to GNU Project\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Debian\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Debian. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Fedora_Linux\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Fedora_Linux. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Arch_Linux\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Arch_Linux. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Ubuntu\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Ubuntu. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Red_Hat_Enterprise_Linux\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Red_Hat_Enterprise_Linux. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"SUSE_Linux_Enterprise\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to SUSE_Linux_Enterprise. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"KDE_Plasma\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to KDE_Plasma. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"GNOME\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to GNOME\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Xfce\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Xfce\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=6): Linux -> Unix -> Linus Torvalds -> GNU Project -> GNOME -> Xfce \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Xfce. Your goal page is Dana Carvey.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Xfce or XFCE (pronounced as four individual letters) is a free and open-source desktop environment for <link>Linux</link> and other <link>Unix-like</link> operating systems.\n",
                        "Xfce aims to be fast and lightweight while still being visually appealing and easy to use. It embodies the traditional <link>U\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Linux\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Linux\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=7): Linux -> Unix -> Linus Torvalds -> GNU Project -> GNOME -> Xfce -> Linux \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Linux. Your goal page is Dana Carvey.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Linux (, LIN-uuks) is a generic name for a family of open-source <link>Unix-like</link> operating systems based on the <link>Linux kernel</link>, an operating system kernel first released on September 17, 1991, by <link>Linus Torvalds</link>. Linux is typically packaged as a <link>Linux distribution\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Unix-like\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Unix-like\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Linux_kernel\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Linux kernel\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Linus_Torvalds\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Linus Torvalds\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Free_Software_Foundation\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Free_Software_Foundation. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Debian\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Debian. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Fedora_Linux\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Fedora Linux\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Arch_Linux\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Arch_Linux. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Ubuntu\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Ubuntu. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Red_Hat_Enterprise_Linux\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Red Hat Enterprise Linux\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"SUSE_Linux_Enterprise\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to SUSE_Linux_Enterprise. This is not a valid link.\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=12): Linux -> Unix -> Linus Torvalds -> GNU Project -> GNOME -> Xfce -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> Fedora Linux -> Red Hat Enterprise Linux \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Red Hat Enterprise Linux. Your goal page is Dana Carvey.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Red Hat Enterprise <link>Linux</link> (RHEL) is a commercial open-source <link>Linux distribution</link> developed by <link>Red Hat</link> for the commercial market. Red Hat Enterprise Linux is released in server versions for x86-64, <link>Power ISA</link>, <link>ARM64</link>, and <link>IBM Z</link>\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Red_Hat\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Red Hat\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=13): Linux -> Unix -> Linus Torvalds -> GNU Project -> GNOME -> Xfce -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> Fedora Linux -> Red Hat Enterprise Linux -> Red Hat \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Red Hat. Your goal page is Dana Carvey.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Red Hat, Inc. (formerly Red Hat <link>Software</link>, Inc.) is an American software company that provides open source software products to enterprises and is a subsidiary of <link>IBM</link>. Founded in 1993, Red Hat has its corporate headquarters in <link>Raleigh, North Carolina</link>, with other\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"IBM\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to IBM\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Fedora_Project\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Fedora_Project. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Linux\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Linux\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=15): Linux -> Unix -> Linus Torvalds -> GNU Project -> GNOME -> Xfce -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> Fedora Linux -> Red Hat Enterprise Linux -> Red Hat -> IBM -> Linux \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Linux. Your goal page is Dana Carvey.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Linux (, LIN-uuks) is a generic name for a family of open-source <link>Unix-like</link> operating systems based on the <link>Linux kernel</link>, an operating system kernel first released on September 17, 1991, by <link>Linus Torvalds</link>. Linux is typically packaged as a <link>Linux distribution\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Unix-like\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Unix-like\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Linux_kernel\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Linux kernel\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Linus_Torvalds\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Linus Torvalds\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"GNU_Project\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to GNU Project\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Debian\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Debian. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Fedora_Linux\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Fedora_Linux. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Arch_Linux\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Arch_Linux. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Ubuntu\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Ubuntu. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Red_Hat_Enterprise_Linux\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Red_Hat_Enterprise_Linux. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"SUSE_Linux_Enterprise\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to SUSE_Linux_Enterprise. This is not a valid link.\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=19): Linux -> Unix -> Linus Torvalds -> GNU Project -> GNOME -> Xfce -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> Fedora Linux -> Red Hat Enterprise Linux -> Red Hat -> IBM -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> GNU Project \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: GNU Project. Your goal page is Dana Carvey.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " The <link>GNU</link> Project ( ) is a <link>free software</link>, mass collaboration project announced by <link>Richard Stallman</link> on September 27, 1983. Its goal is to give computer users freedom and control in their use of their computers and computing devices by collaboratively developing an\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Richard_Stallman\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Richard Stallman\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=20): Linux -> Unix -> Linus Torvalds -> GNU Project -> GNOME -> Xfce -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> Fedora Linux -> Red Hat Enterprise Linux -> Red Hat -> IBM -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> GNU Project -> Richard Stallman \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Richard Stallman. Your goal page is Dana Carvey.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Richard Matthew <link>Stallman</link> ( STAWL-mən; born March 16, 1953), also known by his initials, rms, is an American <link>free software</link> movement activist and programmer. He campaigns for software to be distributed in such a manner that its users have the freedom to use, study, distribute\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Free_software\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Free software\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"GNU_Project\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to GNU Project\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"GNU_Compiler_Collection\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to GNU Compiler Collection\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"GNU_Emacs\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to GNU Emacs\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Software_patents\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Software_patents. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Digital_rights_management\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Digital_rights_management. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Unix-like\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Unix-like\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Computer_programming\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Computer_programming. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Programming_language\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Programming_language. This is not a valid link.\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=25): Linux -> Unix -> Linus Torvalds -> GNU Project -> GNOME -> Xfce -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> Fedora Linux -> Red Hat Enterprise Linux -> Red Hat -> IBM -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> GNU Project -> Richard Stallman -> Free software -> GNU Project -> GNU Compiler Collection -> GNU Emacs -> Unix-like \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Unix-like. Your goal page is Dana Carvey.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " A Unix-like (sometimes referred to as UN*X or *nix) operating system is one that behaves in a manner similar to a <link>Unix</link> system, although not necessarily conforming to or being certified to any version of the <link>Single <link>UNIX</link> Specification</link>. A Unix-like application is \n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Linux\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Linux\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"List_of_Unix_commands\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to List_of_Unix_commands. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Free_Software_Foundation\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Free Software Foundation\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=27): Linux -> Unix -> Linus Torvalds -> GNU Project -> GNOME -> Xfce -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> Fedora Linux -> Red Hat Enterprise Linux -> Red Hat -> IBM -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> GNU Project -> Richard Stallman -> Free software -> GNU Project -> GNU Compiler Collection -> GNU Emacs -> Unix-like -> Linux -> Free Software Foundation \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Free Software Foundation. Your goal page is Dana Carvey.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " The Free <link>Software</link> Foundation (FSF) is a 501(c)(3) non-profit organization founded by <link>Richard Stallman</link> on October 4, 1985, to support the free software movement, with the organization's preference for software being distributed under copyleft (\"share alike\") terms, such as w\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Richard_Stallman\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Richard Stallman\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=28): Linux -> Unix -> Linus Torvalds -> GNU Project -> GNOME -> Xfce -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> Fedora Linux -> Red Hat Enterprise Linux -> Red Hat -> IBM -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> GNU Project -> Richard Stallman -> Free software -> GNU Project -> GNU Compiler Collection -> GNU Emacs -> Unix-like -> Linux -> Free Software Foundation -> Richard Stallman \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Richard Stallman. Your goal page is Dana Carvey.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Richard Matthew <link>Stallman</link> ( STAWL-mən; born March 16, 1953), also known by his initials, rms, is an American <link>free software</link> movement activist and programmer. He campaigns for software to be distributed in such a manner that its users have the freedom to use, study, distribute\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"New_York_City\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to New York City\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=29): Linux -> Unix -> Linus Torvalds -> GNU Project -> GNOME -> Xfce -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> Fedora Linux -> Red Hat Enterprise Linux -> Red Hat -> IBM -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> GNU Project -> Richard Stallman -> Free software -> GNU Project -> GNU Compiler Collection -> GNU Emacs -> Unix-like -> Linux -> Free Software Foundation -> Richard Stallman -> New York City \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: New York City. Your goal page is Dana Carvey.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " New York, often called New York City or <link>NYC</link>, is the most populous city in the <link>United States</link>, located at the southern tip of <link>New York State</link> on one of the world's largest natural harbors. The city comprises five boroughs, each coextensive with a respective county\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Comedy\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Comedy. This is not a valid link.\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Entertainment\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Entertainment. This is not a valid link.\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Culture\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Culture. This is not a valid link.\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Media_and_entertainment\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Media_and_entertainment. This is not a valid link.\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"History\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to History\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=30): Linux -> Unix -> Linus Torvalds -> GNU Project -> GNOME -> Xfce -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> Fedora Linux -> Red Hat Enterprise Linux -> Red Hat -> IBM -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> GNU Project -> Richard Stallman -> Free software -> GNU Project -> GNU Compiler Collection -> GNU Emacs -> Unix-like -> Linux -> Free Software Foundation -> Richard Stallman -> New York City -> History \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: History. Your goal page is Dana Carvey.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " History (derived from Ancient Greek  ἱστορία (historía) 'inquiry; knowledge acquired by investigation') is the systematic study and documentation of human past. History is an academic discipline which uses a narrative to describe, examine, question, and analyze past events, and investigate their pat\n",
                        "\n",
                        "USER: \n",
                        "What's your next step?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Historian\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Historian\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=31): Linux -> Unix -> Linus Torvalds -> GNU Project -> GNOME -> Xfce -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> Fedora Linux -> Red Hat Enterprise Linux -> Red Hat -> IBM -> Linux -> Unix-like -> Linux kernel -> Linus Torvalds -> GNU Project -> Richard Stallman -> Free software -> GNU Project -> GNU Compiler Collection -> GNU Emacs -> Unix-like -> Linux -> Free Software Foundation -> Richard Stallman -> New York City -> History -> Historian \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Historian. Your goal page is Dana Carvey.\n"
                    ]
                }
            ],
            "source": [
                "game = BaseWikiGame(\"Linux\", \"Dana Carvey\")\n",
                "agent = WikiAgent(game, model=\"gpt-4o-mini\", tools=wiki_game_tools)\n",
                "agent_loop(agent, game, 30)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 252,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Miwok by accessing links from wikipedia pages. Your current page is Drupe. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Drupe. Make sure you start by reasoning about what steps you should take to get to the article on Miwok. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Miwok has the following summary:\n",
                        "\n",
                        "[Begin Summary]\n",
                        "The Miwok (also spelled Miwuk, Mi-Wuk, or Me-Wuk) are members of four linguistically related Native American groups Indigenous to what is now Northern California, who traditionally spoke one of the Miwok languages in the Utian family. The word Miwok means people in the Miwok languages.\n",
                        "\n",
                        "\n",
                        "== Subgroups ==\n",
                        "Anthropologists commonly divide the Miwok into four geographically and culturally diverse ethnic subgroups.  These distinctions were not used among the Miwok before European contact.\n",
                        "[End Summary]\n",
                        "\n",
                        "The path you have taken so far is Drupe.\n",
                        "            \n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " In botany, a drupe (or stone <link>fruit</link>) is a type of fruit in which an outer fleshy part (exocarp, or skin, and mesocarp, or flesh) surrounds a single shell (the pip (UK), pit (US), stone, or pyrena) of hardened endocarp with a seed (kernel) inside. Drupes do not split open to release the s\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Miwok?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Flowering_plant\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Flowering plant\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=2): Drupe -> Flowering plant \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Miwok by accessing links from wikipedia pages. Your current page is Flowering plant. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Flowering plant. Make sure you start by reasoning about what steps you should take to get to the article on Miwok. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Miwok has the following summary:\n",
                        "\n",
                        "[Begin Summary]\n",
                        "The Miwok (also spelled Miwuk, Mi-Wuk, or Me-Wuk) are members of four linguistically related Native American groups Indigenous to what is now Northern California, who traditionally spoke one of the Miwok languages in the Utian family. The word Miwok means people in the Miwok languages.\n",
                        "\n",
                        "\n",
                        "== Subgroups ==\n",
                        "Anthropologists commonly divide the Miwok into four geographically and culturally diverse ethnic subgroups.  These distinctions were not used among the Miwok before European contact.\n",
                        "[End Summary]\n",
                        "\n",
                        "The path you have taken so far is Drupe -> Flowering plant.\n",
                        "            \n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Flowering <link>plant</link>s are plants that bear <link>flowers</link> and <link>fruit</link>s, and form the clade Angiospermae (), commonly called angiosperms. They include all forbs (flowering plants without a woody stem), grasses and grass-like plants, a vast majority of broad-leaved trees, shru\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Miwok?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Agriculture\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Agriculture\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=3): Drupe -> Flowering plant -> Agriculture \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Miwok by accessing links from wikipedia pages. Your current page is Agriculture. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Agriculture. Make sure you start by reasoning about what steps you should take to get to the article on Miwok. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Miwok has the following summary:\n",
                        "\n",
                        "[Begin Summary]\n",
                        "The Miwok (also spelled Miwuk, Mi-Wuk, or Me-Wuk) are members of four linguistically related Native American groups Indigenous to what is now Northern California, who traditionally spoke one of the Miwok languages in the Utian family. The word Miwok means people in the Miwok languages.\n",
                        "\n",
                        "\n",
                        "== Subgroups ==\n",
                        "Anthropologists commonly divide the Miwok into four geographically and culturally diverse ethnic subgroups.  These distinctions were not used among the Miwok before European contact.\n",
                        "[End Summary]\n",
                        "\n",
                        "The path you have taken so far is Drupe -> Flowering plant -> Agriculture.\n",
                        "            \n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Agriculture encompasses <link>crop</link> and <link>livestock</link> production, <link>aquaculture</link>, and forestry for <link>food</link> and non-food products. Agriculture was a key factor in the rise of sedentary human <link>civilization</link>, whereby <link>farming</link> of domesticated spe\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Miwok?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Indigenous_Australians\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Indigenous Australians\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=4): Drupe -> Flowering plant -> Agriculture -> Indigenous Australians \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Miwok by accessing links from wikipedia pages. Your current page is Indigenous Australians. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Indigenous Australians. Make sure you start by reasoning about what steps you should take to get to the article on Miwok. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Miwok has the following summary:\n",
                        "\n",
                        "[Begin Summary]\n",
                        "The Miwok (also spelled Miwuk, Mi-Wuk, or Me-Wuk) are members of four linguistically related Native American groups Indigenous to what is now Northern California, who traditionally spoke one of the Miwok languages in the Utian family. The word Miwok means people in the Miwok languages.\n",
                        "\n",
                        "\n",
                        "== Subgroups ==\n",
                        "Anthropologists commonly divide the Miwok into four geographically and culturally diverse ethnic subgroups.  These distinctions were not used among the Miwok before European contact.\n",
                        "[End Summary]\n",
                        "\n",
                        "The path you have taken so far is Drupe -> Flowering plant -> Agriculture -> Indigenous Australians.\n",
                        "            \n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Indigenous <link>Australians</link> are people with familial heritage from, and/or recognised membership of, the various ethnic groups living within the territory of present day <link>Australia</link>  prior to British colonisation. They consist of two distinct groups, which includes many ethnic gro\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Miwok?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Indigenous <link>Australians</link> are people with familial heritage from, and/or recognised membership of, the various ethnic groups living within the territory of present day <link>Australia</link>  prior to British colonisation. They consist of two distinct groups, which includes many ethnic gro\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Miwok?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Papuan people\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Indigenous people of New Guinea\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=5): Drupe -> Flowering plant -> Agriculture -> Indigenous Australians -> Indigenous people of New Guinea \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Miwok by accessing links from wikipedia pages. Your current page is Indigenous people of New Guinea. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Indigenous people of New Guinea. Make sure you start by reasoning about what steps you should take to get to the article on Miwok. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Miwok has the following summary:\n",
                        "\n",
                        "[Begin Summary]\n",
                        "The Miwok (also spelled Miwuk, Mi-Wuk, or Me-Wuk) are members of four linguistically related Native American groups Indigenous to what is now Northern California, who traditionally spoke one of the Miwok languages in the Utian family. The word Miwok means people in the Miwok languages.\n",
                        "\n",
                        "\n",
                        "== Subgroups ==\n",
                        "Anthropologists commonly divide the Miwok into four geographically and culturally diverse ethnic subgroups.  These distinctions were not used among the Miwok before European contact.\n",
                        "[End Summary]\n",
                        "\n",
                        "The path you have taken so far is Drupe -> Flowering plant -> Agriculture -> Indigenous Australians -> Indigenous people of New Guinea.\n",
                        "            \n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " The indigenous peoples of <link>Western New Guinea</link> in <link>Indonesia</link> and <link>Papua New Guinea</link>, commonly called Papuans, are <link>Melanesians</link>. There is genetic evidence for two major historical lineages in <link>New Guinea</link> and neighboring islands: a first wave f\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Miwok?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Australasia\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Australasia\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=6): Drupe -> Flowering plant -> Agriculture -> Indigenous Australians -> Indigenous people of New Guinea -> Australasia \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Miwok by accessing links from wikipedia pages. Your current page is Australasia. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Australasia. Make sure you start by reasoning about what steps you should take to get to the article on Miwok. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Miwok has the following summary:\n",
                        "\n",
                        "[Begin Summary]\n",
                        "The Miwok (also spelled Miwuk, Mi-Wuk, or Me-Wuk) are members of four linguistically related Native American groups Indigenous to what is now Northern California, who traditionally spoke one of the Miwok languages in the Utian family. The word Miwok means people in the Miwok languages.\n",
                        "\n",
                        "\n",
                        "== Subgroups ==\n",
                        "Anthropologists commonly divide the Miwok into four geographically and culturally diverse ethnic subgroups.  These distinctions were not used among the Miwok before European contact.\n",
                        "[End Summary]\n",
                        "\n",
                        "The path you have taken so far is Drupe -> Flowering plant -> Agriculture -> Indigenous Australians -> Indigenous people of New Guinea -> Australasia.\n",
                        "            \n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Australasia is a subregion of <link>Oceania</link>, comprising <link>Australia</link>, <link>New Zealand</link> (overlapping with <link>Polynesia</link>), and sometimes including <link>New Guinea</link> and surrounding islands (overlapping with <link>Melanesia</link>). The term is used in a number o\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Miwok?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Asia-Pacific\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Asia–Pacific\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=7): Drupe -> Flowering plant -> Agriculture -> Indigenous Australians -> Indigenous people of New Guinea -> Australasia -> Asia–Pacific \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Miwok by accessing links from wikipedia pages. Your current page is Asia–Pacific. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Asia–Pacific. Make sure you start by reasoning about what steps you should take to get to the article on Miwok. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Miwok has the following summary:\n",
                        "\n",
                        "[Begin Summary]\n",
                        "The Miwok (also spelled Miwuk, Mi-Wuk, or Me-Wuk) are members of four linguistically related Native American groups Indigenous to what is now Northern California, who traditionally spoke one of the Miwok languages in the Utian family. The word Miwok means people in the Miwok languages.\n",
                        "\n",
                        "\n",
                        "== Subgroups ==\n",
                        "Anthropologists commonly divide the Miwok into four geographically and culturally diverse ethnic subgroups.  These distinctions were not used among the Miwok before European contact.\n",
                        "[End Summary]\n",
                        "\n",
                        "The path you have taken so far is Drupe -> Flowering plant -> Agriculture -> Indigenous Australians -> Indigenous people of New Guinea -> Australasia -> Asia–Pacific.\n",
                        "            \n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " The Asia–Pacific (APAC) is the region of the world adjoining the western <link>Pacific Ocean</link>. The region's precise boundaries vary depending on context, but countries and territories in <link>Australasia</link>, <link>East Asia</link>, and <link>Southeast Asia</link> are often included. In a \n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Miwok?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"North America\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to North America\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=8): Drupe -> Flowering plant -> Agriculture -> Indigenous Australians -> Indigenous people of New Guinea -> Australasia -> Asia–Pacific -> North America \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Miwok by accessing links from wikipedia pages. Your current page is North America. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: North America. Make sure you start by reasoning about what steps you should take to get to the article on Miwok. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Miwok has the following summary:\n",
                        "\n",
                        "[Begin Summary]\n",
                        "The Miwok (also spelled Miwuk, Mi-Wuk, or Me-Wuk) are members of four linguistically related Native American groups Indigenous to what is now Northern California, who traditionally spoke one of the Miwok languages in the Utian family. The word Miwok means people in the Miwok languages.\n",
                        "\n",
                        "\n",
                        "== Subgroups ==\n",
                        "Anthropologists commonly divide the Miwok into four geographically and culturally diverse ethnic subgroups.  These distinctions were not used among the Miwok before European contact.\n",
                        "[End Summary]\n",
                        "\n",
                        "The path you have taken so far is Drupe -> Flowering plant -> Agriculture -> Indigenous Australians -> Indigenous people of New Guinea -> Australasia -> Asia–Pacific -> North America.\n",
                        "            \n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " North America is a <link>continent</link> in the Northern and <link>Western Hemisphere</link>s. <link>North America</link> is bordered to the north by the <link>Arctic Ocean</link>, to the east by the <link>Atlantic Ocean</link>, to the southeast by <link>South America</link> and the <link>Caribbean\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Miwok?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Indigenous_peoples_of_the_Americas\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Indigenous_peoples_of_the_Americas. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Indigenous_peoples_of_North_America\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Indigenous_peoples_of_North_America. This is not a valid link.\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Miwok?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " North America is a <link>continent</link> in the Northern and <link>Western Hemisphere</link>s. <link>North America</link> is bordered to the north by the <link>Arctic Ocean</link>, to the east by the <link>Atlantic Ocean</link>, to the southeast by <link>South America</link> and the <link>Caribbean\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Miwok?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Indigenous_languages_of_North_America\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Indigenous_languages_of_North_America. This is not a valid link.\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Miwok?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Pre-Columbian Americas\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Pre-Columbian Americas. This is not a valid link.\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Miwok?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " North America is a <link>continent</link> in the Northern and <link>Western Hemisphere</link>s. <link>North America</link> is bordered to the north by the <link>Arctic Ocean</link>, to the east by the <link>Atlantic Ocean</link>, to the southeast by <link>South America</link> and the <link>Caribbean\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Miwok?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"California\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to California\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Native_American\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Native_American. This is not a valid link.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\": \"Native_American_tribes_in_Northern_California\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to Native_American_tribes_in_Northern_California. This is not a valid link.\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=9): Drupe -> Flowering plant -> Agriculture -> Indigenous Australians -> Indigenous people of New Guinea -> Australasia -> Asia–Pacific -> North America -> California \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Miwok by accessing links from wikipedia pages. Your current page is California. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: California. Make sure you start by reasoning about what steps you should take to get to the article on Miwok. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Miwok has the following summary:\n",
                        "\n",
                        "[Begin Summary]\n",
                        "The Miwok (also spelled Miwuk, Mi-Wuk, or Me-Wuk) are members of four linguistically related Native American groups Indigenous to what is now Northern California, who traditionally spoke one of the Miwok languages in the Utian family. The word Miwok means people in the Miwok languages.\n",
                        "\n",
                        "\n",
                        "== Subgroups ==\n",
                        "Anthropologists commonly divide the Miwok into four geographically and culturally diverse ethnic subgroups.  These distinctions were not used among the Miwok before European contact.\n",
                        "[End Summary]\n",
                        "\n",
                        "The path you have taken so far is Drupe -> Flowering plant -> Agriculture -> Indigenous Australians -> Indigenous people of New Guinea -> Australasia -> Asia–Pacific -> North America -> California.\n",
                        "            \n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " California is a state in the <link>Western United States</link>, lying on the American Pacific Coast. It borders <link>Oregon</link> to the north, <link>Nevada</link> and <link>Arizona</link> to the east, and an international border with the Mexican state of <link>Baja California</link> to the south\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Miwok?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Indigenous_peoples_of_California\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Indigenous peoples of California\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=10): Drupe -> Flowering plant -> Agriculture -> Indigenous Australians -> Indigenous people of New Guinea -> Australasia -> Asia–Pacific -> North America -> California -> Indigenous peoples of California \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Miwok by accessing links from wikipedia pages. Your current page is Indigenous peoples of California. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Indigenous peoples of California. Make sure you start by reasoning about what steps you should take to get to the article on Miwok. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Miwok has the following summary:\n",
                        "\n",
                        "[Begin Summary]\n",
                        "The Miwok (also spelled Miwuk, Mi-Wuk, or Me-Wuk) are members of four linguistically related Native American groups Indigenous to what is now Northern California, who traditionally spoke one of the Miwok languages in the Utian family. The word Miwok means people in the Miwok languages.\n",
                        "\n",
                        "\n",
                        "== Subgroups ==\n",
                        "Anthropologists commonly divide the Miwok into four geographically and culturally diverse ethnic subgroups.  These distinctions were not used among the Miwok before European contact.\n",
                        "[End Summary]\n",
                        "\n",
                        "The path you have taken so far is Drupe -> Flowering plant -> Agriculture -> Indigenous Australians -> Indigenous people of New Guinea -> Australasia -> Asia–Pacific -> North America -> California -> Indigenous peoples of California.\n",
                        "            \n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Indigenous peoples of <link>California</link>, commonly known as Indigenous Californians or Native Californians, are a diverse group of nations and peoples that are indigenous to the geographic area within the current boundaries of California before and after European colonization. There are current\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Miwok?\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Miwok\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Miwok\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=11): Drupe -> Flowering plant -> Agriculture -> Indigenous Australians -> Indigenous people of New Guinea -> Australasia -> Asia–Pacific -> North America -> California -> Indigenous peoples of California -> Miwok \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Miwok by accessing links from wikipedia pages. Your current page is Miwok. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Miwok. Make sure you start by reasoning about what steps you should take to get to the article on Miwok. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Miwok has the following summary:\n",
                        "\n",
                        "[Begin Summary]\n",
                        "The Miwok (also spelled Miwuk, Mi-Wuk, or Me-Wuk) are members of four linguistically related Native American groups Indigenous to what is now Northern California, who traditionally spoke one of the Miwok languages in the Utian family. The word Miwok means people in the Miwok languages.\n",
                        "\n",
                        "\n",
                        "== Subgroups ==\n",
                        "Anthropologists commonly divide the Miwok into four geographically and culturally diverse ethnic subgroups.  These distinctions were not used among the Miwok before European contact.\n",
                        "[End Summary]\n",
                        "\n",
                        "The path you have taken so far is Drupe -> Flowering plant -> Agriculture -> Indigenous Australians -> Indigenous people of New Guinea -> Australasia -> Asia–Pacific -> North America -> California -> Indigenous peoples of California -> Miwok.\n",
                        "            \n",
                        "Success!\n"
                    ]
                }
            ],
            "source": [
                "game = WikiGame(\"Drupe\", \"Miwok\")\n",
                "agent = WikiAgent(game, model=\"gpt-4o-mini\", tools=wiki_game_tools)\n",
                "agent_loop(agent, game, 30)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Implement the ReAct framework\n",
                "```c\n",
                "Difficulty: 🔴🔴⚪⚪⚪\n",
                "Importance: 🔵🔵🔵⚪⚪\n",
                "\n",
                "You should spend up to 15-20 mins on this exercise.\n",
                "```\n",
                "\n",
                "Chain-of-thought prompting confers significant benefits to model performance, and you probably tried it when you messed around with prompting above. But when we're using LLMs as agents, we may want to provide a different structure to elicit reasoning. This is called the [**ReAct** framework](https://arxiv.org/abs/2210.03629); it consists of:\n",
                "\n",
                "- Getting the model to generate **Re**asoning about its current situation, and what sort of actions it should consider taking.\n",
                "\n",
                "- Then getting the model to perform an **Act**ion based on its outputted reasoning.\n",
                "\n",
                "Remember that if you're calling the model without tools, OpenAI won't automatically provide the model with a description of the tools in its system message, so we'll have to ensure that the tool descriptions are in the `system_instruction` we provide (this will lead to some redundancy when the model takes an action, but this seems to be okay). This means that from now on we will have to feed both the *task* and the *agent* the list of tools the agent can use."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 121,
            "metadata": {},
            "outputs": [],
            "source": [
                "class WikiGameReAct(WikiGame):\n",
                "    \"\"\"\n",
                "    Inherits from WikiGame and adds the ReAct framework.\n",
                "\n",
                "    Attributes:\n",
                "        starting_page (str): The title of the starting page (inherited)\n",
                "        goal_page (str): The title of the goal page (inherited)\n",
                "        current_page (WikipediaPage): The current Wikipedia page (inherited)\n",
                "        page_history (List[str]): The history of pages visited (inherited)\n",
                "\n",
                "    Methods:\n",
                "\n",
                "        get_page(title: str) -> WikipediaPage: Get a Wikipedia page object given a title (inherited)\n",
                "\n",
                "        get_page_summary(page: WikipediaPage | None = None) -> str: Get the summary of a Wikipedia page (inherited)\n",
                "\n",
                "        get_permitted_links(title: Optional[str] = None) -> list[str]: Get permitted links for the current page (inherited)\n",
                "\n",
                "        is_permitted_link(link: str) -> bool: Check if a link is permitted (inherited)\n",
                "\n",
                "        system_instruction -> dict: Generate the starting instructions for the game (inherited)\n",
                "\n",
                "        on_page_instruction -> dict: Generate instructions for the current page (inherited)\n",
                "\n",
                "        next_step_instruction -> dict: Generate instructions for the next step (inherited)\n",
                "\n",
                "        get_instructions(system: bool, on_page: bool, next_step: bool) -> str: Generate instruction messages based on the current game state (inherited)\n",
                "\n",
                "        check_win() -> bool: Check if the game has been won (inherited)\n",
                "\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(self, starting_page: str, goal_page: str, tools=None):\n",
                "        super().__init__(starting_page, goal_page)\n",
                "        self.tools = tools\n",
                "\n",
                "    @property\n",
                "    def system_instruction(self):\n",
                "        \"\"\"\n",
                "        Provided a description of the tools in the system message. When generate is called with tools this is redundant, but when generate is called without tools, this is useful.\n",
                "\n",
                "        Returns:\n",
                "            dict: The starting instructions. \"role\" is \"system\" for system messages.\n",
                "        \"\"\"\n",
                "        tool_descriptions = \"\\n\".join([tool.description[\"function\"][\"name\"] + \":\" + tool.description[\"function\"][\"description\"] for tool in self.tools])\n",
                "        return {\n",
                "            \"role\": \"system\",\n",
                "            \"content\": f\"\"\"You are a wikipedia-racing AI. Your goal is to reach {self.goal_page.title} by accessing links from wikipedia pages. Your current page is {self.current_page.title}. You have access to {str(len(self.tools))} tools, which are:\\n{tool_descriptions}\"\"\",\n",
                "        }\n",
                "\n",
                "\n",
                "class WikiAgentReAct(WikiAgent):\n",
                "    \"\"\"\n",
                "    Inherits from WikiAgent and adds the ReAct framework.\n",
                "\n",
                "    Attributes:\n",
                "        model (str): The model used for generating responses (inherited)\n",
                "        tools (List[Any]): List of tools (inherited)\n",
                "        client (OpenAI): OpenAI client for API calls (inherited)\n",
                "        task (Any): The current task being executed (inherited)\n",
                "        chat_history (List[dict]): History of interactions (inherited)\n",
                "\n",
                "    Methods:\n",
                "        get_response(use_tool: bool = True) -> ChatCompletionMessage: Get response from the model (inherited)\n",
                "\n",
                "        execute_tool_calls(message: ChatCompletionMessage) -> List[str]: Execute tool calls from the model's response (inherited)\n",
                "\n",
                "        run(with_tool: bool = True) -> bool: Run one loop of the Wikipedia agent (inherited)\n",
                "\n",
                "        update_history(message : str | ChatCompletionMessage | List[str | ChatCompletionMessage]): Update self.chat_history and self.full_chat_history with a message or list of messages. (inherited)\n",
                "\n",
                "        reset_history(): Empty self.chat_history of the agent. (inherited)\n",
                "\n",
                "        handle_tool_calls(response: ChatCompletionMessage): Handles tool_calls in the wikipedia game context. (inherited)\n",
                "\n",
                "        handle_refusal(response: ChatCompletionMessage): Handles refusals in the wikipedia game context. (inherited)\n",
                "\n",
                "        start(): A function to put the starting instructions in agent.chat_history when the agent starts a new page or starts the game. (inherited)\n",
                "\n",
                "        run(): This function runs the agent in the wikipedia game context. (inherited)\n",
                "\n",
                "\n",
                "    \"\"\"\n",
                "\n",
                "    def generate_reason(self) -> ChatCompletionMessage:\n",
                "        # Get the model to reason about the current state of the game and add the response to the messages (you may not want to give it tools for this)\n",
                "        self.chat_history.append(\n",
                "            apply_user_format(\n",
                "                \"Think carefully about your current situation and what actions you want to take to get closer to\"\n",
                "                + self.task.goal_page.title\n",
                "                + \".\"\n",
                "            )\n",
                "        )\n",
                "        response = self.get_response(use_tool=False)\n",
                "        return response\n",
                "\n",
                "    def generate_action(self) -> ChatCompletionMessage:\n",
                "        # Get the model to generate an action based on the reasoning and add the response to the messages\n",
                "        self.chat_history.append(apply_user_format(\"What action do you want to take?\"))\n",
                "        response = self.get_response()\n",
                "        return response\n",
                "\n",
                "    def generate_reason_and_action(self):\n",
                "        \"\"\"\n",
                "        Generate a reason, store this in history, then generate and return an action.\n",
                "        \"\"\"\n",
                "        reason = self.generate_reason()\n",
                "        self.update_history(apply_assistant_format(reason.content))\n",
                "        print(\"\\nModel response ('Reason'):\", reason.content)\n",
                "\n",
                "        action = self.generate_action()\n",
                "\n",
                "        return action\n",
                "\n",
                "    def run(self):\n",
                "        \"\"\"\n",
                "        Run one loop of the agent.\n",
                "\n",
                "        This function should:\n",
                "            - Generate a Reason and Action\n",
                "            - Handle the tool calls, refusals, and no tool calls in the model response\n",
                "        \"\"\"\n",
                "        response = self.generate_reason_and_action()\n",
                "\n",
                "        if response.tool_calls:\n",
                "            self.handle_tool_calls(response)\n",
                "        elif response.refusal:\n",
                "            self.handle_refusal(response)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You may have to rewrite your `agent_loop`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 122,
            "metadata": {},
            "outputs": [],
            "source": [
                "def agent_loop_ReAct(game, agent, num_loops = 10):\n",
                "    \"\"\"\n",
                "    Run the agent loop for a given number of loops with the ReAct framework.\n",
                "\n",
                "    Args:\n",
                "        agent (WikiReActAgent): The agent to run\n",
                "        game (WikiGameReAct): The game to play\n",
                "        num_loops (int): The number of loops to run\n",
                "    \"\"\"\n",
                "    agent.start()\n",
                "    for i in range(num_loops):\n",
                "        if game.check_win():\n",
                "            print(\"Success\")\n",
                "            return\n",
                "        agent.run()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Your `WikiAgent` and `WikiGame` with only improved prompting might not be able to solve \"Drupe\" → \"17th parallel north\" (or might not be able to solve it very effectively or reliably). However, your ReAct agent should be able to solve this path."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "game = WikiGame(\"Drupe\", \"17th parallel north\")\n",
                "agent = WikiAgent(task=game, tools=wiki_game_tools)\n",
                "agent_loop(agent, game, 40)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "game = WikiGameReAct(\"Drupe\", \"17th parallel north\", tools=wiki_game_tools)\n",
                "agent = WikiAgentReAct(game, model=\"gpt-4o-mini\", tools = wiki_game_tools)\n",
                "agent_loop_ReAct(game, agent,40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Implement a reflexion tool\n",
                "```c\n",
                "Difficulty: 🔴🔴🔴⚪⚪\n",
                "Importance: 🔵🔵🔵⚪⚪\n",
                "\n",
                "You should spend up to 10-15 mins on this exercise.\n",
                "```\n",
                "[Chloe comment] Reflexion should be better explained, with a diagram, not just in 1 sentence.\n",
                "\n",
                "=====================\n",
                "\n",
                "\n",
                "[This paper](https://arxiv.org/abs/2303.11366) finds better performance by LLMs on tasks when they can perform \"lookahead\" and get feedback on their plans. We will imitate this by allowing the agent to suggest candidate paths, and informing it where these paths go wrong (if they do). You'll need to add this tool to the list of tools.\n",
                "\n",
                "We don't want to provide the agent the links/content of every page when it does this lookahead, as then we'd just be reimplementing a smaller version of the game *inside the game*. Instead, we'll let the agent suggest paths without seeing any content or links, and then let it know if this path works. It's very likely that a suggested link will — at some point — not be accessible from one of the pages, but this tool will still be useful to help the agent plan."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 154,
            "metadata": {},
            "outputs": [],
            "source": [
                "class test_path_tool(Tool):\n",
                "    \"\"\"\n",
                "    Implements a tool that allows the agent to test paths from the current state of the game.\n",
                "    \"\"\"\n",
                "    \n",
                "    name = \"test_path\"\n",
                "\n",
                "    def execute(self, task: Any, path: str) -> str:\n",
                "        \"\"\"\n",
                "        Test if a given path is valid.\n",
                "\n",
                "        Args:\n",
                "            path (str): A string representing a path, e.g., \"Barack Obama -> Indonesia -> India\"\n",
                "\n",
                "        Returns:\n",
                "            str: A message indicating whether the path is valid or where it fails.\n",
                "        \"\"\"\n",
                "        path_nodes = [node.strip() for node in path.split(\"->\")]\n",
                "        \n",
                "        if not path_nodes:\n",
                "            return \"ERROR: Empty path provided.\"\n",
                "        \n",
                "        if path_nodes[0] != task.current_page.title:\n",
                "            return f\"ERROR: The path should start with the current page: {task.current_page.title}\"\n",
                "        \n",
                "        for i in range(len(path_nodes) - 1):\n",
                "            current_node = path_nodes[i]\n",
                "            next_node = path_nodes[i + 1]\n",
                "            \n",
                "            permitted_links = set(link.lower() for link in task.get_permitted_links(current_node))\n",
                "            \n",
                "            if next_node.lower() not in permitted_links:\n",
                "                return f\"This path works until {next_node}, which is not accessible from {current_node}\"\n",
                "        \n",
                "        return \"This path is valid.\"\n",
                "    \n",
                "    @property\n",
                "    def description(self):\n",
                "        return {\n",
                "            \"type\" : \"function\",\n",
                "            \"function\" : {\n",
                "                \"name\" : \"test_path\",\n",
                "                \"description\" : \"Accepts a test path string in the form \\\"current_page -> page1 -> page2 -> ... -> pageN\\\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \\\"success.\\\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\",\n",
                "                \"parameters\" : {\n",
                "                    \"type\" : \"object\",\n",
                "                    \"properties\": {\n",
                "                        \"path\" : {\n",
                "                            \"type\" : \"string\",\n",
                "                            \"description\" : \"The path you want to test, formatted as \\\" current_page -> page1 -> page2 -> ... -> pageN\\\".\"\n",
                "                        },\n",
                "                    },\n",
                "                    \"required\" : [\"path\"]\n",
                "                }\n",
                "            }\n",
                "        }\n",
                "test_path_tool_inst = test_path_tool()\n",
                "wiki_game_tools = [get_content_tool_inst, move_page_tool_inst, test_path_tool_inst]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 165,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Central Vietnam by accessing links from wikipedia pages. Your current page is William Pitt the Younger. You have access to 4 tools, which are:\n",
                        "get_content:Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select to move to will be wrapped in <link></link> tags.\n",
                        "move_page:Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n",
                        "test_path:Accepts a test path string in the form \"current_page -> page1 -> page2 -> ... -> pageN\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \"success.\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\n",
                        "get_page_summary:Get the summary of a wikipedia page you are considering moving to, to the last full stop within the first 500 characters. The page needs to be accessible via a link from the current page. Anything which corresponds to a link you can select will be wrapped in <link></link> tags. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: William Pitt the Younger. Make sure you start by reasoning about what steps you should take to get to the article on Central Vietnam. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Central Vietnam has the following summary:\n",
                        "[Begin Summary]\n",
                        "Central Vietnam (Vietnamese: Trung Bộ or miền Trung), also known as Middle Vietnam or The Middle, formerly known as Trung Phần by South Vietnam, Trung Kỳ and Annam under French Indochina, is one of the three geographical regions within Vietnam.\n",
                        "The name Trung Bộ was used by the emperor Bảo Đại when he established administrative level higher than Province in 1945, instead of the Trung Kỳ which recalled the French occupation.\n",
                        "[End Summary]\n",
                        "\n",
                        "\n",
                        "            \n",
                        "        The pages you've visited so far are: William Pitt the Younger\n",
                        "\n",
                        " Make sure to use the test_path tool liberally to explore your options! Use it at least 3 times before attempting to move page! Use it to test very long-horizon candidate paths (e.g. many more than just one link)\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Central Vietnam by accessing links from wikipedia pages. Your current page is William Pitt the Younger. You have access to 4 tools, which are:\n",
                        "get_content:Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select to move to will be wrapped in <link></link> tags.\n",
                        "move_page:Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n",
                        "test_path:Accepts a test path string in the form \"current_page -> page1 -> page2 -> ... -> pageN\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \"success.\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\n",
                        "get_page_summary:Get the summary of a wikipedia page you are considering moving to, to the last full stop within the first 500 characters. The page needs to be accessible via a link from the current page. Anything which corresponds to a link you can select will be wrapped in <link></link> tags. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: William Pitt the Younger. Make sure you start by reasoning about what steps you should take to get to the article on Central Vietnam. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Central Vietnam has the following summary:\n",
                        "[Begin Summary]\n",
                        "Central Vietnam (Vietnamese: Trung Bộ or miền Trung), also known as Middle Vietnam or The Middle, formerly known as Trung Phần by South Vietnam, Trung Kỳ and Annam under French Indochina, is one of the three geographical regions within Vietnam.\n",
                        "The name Trung Bộ was used by the emperor Bảo Đại when he established administrative level higher than Province in 1945, instead of the Trung Kỳ which recalled the French occupation.\n",
                        "[End Summary]\n",
                        "\n",
                        "\n",
                        "            \n",
                        "        The pages you've visited so far are: William Pitt the Younger\n",
                        "\n",
                        " Make sure to use the test_path tool liberally to explore your options! Use it at least 3 times before attempting to move page! Use it to test very long-horizon candidate paths (e.g. many more than just one link)\n",
                        "\n",
                        "Model response ('Reason'): To reach the article on Central Vietnam from \"William Pitt the Younger,\" I need to think about the geographical and historical context, as Central Vietnam relates to Vietnam, which may be covered in pages related to Asia or countries.\n",
                        "\n",
                        "First, I will explore the links available on the \"William Pitt the Younger\" page to identify pages that could lead towards topics connected to Vietnam or Asian geography.\n",
                        "\n",
                        "After gathering content, I can plan my next moves accordingly. I will use the `get_content` tool initially to find accessible links. Let's start by retrieving the content of the current page.\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[165], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m game \u001b[38;5;241m=\u001b[39m WikiGameHistory(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWilliam Pitt the Younger\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCentral Vietnam\u001b[39m\u001b[38;5;124m\"\u001b[39m, tools \u001b[38;5;241m=\u001b[39m wiki_game_tools)\n\u001b[0;32m      2\u001b[0m agent \u001b[38;5;241m=\u001b[39m WikiAgentReAct(game, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m, tools \u001b[38;5;241m=\u001b[39m wiki_game_tools)\n\u001b[1;32m----> 3\u001b[0m \u001b[43magent_loop_ReAct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m,\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n",
                        "Cell \u001b[1;32mIn[122], line 15\u001b[0m, in \u001b[0;36magent_loop_ReAct\u001b[1;34m(game, agent, num_loops)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "Cell \u001b[1;32mIn[121], line 123\u001b[0m, in \u001b[0;36mWikiAgentReAct.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    Run one loop of the agent.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m        - Handle the tool calls, refusals, and no tool calls in the model response\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reason_and_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtool_calls:\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_tool_calls(response)\n",
                        "Cell \u001b[1;32mIn[121], line 111\u001b[0m, in \u001b[0;36mWikiAgentReAct.generate_reason_and_action\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_history(apply_assistant_format(reason\u001b[38;5;241m.\u001b[39mcontent))\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel response (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReason\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m):\u001b[39m\u001b[38;5;124m\"\u001b[39m, reason\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m--> 111\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\n",
                        "Cell \u001b[1;32mIn[121], line 100\u001b[0m, in \u001b[0;36mWikiAgentReAct.generate_action\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_action\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletionMessage:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# Get the model to generate an action based on the reasoning and add the response to the messages\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_history\u001b[38;5;241m.\u001b[39mappend(apply_user_format(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat action do you want to take?\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m--> 100\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
                        "File \u001b[1;32mc:\\Users\\styme\\OneDrive\\Documents\\AI STUFF\\Model Written Evals\\Code Replication\\ARENA_evals\\curriculum\\utils.py:74\u001b[0m, in \u001b[0;36mretry_with_exponential_backoff.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(retries):\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrate_limit_exceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
                        "Cell \u001b[1;32mIn[57], line 26\u001b[0m, in \u001b[0;36mSimpleAgent.get_response\u001b[1;34m(self, use_tool)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;129m@retry_with_exponential_backoff\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, use_tool: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletionMessage:\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m    Get the response from the model via an API call, with the option of tool calling.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m        ChatCompletionMessage: The response from the model\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_tool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_tool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\openai\\_utils\\_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\openai\\resources\\chat\\completions.py:643\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    641\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    642\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\openai\\_base_client.py:1250\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1238\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1245\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1246\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1247\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1248\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1249\u001b[0m     )\n\u001b[1;32m-> 1250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\openai\\_base_client.py:931\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    924\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    929\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    930\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 931\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\openai\\_base_client.py:962\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    959\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 962\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    963\u001b[0m         request,\n\u001b[0;32m    964\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    968\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[0;32m    910\u001b[0m )\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\httpx\\_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1012\u001b[0m     )\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\httpx\\_transports\\default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    231\u001b[0m )\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    242\u001b[0m )\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\httpcore\\_sync\\http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\httpcore\\_sync\\http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    107\u001b[0m     (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m         trailing_data,\n\u001b[1;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m         http_version,\n\u001b[0;32m    116\u001b[0m         status,\n\u001b[0;32m    117\u001b[0m         reason_phrase,\n\u001b[0;32m    118\u001b[0m         headers,\n\u001b[0;32m    119\u001b[0m     )\n\u001b[0;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\httpcore\\_sync\\http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "game = WikiGameHistory(\"William Pitt the Younger\", \"Central Vietnam\", tools = wiki_game_tools)\n",
                "agent = WikiAgentReAct(game, model=\"gpt-4o-mini\", tools = wiki_game_tools)\n",
                "agent_loop_ReAct(game,agent, 40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<details><summary>Help: My agent isn't using the <code>test_path</code> tool</summary>\n",
                "\n",
                "If your agent isn't using the test path tool, you may want to go back and modify your prompting. One way you could do this is to schedule a prompt to tell the agent to use the `test_path` tool if it hasn't used it in its last N tool calls. Alternatively, you could just include in every `on_page_instruction` a prompt indicating that the agent should use this tool.\n",
                "\n",
                "</details>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Let the LLM see its entire chat history\n",
                "```c\n",
                "Difficulty: 🔴🔴⚪⚪⚪\n",
                "Importance: 🔵🔵⚪⚪⚪\n",
                "```\n",
                "\n",
                "You may have noticed that the agent performs significantly worse as a result of the fact that we decided to reset the chat history every time the agent encounters a new page. It often comes up with plans and doesn't follow through on them. We can fix this issue by letting the agent see the entirety of its chat history.\n",
                "\n",
                "What we have to overcome is the context window considerations, specifically with regards to the length of wikipedia pages. However, we can fix these issues by resetting the outputs of the `get_content` function each time the agent moves to a new page, instead of resetting the entire chat history.\n",
                "\n",
                "We'll modify the reset function in the `WikiAgentReAct` class to accomplish this."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 188,
            "metadata": {},
            "outputs": [],
            "source": [
                "class WikiAgentChatHistory(WikiAgentReAct):\n",
                "    \"\"\"\n",
                "    Inherits from WikiAgentReAct and adds the ability to store and retrieve chat history.\n",
                "\n",
                "    Attributes:\n",
                "        model (str): The model used for generating responses (inherited)\n",
                "        tools (List[Any]): List of tools (inherited)\n",
                "        client (OpenAI): OpenAI client for API calls (inherited)\n",
                "        task (Any): The current task being executed (inherited)\n",
                "        chat_history (List[dict]): History of interactions (inherited)\n",
                "        full_chat_history (List[dict]): Full history of interactions\n",
                "\n",
                "    Methods:\n",
                "        get_response(use_tool: bool = True) -> ChatCompletionMessage: Get response from the model (inherited)\n",
                "\n",
                "        execute_tool_calls(message: ChatCompletionMessage) -> List[str]: Execute tool calls from the model's response (inherited)\n",
                "\n",
                "        run(with_tool: bool = True) -> bool: Run one loop of the Wikipedia agent (inherited)\n",
                "\n",
                "        update_history(message : str | ChatCompletionMessage | List[str | ChatCompletionMessage]): Update self.chat_history and self.full_chat_history with a message or list of messages. (inherited)\n",
                "\n",
                "        reset_history(): Empty self.chat_history of the agent. (modified below)\n",
                "\n",
                "        handle_tool_calls(response: ChatCompletionMessage): Handles tool_calls in the wikipedia game context. (inherited)\n",
                "\n",
                "        handle_refusal(response: ChatCompletionMessage): Handles refusals in the wikipedia game context. (inherited)\n",
                "\n",
                "        start(): A function to put the starting instructions in agent.chat_history when the agent starts a new page or starts the game. (inherited)\n",
                "\n",
                "        run(): This function runs the agent in the wikipedia game context. (inherited)\n",
                "\n",
                "        store_chat_history(): Store the current chat history in the full chat history.\n",
                "\n",
                "        retrieve_chat_history(): Retrieve the full chat history.\n",
                "    \"\"\"\n",
                "    def reset_history(self):\n",
                "        \"\"\"\n",
                "        Replace the output of get_content tool with an indication that wikipedia content was output when the agent moves to a new page\n",
                "        \"\"\"\n",
                "        for message in self.chat_history:\n",
                "            if isinstance(message, dict):\n",
                "                if message[\"role\"] == \"tool\" and message[\"name\"] == \"get_content\" and message[\"content\"] != \"Wikipedia content was output here.\":\n",
                "                    message[\"content\"] = \"Wikipedia content was output here.\"\n",
                "                else:\n",
                "                    pass\n",
                "            else:\n",
                "                pass\n",
                "                     \n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 189,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach 17th parallel north by accessing links from wikipedia pages. Your current page is Drupe. You have access to 4 tools, which are:\n",
                        "get_content:Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select to move to will be wrapped in <link></link> tags.\n",
                        "move_page:Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n",
                        "test_path:Accepts a test path string in the form \"current_page -> page1 -> page2 -> ... -> pageN\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \"success.\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\n",
                        "get_page_content:Get all the content for any wikipedia page. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Drupe. Make sure you start by reasoning about what steps you should take to get to the article on 17th parallel north. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, 17th parallel north has the following summary: \n",
                        "            \n",
                        "            [Begin Summary]\n",
                        "            The 17th parallel north is a circle of latitude that is 17 degrees north of the Earth's equatorial plane. It crosses Africa, Asia, the Indian Ocean, the Pacific Ocean, Central America, the Caribbean and the Atlantic Ocean.\n",
                        "The parallel is particularly significant in the history of Vietnam (see below).\n",
                        "At this latitude the sun is visible for 13 hours, 9 minutes during the summer solstice and 11 hours, 7 minutes during the winter solstice.\n",
                        "            [End Summary]\n",
                        "            \n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach 17th parallel north by accessing links from wikipedia pages. Your current page is Drupe. You have access to 4 tools, which are:\n",
                        "get_content:Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select to move to will be wrapped in <link></link> tags.\n",
                        "move_page:Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n",
                        "test_path:Accepts a test path string in the form \"current_page -> page1 -> page2 -> ... -> pageN\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \"success.\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\n",
                        "get_page_content:Get all the content for any wikipedia page. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Drupe. Make sure you start by reasoning about what steps you should take to get to the article on 17th parallel north. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, 17th parallel north has the following summary: \n",
                        "            \n",
                        "            [Begin Summary]\n",
                        "            The 17th parallel north is a circle of latitude that is 17 degrees north of the Earth's equatorial plane. It crosses Africa, Asia, the Indian Ocean, the Pacific Ocean, Central America, the Caribbean and the Atlantic Ocean.\n",
                        "The parallel is particularly significant in the history of Vietnam (see below).\n",
                        "At this latitude the sun is visible for 13 hours, 9 minutes during the summer solstice and 11 hours, 7 minutes during the winter solstice.\n",
                        "            [End Summary]\n",
                        "            \n",
                        "\n",
                        "Model response ('Reason'): To reach the page on \"17th parallel north,\" I should consider the possible connections that could lead me from the current page \"Drupe\". The \"Drupe\" page is focused on fruit and plant biology, and it might not directly link to geographic concepts. However, since \"17th parallel north\" pertains to geographical latitude, I may need to look for links related to geography, climate, or a specific region intersecting this parallel (such as Vietnam, as noted in the summary).\n",
                        "\n",
                        "### Initial Approach:\n",
                        "1. **Check for Geography-Related Links**: First, I will search the content of the \"Drupe\" page for any links related to geography, regions, or notable climates.\n",
                        "2. **Potential Related Terms**: Research anything that connects to latitude, longitude, Earth, equator, or major geographic regions that could cross the 17th parallel north.\n",
                        "3. **Refine Strategy Based on Links**: Based on the available links on the \"Drupe\" page, I plan to navigate to a related page that could potentially lead to geographic concepts.\n",
                        "\n",
                        "Let me now gather the content of the \"Drupe\" page to identify useful links.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " In botany, a drupe (or stone <link>fruit</link>) is a type of fruit in which an outer fleshy part (exocarp, or skin, and mesocarp, or flesh) surrounds a single shell (the pip (UK), pit (US), stone, or pyrena) of hardened endocarp with a seed (kernel) inside. Drupes do not split open to release the s\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to 17th parallel north?\n",
                        "\n",
                        "Model response ('Reason'): Upon reviewing the content of the \"Drupe\" page, the following links are present that may lead to relevant concepts for navigating towards \"17th parallel north\":\n",
                        "\n",
                        "1. **Flowering plant**: This could potentially lead to environmental or geographical discussions but may not be directly related to latitude.\n",
                        "2. **Prunus**: This is a genus that includes many drupe-producing plants, but again, it is unlikely to lead directly towards latitude or geography.\n",
                        "3. **Hickory**: This might also be related to trees, which may not be beneficial for our navigation.\n",
                        "4. **Pome**: This is another type of fruit but unlikely to lead us toward geography.\n",
                        "\n",
                        "Given the lack of strong geographical terms in the links provided, my best option would be to move to the **\"Flowering plant\"** page. This could ultimately provide a broader connection to ecological regions and possibly lead to geographic discussions, including notable places that cross the 17th parallel north.\n",
                        "\n",
                        "Therefore, I’ll move to the \"Flowering plant\" page to see if it can directly or indirectly connect to geographical concepts more related to the 17th parallel north. \n",
                        "\n",
                        "### Next Step:\n",
                        "I will now execute the move to the \"Flowering plant\" page.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Flowering_plant\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Flowering plant\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=2): Drupe -> Flowering plant \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach 17th parallel north by accessing links from wikipedia pages. Your current page is Flowering plant. You have access to 4 tools, which are:\n",
                        "get_content:Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select to move to will be wrapped in <link></link> tags.\n",
                        "move_page:Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n",
                        "test_path:Accepts a test path string in the form \"current_page -> page1 -> page2 -> ... -> pageN\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \"success.\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\n",
                        "get_page_content:Get all the content for any wikipedia page. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Flowering plant. Make sure you start by reasoning about what steps you should take to get to the article on 17th parallel north. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, 17th parallel north has the following summary: \n",
                        "            \n",
                        "            [Begin Summary]\n",
                        "            The 17th parallel north is a circle of latitude that is 17 degrees north of the Earth's equatorial plane. It crosses Africa, Asia, the Indian Ocean, the Pacific Ocean, Central America, the Caribbean and the Atlantic Ocean.\n",
                        "The parallel is particularly significant in the history of Vietnam (see below).\n",
                        "At this latitude the sun is visible for 13 hours, 9 minutes during the summer solstice and 11 hours, 7 minutes during the winter solstice.\n",
                        "            [End Summary]\n",
                        "            \n",
                        "\n",
                        "Model response ('Reason'): Now that I'm on the \"Flowering plant\" page, I need to identify any links or concepts that could guide me toward geographic information, particularly regarding latitude and the 17th parallel north. \n",
                        "\n",
                        "### Possible Connections:\n",
                        "1. **Ecology**: Flowering plants may have ecological distributions that could touch upon regions along the 17th parallel. This could lead to climate or geography-related pages.\n",
                        "2. **Geography**: There might be links discussing the habitats or geographic distribution of flowering plants that could reference the equator or latitudes.\n",
                        "\n",
                        "### Next Steps:\n",
                        "1. **Look for Links**: I need to check the links on the \"Flowering plant\" page to see if there are any direct references to geography, ecology, or specific regions.\n",
                        "2. **Identify Key Areas**: If the page discusses areas where certain flowering plants are prominent and these areas intersect with the 17th parallel north, this would be relevant.\n",
                        "\n",
                        "### Action:\n",
                        "I will now gather the content of the \"Flowering plant\" page to analyze the links available for further navigation toward 17th parallel north.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Flowering <link>plant</link>s are plants that bear <link>flowers</link> and <link>fruit</link>s, and form the clade Angiospermae (), commonly called angiosperms. They include all forbs (flowering plants without a woody stem), grasses and grass-like plants, a vast majority of broad-leaved trees, shru\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to 17th parallel north?\n",
                        "\n",
                        "Model response ('Reason'): I have gathered the content of the \"Flowering plant\" page, which includes information about the diversity and significance of flowering plants (angiosperms). However, the geographical connections are still not direct.\n",
                        "\n",
                        "### Links and Potential Connections:\n",
                        "1. **Geographic Distribution**: The page discusses angiosperms' ecological diversity and adaptability to various habitats, which can relate to latitude. However, it doesn't seem to have direct links to geographic concepts or regions that intersect with the 17th parallel north.\n",
                        "\n",
                        "2. **Human Interaction**: There are mentions of agriculture and crops like rice, maize, and wheat. These crops are significant in various regions, especially in climates that might align with the 17th parallel, such as Southeast Asia.\n",
                        "\n",
                        "### Next Steps:\n",
                        "To find a better route toward \"17th parallel north,\" it would be beneficial to explore links related to agriculture, especially **Rice**, as rice cultivation is prevalent in countries along the 17th parallel (e.g., Vietnam). \n",
                        "\n",
                        "### Action:\n",
                        "I will move to the **\"Rice\"** page to explore its significance and possibly draw connections to regions along the 17th parallel north, potentially including Vietnam, which is specifically mentioned in the summary of the target article. \n",
                        "\n",
                        "Let's move to the \"Rice\" page.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Rice\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Rice\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=3): Drupe -> Flowering plant -> Rice \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach 17th parallel north by accessing links from wikipedia pages. Your current page is Rice. You have access to 4 tools, which are:\n",
                        "get_content:Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select to move to will be wrapped in <link></link> tags.\n",
                        "move_page:Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n",
                        "test_path:Accepts a test path string in the form \"current_page -> page1 -> page2 -> ... -> pageN\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \"success.\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\n",
                        "get_page_content:Get all the content for any wikipedia page. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Rice. Make sure you start by reasoning about what steps you should take to get to the article on 17th parallel north. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, 17th parallel north has the following summary: \n",
                        "            \n",
                        "            [Begin Summary]\n",
                        "            The 17th parallel north is a circle of latitude that is 17 degrees north of the Earth's equatorial plane. It crosses Africa, Asia, the Indian Ocean, the Pacific Ocean, Central America, the Caribbean and the Atlantic Ocean.\n",
                        "The parallel is particularly significant in the history of Vietnam (see below).\n",
                        "At this latitude the sun is visible for 13 hours, 9 minutes during the summer solstice and 11 hours, 7 minutes during the winter solstice.\n",
                        "            [End Summary]\n",
                        "            \n",
                        "\n",
                        "Model response ('Reason'): I am currently on the \"Rice\" page, which is relevant because rice is a significant crop in regions along the 17th parallel north, particularly in Southeast Asia, including Vietnam. \n",
                        "\n",
                        "### Potential Connections:\n",
                        "1. **Geographical Context**: The page likely discusses the geographical areas where rice is grown, which may directly relate to the regions that fall along the 17th parallel north.\n",
                        "2. **Agricultural Impact**: There could be information on how the geography and climate impact rice cultivation, providing context for areas along this specific latitude.\n",
                        "\n",
                        "### Next Steps:\n",
                        "1. **Look for Geographic Links**: I will focus on identifying links that discuss the regions, ecosystems, or countries that produce rice. This could lead me to a geographical article that intersects with the 17th parallel.\n",
                        "2. **Check for Vietnam**: Since Vietnam is explicitly mentioned in the summary about the 17th parallel north, I will check if there are any links or sections discussing Vietnam or its climate, geography, or agricultural practices in connection to rice.\n",
                        "\n",
                        "### Action:\n",
                        "I will now gather the content of the \"Rice\" page to analyze both the direct information provided and to see what links are available for further navigation. This will help in determining the next step toward reaching the \"17th parallel north.\"\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Rice is a cereal grain and in its domesticated form is the staple food of over half of the world's population, particularly in <link>Asia</link> and <link>Africa</link>. Rice is the seed of the grass species <link>Oryza sativa</link> (Asian rice)—or, much less commonly, <link>Oryza glaberrima</link>\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to 17th parallel north?\n",
                        "\n",
                        "Model response ('Reason'): Now that I am on the \"Rice\" page and have gathered substantial information, it is clear that rice is a major crop in several countries along the 17th parallel north, specifically Vietnam, as noted in the content. This suggests that this page is potentially relevant for navigating towards the \"17th parallel north\" article.\n",
                        "\n",
                        "### Key Insights from the \"Rice\" Page:\n",
                        "1. **Vietnam**: It mentions that Vietnam is one of the major rice producers, which connects directly to the significance of the 17th parallel north, as Vietnam is located close to this latitude.\n",
                        "2. **Geographical Impact**: The cultivation practices and environmental conditions for growing rice can imply regional climates that may relate to latitudes like the 17th parallel north.\n",
                        "\n",
                        "### Next Steps:\n",
                        "1. **Look for Links**: I should look for specific links on the \"Rice\" page that may lead to articles about Vietnam or related geographical concepts.\n",
                        "2. **Potential Relevant Terms**: Specifically target any links that could mention Vietnam, Southeast Asia, or geographical regions that discuss the 17th parallel north.\n",
                        "\n",
                        "### Actions:\n",
                        "I will check for links within the \"Rice\" content that might directly or indirectly lead to the \"17th parallel north\" article. If I see any link related to **Vietnam** or **Southeast Asia**, I will move to that page, as it may provide relevant information connecting us to the target latitude. \n",
                        "\n",
                        "Let me examine the links and see what I can access next. If necessary, I can continue focusing on the connections that tie back to the 17th parallel. \n",
                        "\n",
                        "### Action:\n",
                        "I will check the links on the \"Rice\" page right now.\n"
                    ]
                },
                {
                    "ename": "TypeError",
                    "evalue": "get_page_content.execute() missing 1 required positional argument: 'page_title'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[189], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m game \u001b[38;5;241m=\u001b[39m WikiGameReAct(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDrupe\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m17th parallel north\u001b[39m\u001b[38;5;124m\"\u001b[39m, tools\u001b[38;5;241m=\u001b[39mwiki_game_tools)\n\u001b[0;32m      2\u001b[0m agent \u001b[38;5;241m=\u001b[39m WikiAgentChatHistory(game, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m, tools \u001b[38;5;241m=\u001b[39m wiki_game_tools)\n\u001b[1;32m----> 3\u001b[0m \u001b[43magent_loop_ReAct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n",
                        "Cell \u001b[1;32mIn[122], line 15\u001b[0m, in \u001b[0;36magent_loop_ReAct\u001b[1;34m(game, agent, num_loops)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "Cell \u001b[1;32mIn[121], line 126\u001b[0m, in \u001b[0;36mWikiAgentReAct.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_reason_and_action()\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtool_calls:\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_tool_calls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mrefusal:\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_refusal(response)\n",
                        "Cell \u001b[1;32mIn[118], line 79\u001b[0m, in \u001b[0;36mWikiAgent.handle_tool_calls\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_history(response)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Execute the tool calls\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m tool_responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_tool_calls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Add tool calls and responses to the history\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tool_call, tool_response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(response\u001b[38;5;241m.\u001b[39mtool_calls, tool_responses):\n",
                        "Cell \u001b[1;32mIn[57], line 54\u001b[0m, in \u001b[0;36mSimpleAgent.execute_tool_calls\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m     50\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m     51\u001b[0m         (tool \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools \u001b[38;5;28;01mif\u001b[39;00m tool\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m tool_call\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m     52\u001b[0m     )\n\u001b[0;32m     53\u001b[0m     arguments \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(tool_call\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39marguments)\n\u001b[1;32m---> 54\u001b[0m     tool_response \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39marguments, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask)\n\u001b[0;32m     55\u001b[0m     tool_responses\u001b[38;5;241m.\u001b[39mappend(tool_response)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tool_responses\n",
                        "\u001b[1;31mTypeError\u001b[0m: get_page_content.execute() missing 1 required positional argument: 'page_title'"
                    ]
                }
            ],
            "source": [
                "game = WikiGameReAct(\"Drupe\", \"17th parallel north\", tools=wiki_game_tools)\n",
                "agent = WikiAgentChatHistory(game, model=\"gpt-4o-mini\", tools = wiki_game_tools)\n",
                "agent_loop_ReAct(game, agent, 40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Tool use"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[CHLOE COMMENT] This should be put into \"Bonus\" section, where people just play around, and we give some bullet suggestions of things to try.\n",
                "\n",
                "==============\n",
                "\n",
                "We can also give the agent additional tools that may be useful for the wikipediaGame task, or more general tooling methods. \n",
                "\n",
                "\n",
                "\n",
                "**[JAMES COMMENT]** I still need to figure out what to say about tool use. If you have any ideas then open to suggestions :) Lilian Weng did a little \"humans use tools\" and so do some animals thing. A cute animal pic might actually go over quite well here IMO.\n",
                "\n",
                "\n",
                "\n",
                "\n",
                " but if you give the agent too many tools (especially with poor descriptions), then performance can often suffer. This happens most prominently when using more than 5-10 tools."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Implement a page summary tool\n",
                "```c\n",
                "Difficulty:🔴🔴⚪⚪⚪\n",
                "Importance:🔵🔵⚪⚪⚪\n",
                "\n",
                "You should spend up to 10-15 mins on this exercise.\n",
                "```\n",
                "\n",
                "Implement a tool that allows an agent to get a summary of an accessible page. This imitates wikipedia's native 'hover summary' tool.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 166,
            "metadata": {},
            "outputs": [],
            "source": [
                "class get_accessible_page_summary_tool(Tool):\n",
                "    \"\"\"\n",
                "    Implements a tool that allows the agent to get the summary of a Wikipedia page (you should use the get_page_summary function from the agent class)\n",
                "    \"\"\"\n",
                "\n",
                "    name = \"get_accessible_page_summary\"\n",
                "\n",
                "    @staticmethod\n",
                "    def get_page_summary(task: Any, page_title: str) -> str:\n",
                "        \"\"\"\n",
                "        Get summary of a wikipedia page, to the last full stop within the first 500 characters. This is used to give a brief overview of the page to the agent.\n",
                "\n",
                "        Args:\n",
                "            page (str): The Wikipedia page title.\n",
                "            task (Any): The current task object.\n",
                "\n",
                "        Returns:\n",
                "            str: The summary of the Wikipedia page.\n",
                "        \"\"\"\n",
                "\n",
                "        page = task.get_page(page_title)\n",
                "        if page in task.get_permitted_links():\n",
                "            summary = page.content[:500]\n",
                "            last_period_index = summary.rfind(\".\")\n",
                "            return (\n",
                "                summary[: last_period_index + 1] if last_period_index != -1 else summary\n",
                "            )\n",
                "        else:\n",
                "            return \"This page is not accessible from the current page.\"\n",
                "\n",
                "    @property\n",
                "    def description(self):\n",
                "        \"\"\"\n",
                "        Provides the description of the get_page_summary tool\n",
                "\n",
                "        Returns:\n",
                "            dict: The description of the tool for the API\n",
                "        \"\"\"\n",
                "        return {\n",
                "            \"type\": \"function\",\n",
                "            \"function\": {\n",
                "                \"name\": self.name,\n",
                "                \"description\": \"Get the summary of a wikipedia page you are considering moving to, to the last full stop within the first 500 characters. The page needs to be accessible via a link from the current page. Anything which corresponds to a link you can select will be wrapped in <link></link> tags.\",\n",
                "                \"parameters\": {\n",
                "                    \"type\": \"object\",\n",
                "                    \"properties\": {\n",
                "                        \"page_title\": {\n",
                "                            \"type\": \"object\",\n",
                "                            \"description\": \"The wikipedia page you want to get the summary of.\",\n",
                "                        }\n",
                "                    },\n",
                "                    \"required\": [\"page_title\"],\n",
                "                },\n",
                "            },\n",
                "        }\n",
                "\n",
                "\n",
                "get_accessible_page_summary_tool_inst = get_accessible_page_summary_tool()\n",
                "wiki_game_tools = [get_content_tool_inst, move_page_tool_inst, test_path_tool_inst, get_accessible_page_summary_tool_inst]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 167,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Central Vietnam by accessing links from wikipedia pages. Your current page is William Pitt the Younger. You have access to 4 tools, which are:\n",
                        "get_content:Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select to move to will be wrapped in <link></link> tags.\n",
                        "move_page:Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n",
                        "test_path:Accepts a test path string in the form \"current_page -> page1 -> page2 -> ... -> pageN\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \"success.\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\n",
                        "get_page_summary:Get the summary of a wikipedia page you are considering moving to, to the last full stop within the first 500 characters. The page needs to be accessible via a link from the current page. Anything which corresponds to a link you can select will be wrapped in <link></link> tags. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: William Pitt the Younger. Make sure you start by reasoning about what steps you should take to get to the article on Central Vietnam. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Central Vietnam has the following summary:\n",
                        "[Begin Summary]\n",
                        "Central Vietnam (Vietnamese: Trung Bộ or miền Trung), also known as Middle Vietnam or The Middle, formerly known as Trung Phần by South Vietnam, Trung Kỳ and Annam under French Indochina, is one of the three geographical regions within Vietnam.\n",
                        "The name Trung Bộ was used by the emperor Bảo Đại when he established administrative level higher than Province in 1945, instead of the Trung Kỳ which recalled the French occupation.\n",
                        "[End Summary]\n",
                        "\n",
                        "\n",
                        "            \n",
                        "        The pages you've visited so far are: William Pitt the Younger\n",
                        "\n",
                        " Make sure to use the test_path tool liberally to explore your options! Use it at least 3 times before attempting to move page! Use it to test very long-horizon candidate paths (e.g. many more than just one link)\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[167], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m agent \u001b[38;5;241m=\u001b[39m WikiAgentReAct(game, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m, tools \u001b[38;5;241m=\u001b[39m wiki_game_tools)\n\u001b[0;32m      3\u001b[0m game \u001b[38;5;241m=\u001b[39m WikiGameHistory(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWilliam Pitt the Younger\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCentral Vietnam\u001b[39m\u001b[38;5;124m\"\u001b[39m, tools \u001b[38;5;241m=\u001b[39m wiki_game_tools)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVietnam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
                        "Cell \u001b[1;32mIn[69], line 12\u001b[0m, in \u001b[0;36mget_content\u001b[1;34m(page)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mGet the content of a Wikipedia page with links wrapped with <link></link> tags.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m    str: The content of the page with links wrapped with tags.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m content \u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m---> 12\u001b[0m permitted_links \u001b[38;5;241m=\u001b[39m \u001b[43mget_permitted_links\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(permitted_links, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     14\u001b[0m     content \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"(\\s|[,.)!?;:'\"])(\"\"\"\u001b[39;00m \u001b[38;5;241m+\u001b[39m re\u001b[38;5;241m.\u001b[39mescape(word) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m)(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms|[,.)!?;:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m])\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1<link>\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2</link>\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m         flags\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mIGNORECASE,\n\u001b[0;32m     20\u001b[0m     )\n",
                        "Cell \u001b[1;32mIn[68], line 12\u001b[0m, in \u001b[0;36mget_permitted_links\u001b[1;34m(current_page)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_permitted_links\u001b[39m(current_page: WikipediaPage) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Get \"permitted\" links (i.e. links that are in the content of the page) from a Wikipedia page.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     all_links \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent_page\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinks\u001b[49m\n\u001b[0;32m     13\u001b[0m     content \u001b[38;5;241m=\u001b[39m current_page\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     14\u001b[0m     permitted_links \u001b[38;5;241m=\u001b[39m [link \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m all_links \u001b[38;5;28;01mif\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m content]\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\wikipedia\\wikipedia.py:607\u001b[0m, in \u001b[0;36mWikipediaPage.links\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;124;03mList of titles of Wikipedia page links on a page.\u001b[39;00m\n\u001b[0;32m    602\u001b[0m \n\u001b[0;32m    603\u001b[0m \u001b[38;5;124;03m.. note:: Only includes articles from namespace 0, meaning no Category, User talk, or other meta-Wikipedia pages.\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_links\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 607\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_links \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    608\u001b[0m     link[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__continued_query({\n\u001b[0;32m    610\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprop\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinks\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    611\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplnamespace\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    612\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpllimit\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    613\u001b[0m     })\n\u001b[0;32m    614\u001b[0m   ]\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_links\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\wikipedia\\wikipedia.py:607\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;124;03mList of titles of Wikipedia page links on a page.\u001b[39;00m\n\u001b[0;32m    602\u001b[0m \n\u001b[0;32m    603\u001b[0m \u001b[38;5;124;03m.. note:: Only includes articles from namespace 0, meaning no Category, User talk, or other meta-Wikipedia pages.\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_links\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 607\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_links \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    608\u001b[0m     link[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__continued_query({\n\u001b[0;32m    610\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprop\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinks\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    611\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplnamespace\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    612\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpllimit\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    613\u001b[0m     })\n\u001b[0;32m    614\u001b[0m   ]\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_links\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\wikipedia\\wikipedia.py:413\u001b[0m, in \u001b[0;36mWikipediaPage.__continued_query\u001b[1;34m(self, query_params)\u001b[0m\n\u001b[0;32m    410\u001b[0m params \u001b[38;5;241m=\u001b[39m query_params\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    411\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(last_continue)\n\u001b[1;32m--> 413\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[43m_wiki_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m request:\n\u001b[0;32m    416\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\wikipedia\\wikipedia.py:737\u001b[0m, in \u001b[0;36m_wiki_request\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m    734\u001b[0m   wait_time \u001b[38;5;241m=\u001b[39m (RATE_LIMIT_LAST_CALL \u001b[38;5;241m+\u001b[39m RATE_LIMIT_MIN_WAIT) \u001b[38;5;241m-\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m    735\u001b[0m   time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mint\u001b[39m(wait_time\u001b[38;5;241m.\u001b[39mtotal_seconds()))\n\u001b[1;32m--> 737\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAPI_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RATE_LIMIT:\n\u001b[0;32m    740\u001b[0m   RATE_LIMIT_LAST_CALL \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\requests\\sessions.py:724\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[0;32m    723\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_redirects(r, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 724\u001b[0m     history \u001b[38;5;241m=\u001b[39m [resp \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m gen]\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    726\u001b[0m     history \u001b[38;5;241m=\u001b[39m []\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\requests\\sessions.py:724\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[0;32m    723\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_redirects(r, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 724\u001b[0m     history \u001b[38;5;241m=\u001b[39m [resp \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m gen]\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    726\u001b[0m     history \u001b[38;5;241m=\u001b[39m []\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\requests\\sessions.py:265\u001b[0m, in \u001b[0;36mSessionRedirectMixin.resolve_redirects\u001b[1;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m req\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 265\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    266\u001b[0m         req,\n\u001b[0;32m    267\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    268\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    269\u001b[0m         verify\u001b[38;5;241m=\u001b[39mverify,\n\u001b[0;32m    270\u001b[0m         cert\u001b[38;5;241m=\u001b[39mcert,\n\u001b[0;32m    271\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    272\u001b[0m         allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    273\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39madapter_kwargs,\n\u001b[0;32m    274\u001b[0m     )\n\u001b[0;32m    276\u001b[0m     extract_cookies_to_jar(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcookies, prepared_request, resp\u001b[38;5;241m.\u001b[39mraw)\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;66;03m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\urllib3\\connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    794\u001b[0m     conn,\n\u001b[0;32m    795\u001b[0m     method,\n\u001b[0;32m    796\u001b[0m     url,\n\u001b[0;32m    797\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    798\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    799\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    800\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    801\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    802\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    803\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    804\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    806\u001b[0m )\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\urllib3\\connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\site-packages\\urllib3\\connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    465\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\http\\client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
                        "File \u001b[1;32mc:\\Users\\styme\\anaconda3\\envs\\arena\\lib\\ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "wiki_game_tools = [get_content_tool_inst, move_page_tool_inst, test_path_tool_inst, get_accessible_page_summary_tool_inst]\n",
                "agent = WikiAgentReAct(game, model=\"gpt-4o-mini\", tools = wiki_game_tools)\n",
                "game = WikiGameHistory(\"William Pitt the Younger\", \"Central Vietnam\", tools = wiki_game_tools)\n",
                "\n",
                "print(get_content(get_page(\"Vietnam\")))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Implement an arbitrary page summary/content tool\n",
                "```c\n",
                "Difficulty:🔴⚪⚪⚪⚪\n",
                "Importance:🔵🔵⚪⚪⚪\n",
                "\n",
                "You should spend up to 5-10 mins on this exercise.\n",
                "```\n",
                "\n",
                "Now implement a tool that allows the agent to suggest any wikipedia page, and get a brief summary of it. This may be helpful for the agent to formulate plans into the future.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 168,
            "metadata": {},
            "outputs": [],
            "source": [
                "class get_page_content(Tool):\n",
                "    \"\"\"\n",
                "    Implements a tool that allows the agent to get the content of any Wikipedia page (not wrapped in link tags).\n",
                "    \"\"\"\n",
                "\n",
                "    name = \"get_any_page_content\"\n",
                "\n",
                "    @staticmethod\n",
                "    def execute(task: Any, page_title: str | None = None) -> str:\n",
                "        \"\"\"\n",
                "        Get the content of any wikipedia page\n",
                "\n",
                "        Also provides current page content if no page_title is provided.\n",
                "\n",
                "        Args:\n",
                "            page_title (str): The title of the Wikipedia page\n",
                "\n",
                "        Returns:\n",
                "            str: The content of the page (not wrapped in link tags).\n",
                "        \"\"\"\n",
                "        if page_title:\n",
                "            page = task.get_page(page_title)\n",
                "            content = page.content\n",
                "            return content\n",
                "        else:\n",
                "            content = task.current_page.content\n",
                "            permitted_links = get_permitted_links(task.current_page)\n",
                "            for word in sorted(permitted_links, key=len, reverse=True):\n",
                "                content = re.sub(\n",
                "                    r\"\"\"(\\s|[,.)!?;:'\"])(\"\"\" + re.escape(word) + r\"\"\")(\\s|[,.)!?;:'\"s])\"\"\",\n",
                "                    r\"\"\"\\1<link>\\2</link>\\3\"\"\",\n",
                "                    content,\n",
                "                    count=1,\n",
                "                    flags=re.IGNORECASE,\n",
                "                )\n",
                "            return content\n",
                "\n",
                "    @property\n",
                "    def description(self):\n",
                "        \"\"\"\n",
                "        Provides the description of the get_any_page_content tool\n",
                "\n",
                "        Returns:\n",
                "            dict: The description of the tool for the API\n",
                "        \"\"\"\n",
                "        return {\n",
                "            \"type\": \"function\",\n",
                "            \"function\": {\n",
                "                \"name\": self.name,\n",
                "                \"description\": \"Get all the content for any wikipedia page.\",\n",
                "                \"parameters\": {\n",
                "                    \"type\": \"object\",\n",
                "                    \"properties\": {\n",
                "                        \"page_title\": {\n",
                "                            \"type\": \"object\",\n",
                "                            \"description\": \"The wikipedia page you want to get the content of.\",\n",
                "                        }\n",
                "                    },\n",
                "                    \"required\": [\"page_title\"],\n",
                "                },\n",
                "            },\n",
                "        }\n",
                "\n",
                "get_page_content_tool_inst = get_page_content()\n",
                "wiki_game_tools = [get_content_tool_inst, move_page_tool_inst, test_path_tool_inst, get_page_content_tool_inst]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 186,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Rosenhan experiment by accessing links from wikipedia pages. Your current page is 49th Fighter Training Squadron. You have access to 4 tools, which are:\n",
                        "get_content:Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select to move to will be wrapped in <link></link> tags.\n",
                        "move_page:Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n",
                        "test_path:Accepts a test path string in the form \"current_page -> page1 -> page2 -> ... -> pageN\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \"success.\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\n",
                        "get_page_content:Get all the content for any wikipedia page. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: 49th Fighter Training Squadron. Make sure you start by reasoning about what steps you should take to get to the article on Rosenhan experiment. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Rosenhan experiment has the following summary:\n",
                        "[Begin Summary]\n",
                        "The Rosenhan experiment or Thud experiment was an experiment regarding the validity of psychiatric diagnosis. For the experiment, participants submitted themselves for evaluation at various psychiatric institutions and feigned hallucinations in order to be accepted, but acted normally from then onward. Each was diagnosed with a psychiatric disorder and given antipsychotic medication.\n",
                        "[End Summary]\n",
                        "\n",
                        "\n",
                        "            \n",
                        "        The pages you've visited so far are: 49th Fighter Training Squadron\n",
                        "\n",
                        " Make sure to use the test_path tool liberally to explore your options! Use it at least 3 times before attempting to move page! Use it to test very long-horizon candidate paths (e.g. many more than just one link)\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Rosenhan experiment by accessing links from wikipedia pages. Your current page is 49th Fighter Training Squadron. You have access to 4 tools, which are:\n",
                        "get_content:Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select to move to will be wrapped in <link></link> tags.\n",
                        "move_page:Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n",
                        "test_path:Accepts a test path string in the form \"current_page -> page1 -> page2 -> ... -> pageN\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \"success.\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\n",
                        "get_page_content:Get all the content for any wikipedia page. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: 49th Fighter Training Squadron. Make sure you start by reasoning about what steps you should take to get to the article on Rosenhan experiment. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Rosenhan experiment has the following summary:\n",
                        "[Begin Summary]\n",
                        "The Rosenhan experiment or Thud experiment was an experiment regarding the validity of psychiatric diagnosis. For the experiment, participants submitted themselves for evaluation at various psychiatric institutions and feigned hallucinations in order to be accepted, but acted normally from then onward. Each was diagnosed with a psychiatric disorder and given antipsychotic medication.\n",
                        "[End Summary]\n",
                        "\n",
                        "\n",
                        "            \n",
                        "        The pages you've visited so far are: 49th Fighter Training Squadron\n",
                        "\n",
                        " Make sure to use the test_path tool liberally to explore your options! Use it at least 3 times before attempting to move page! Use it to test very long-horizon candidate paths (e.g. many more than just one link)\n",
                        "\n",
                        "Model response ('Reason'): To reach the article on the Rosenhan experiment, I need to identify potential pathways from the current page (49th Fighter Training Squadron) that might lead toward psychology or psychiatric topics, since the Rosenhan experiment is related to psychiatric diagnosis.\n",
                        "\n",
                        "First, I'll use the `get_content` tool to see which links are available on the 49th Fighter Training Squadron page. This will help me identify any relevant connections to broader topics or fields that could lead to psychology or psychiatry.\n",
                        "\n",
                        "After examining the links, I’ll test some longer path options that could connect to psychology or associated topics. Since I need to use the `test_path` tool liberally, I will outline a few potential paths based on connections from the links.\n",
                        "\n",
                        "Let's begin by getting the content of the current page to explore the links available. \n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " The 49th Fighter Training Squadron is part of the <link>14th Flying Training Wing</link> based at <link>Columbus Air Force Base</link>, Mississippi.  It operates <link>T-38 Talon</link> aircraft conducting flight training.\n",
                        "The squadron was first activated as the 49th Pursuit Squadron in 1941 during \n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): After analyzing the content of the page for the 49th Fighter Training Squadron, we can see there are links primarily related to military history, aircraft, and air force bases. None of these directly connect to psychology or psychiatry, which is essential to reach the Rosenhan experiment.\n",
                        "\n",
                        "Given that the Rosenhan experiment is related to psychiatric evaluation and diagnosis, I need to pivot my strategy. I can search for pages that are more aligned with psychology or mental health, or seek broader topics related to them, such as \"Psychology,\" \"Psychiatry,\" or \"Mental health.\"\n",
                        "\n",
                        "### Steps to Take:\n",
                        "1. **Identify Next Page Options:** I'll look for links that can connect to broader fields. Notably, terms like \"14th Flying Training Wing\" or \"Air Defense Command\" don't seem relevant.\n",
                        "2. **Use Test Path Tool:** I can use the test path tool to explore connections toward psychology or mental health. \n",
                        "3. **Shift Focus:** I may need to try a few paths to explore potential links deeper into related subjects that could lead toward the desired topic.\n",
                        "\n",
                        "### Testing Potential Paths:\n",
                        "To begin exploring connections, I can test the following potential paths. \n",
                        "\n",
                        "1. **Testing Air Force Links:** \n",
                        "   - \"49th Fighter Training Squadron -> 14th Flying Training Wing ->\" \n",
                        "   - \"49th Fighter Training Squadron ->Air Defense Command ->\"\n",
                        "  \n",
                        "2. **Exploring Historical Links:**\n",
                        "   - \"49th Fighter Training Squadron -> World War II -> Psychology\"\n",
                        "   - \"49th Fighter Training Squadron -> Military History -> Psychiatry\"\n",
                        "\n",
                        "I'll test these paths one after another to see if any lead us closer to psychology-related topics. \n",
                        "\n",
                        "Let's start by testing the first path: \"49th Fighter Training Squadron -> 14th Flying Training Wing.\"  I'll check this path first. \n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        " TESTING PATH \n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = test_path, Args = {\"path\":\"49th Fighter Training Squadron -> 14th Flying Training Wing\"} \n",
                        "TOOL RESPONSE:\n",
                        " This path is valid.\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): Since the path \"49th Fighter Training Squadron -> 14th Flying Training Wing\" is valid, I can move to the \"14th Flying Training Wing\" page. However, I need to be mindful that this path is still within the realm of military aviation and might not lead directly to psychology.\n",
                        "\n",
                        "To increase my chances of finding a relevant link that leads to psychology or psychiatry, the subsequent steps will follow this strategy:\n",
                        "\n",
                        "1. **Move to the 14th Flying Training Wing page.**\n",
                        "2. **Then, explore any links presented on that page.** I'll look for links related to psychology, mental health, or relevant experiments.\n",
                        "3. **Use the `test_path` tool again** to ensure I am not going down a dead end with limited options for further exploration.\n",
                        "\n",
                        "I'll proceed now to move to the \"14th Flying Training Wing\" page. \n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"14th Flying Training Wing\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to 14th Flying Training Wing\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=2): 49th Fighter Training Squadron -> 14th Flying Training Wing \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Rosenhan experiment by accessing links from wikipedia pages. Your current page is 14th Flying Training Wing. You have access to 4 tools, which are:\n",
                        "get_content:Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select to move to will be wrapped in <link></link> tags.\n",
                        "move_page:Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n",
                        "test_path:Accepts a test path string in the form \"current_page -> page1 -> page2 -> ... -> pageN\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \"success.\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\n",
                        "get_page_content:Get all the content for any wikipedia page. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: 14th Flying Training Wing. Make sure you start by reasoning about what steps you should take to get to the article on Rosenhan experiment. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Rosenhan experiment has the following summary:\n",
                        "[Begin Summary]\n",
                        "The Rosenhan experiment or Thud experiment was an experiment regarding the validity of psychiatric diagnosis. For the experiment, participants submitted themselves for evaluation at various psychiatric institutions and feigned hallucinations in order to be accepted, but acted normally from then onward. Each was diagnosed with a psychiatric disorder and given antipsychotic medication.\n",
                        "[End Summary]\n",
                        "\n",
                        "\n",
                        "            \n",
                        "        The pages you've visited so far are: 49th Fighter Training Squadron -> 14th Flying Training Wing\n",
                        "\n",
                        " Make sure to use the test_path tool liberally to explore your options! Use it at least 3 times before attempting to move page! Use it to test very long-horizon candidate paths (e.g. many more than just one link)\n",
                        "\n",
                        "Model response ('Reason'): To reach the page on the Rosenhan experiment, I need to think about potential connections between my current page, the 14th Flying Training Wing, and psychological concepts related to the Rosenhan experiment.\n",
                        "\n",
                        "The first step is to explore links related to defense, aviation psychology, training, or anything that might lead toward psychology or medical terms, as these might eventually connect to mental health topics or psychiatric studies.\n",
                        "\n",
                        "I will first retrieve the content of the 14th Flying Training Wing to identify any links that might lead to relevant pages. Then, based on the information gathered, I'll formulate a test path to explore further options. Let's start by getting the content of the current page.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " The 14th Flying Training Wing is a wing of the <link>United States Air Force</link> based out of <link>Columbus Air Force Base</link>, <link>Mississippi</link>.\n",
                        "The <link>14th Operations Group</link> and its six squadrons are responsible for the 52-week Undergraduate Pilot Training (UPT) mission. Th\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): From the content of the 14th Flying Training Wing, I notice several links that might be useful for reaching topics related to psychology or psychiatric diagnosis, which is the focus of the Rosenhan experiment. Here’s what I observe:\n",
                        "\n",
                        "1. **Psychological Warfare:** This term appears in the context of the Vietnam War operations. It might lead to discussions about psychological aspects and potentially link to psychological studies or experiments.\n",
                        "   \n",
                        "2. **Vietnam War:** This may have pages related to the societal impacts of the war, including mental health issues and psychological experiments that could overlap with the topics related to Rosenhan.\n",
                        "\n",
                        "3. **Medical Group:** There is a mention of the 14th Medical Group, which could relate healthcare and psychiatric care.\n",
                        "\n",
                        "Given this reasoning, my best next step would be to investigate the \"Vietnam War\" link to see if that leads to any psychology-related topics that could connect to the Rosenhan experiment.\n",
                        "\n",
                        "Let's test this potential path first to ensure it’s a viable option. I'll perform a test path from \"14th Flying Training Wing\" to \"Vietnam War\" and afterwards decide based on the results. I'll also consider additional paths based on what I learn from the test. \n",
                        "\n",
                        "Let’s proceed with the test path: \n",
                        "- Current Page -> Vietnam War\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        " TESTING PATH \n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = test_path, Args = {\"path\":\"14th Flying Training Wing -> Vietnam War\"} \n",
                        "TOOL RESPONSE:\n",
                        " This path is valid.\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): Since the path from \"14th Flying Training Wing\" to \"Vietnam War\" is valid, I will move to that page. The Vietnam War is a significant historical event that potentially intersects with psychological aspects, including reactions to trauma and studies related to mental health, which could lead to the Rosenhan experiment.\n",
                        "\n",
                        "After accessing the Vietnam War page, I can further explore links that might directly connect to psychological studies or the field of psychology that includes the Rosenhan experiment.\n",
                        "\n",
                        "Now, I’ll proceed to move to the \"Vietnam War\" page.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Vietnam War\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Vietnam War\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=3): 49th Fighter Training Squadron -> 14th Flying Training Wing -> Vietnam War \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Rosenhan experiment by accessing links from wikipedia pages. Your current page is Vietnam War. You have access to 4 tools, which are:\n",
                        "get_content:Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select to move to will be wrapped in <link></link> tags.\n",
                        "move_page:Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n",
                        "test_path:Accepts a test path string in the form \"current_page -> page1 -> page2 -> ... -> pageN\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \"success.\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\n",
                        "get_page_content:Get all the content for any wikipedia page. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Vietnam War. Make sure you start by reasoning about what steps you should take to get to the article on Rosenhan experiment. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Rosenhan experiment has the following summary:\n",
                        "[Begin Summary]\n",
                        "The Rosenhan experiment or Thud experiment was an experiment regarding the validity of psychiatric diagnosis. For the experiment, participants submitted themselves for evaluation at various psychiatric institutions and feigned hallucinations in order to be accepted, but acted normally from then onward. Each was diagnosed with a psychiatric disorder and given antipsychotic medication.\n",
                        "[End Summary]\n",
                        "\n",
                        "\n",
                        "            \n",
                        "        The pages you've visited so far are: 49th Fighter Training Squadron -> 14th Flying Training Wing -> Vietnam War\n",
                        "\n",
                        " Make sure to use the test_path tool liberally to explore your options! Use it at least 3 times before attempting to move page! Use it to test very long-horizon candidate paths (e.g. many more than just one link)\n",
                        "\n",
                        "Model response ('Reason'): To get to the \"Rosenhan experiment\" from the \"Vietnam War\" page, I should look for relevant links that can potentially lead me towards psychology or psychiatry-related topics, as the Rosenhan experiment pertains to psychiatric diagnosis.\n",
                        "\n",
                        "Considering the summary provided, terms like \"psychology,\" \"psychiatry,\" \"mental health,\" or related areas could be the right pathway. The first step is to analyze the links available on the \"Vietnam War\" page to see if any might lead to these subjects.\n",
                        "\n",
                        "I will begin by testing a few possible paths to see if any link from \"Vietnam War\" can guide me towards psychology or psychiatric topics. If I don't find any promising links immediately, I may have to return to the \"Vietnam War\" page and look for a more indirect route.\n",
                        "\n",
                        "Let's start with a long test path that might go from \"Vietnam War\" to some related psychological or mental health topics, perhaps by going through military or societal impacts that connect back to psychology. I will create a test path such as this: \n",
                        "\n",
                        "1. \"Vietnam War\" -> \"Vietnamese culture\" -> \"Mental health in Vietnam\" (hypothetical path)\n",
                        "\n",
                        "I will use the `test_path` tool to check the success of this path and modify it accordingly. If it fails, I will adjust based on the available links and test again with a different direction. \n",
                        "\n",
                        "Let's perform the first test path. I will initiate the testing with this first path.\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        " TESTING PATH \n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = test_path, Args = {\"path\":\"Vietnam War -> Vietnamese culture -> Mental health in Vietnam\"} \n",
                        "TOOL RESPONSE:\n",
                        " This path works until Vietnamese culture, which is not accessible from Vietnam War\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): Since the first test path failed after attempting to go to \"Vietnamese culture,\" I'll need to focus on other links directly from the \"Vietnam War\" page. I want to look for links that could lead to content related to psychology, psychiatry, or mental health.\n",
                        "\n",
                        "Given my current position, the strategy will involve checking links on the \"Vietnam War\" page more thoroughly. Below are some steps I can take:\n",
                        "\n",
                        "1. Look for links that are related to \"psychological effects,\" \"mental health,\" \"combat stress,\" or \"war psychiatry\".\n",
                        "2. If there's a more historical or sociological aspect mentioned, that could also lead to the Rothenhan experiment through a discussion of mental health issues stemming from war experiences.\n",
                        "\n",
                        "Once I have identified a more relevant link, I’ll use that to navigate to a new page. However, before doing that, I will conduct a few more tests to explore the existing links properly.\n",
                        "\n",
                        "Let's conduct another test with a different approach. I will attempt this test path to check links that might lead to broader psychological discussions:\n",
                        "\n",
                        "1. \"Vietnam War\" -> \"Post-Traumatic Stress Disorder\" -> \"Mental health treatment\" (hypothetical path)\n",
                        "\n",
                        "Now, I will use the `test_path` tool for this path to see if it leads somewhere useful. \n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        " TESTING PATH \n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = test_path, Args = {\"path\":\"Vietnam War -> Post-Traumatic Stress Disorder -> Mental health treatment\"} \n",
                        "TOOL RESPONSE:\n",
                        " This path works until Post-Traumatic Stress Disorder, which is not accessible from Vietnam War\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): Given that both of my previous attempts to test paths from the \"Vietnam War\" page have not been successful, it is clear that I need to revisit the links available on the \"Vietnam War\" page and look for alternative routes. \n",
                        "\n",
                        "The next step is to examine the specific links on the \"Vietnam War\" page again to identify any connections that could lead me to psychology or mental health topics that might relate indirectly to the Rosenhan experiment. \n",
                        "\n",
                        "I will take the following approach:\n",
                        "\n",
                        "1. Access the content of the \"Vietnam War\" page to thoroughly review all available links.\n",
                        "2. Look for any terms related to psychology, psychiatry, or even mentions of soldiers dealing with mental health issues where connections might be drawn.\n",
                        "\n",
                        "This will give me the best chance of finding pathways to related content. \n",
                        "\n",
                        "I will start by executing the `get_content` function to get all the content for the \"Vietnam War\" page and identify the relevant links. Let's proceed with this action.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " The <link>Vietnam</link> War was a conflict in Vietnam, <link>Laos</link>, and <link>Cambodia</link> from 1 November 1955 to the <link>fall of Saigon</link> on 30 April 1975. It was the second of the <link>Indochina Wars</link> and a major conflict of the <link>Cold War</link>. While the war was off\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): Now that I have access to the entire content of the \"Vietnam War\" page, I can review the links available more thoroughly. \n",
                        "\n",
                        "From my observations, the key steps to reach the article on the \"Rosenhan experiment\" involve navigating through topics closely related to psychology or mental health, as previously mentioned. The Vietnam War had significant psychological effects on veterans and society, which might help bridge the gap to the Rosenhan experiment.\n",
                        "\n",
                        "Here are the actions I will take:\n",
                        "1. **Identify Relevant Links**: By reviewing the entire text of the Vietnam War page, I will identify any links that may point towards psychological impacts, mental health treatment, or studies related to psychiatric diagnosis.\n",
                        "\n",
                        "2. **Test Possible Paths**: Once I've identified potential links, I will test paths to determine which, if any, might successfully connect with psychology or mental health topics.\n",
                        "\n",
                        "3. **Move to a Relevant Page**: After finding a valid path, I will navigate to that new page and continue the process towards the Rosenhan experiment.\n",
                        "\n",
                        "To begin, I will look closely through the links present in the text to see if any connect directly with psychology or mental health fields. A few terms might stand out, particularly related to the psychological effects of war or PTSD.\n",
                        "\n",
                        "After carefully scanning the available links, if I find a promising one, I'll create a test path based on those links. \n",
                        "\n",
                        "Let's proceed by checking the links and formulating a test path. \n",
                        "\n",
                        "For the first link, there's a mention of \"Vietnam syndrome.\" This could be a promising topic since it relates to the psychological effects of the Vietnam War. Another potential reference might be \"Post-Traumatic Stress Disorder\" (PTSD), which is also related.\n",
                        "\n",
                        "Given these observations, I will test a path that uses \"Vietnam syndrome\" as the first step. I will formulate and test the following path:\n",
                        "\n",
                        "1. \"Vietnam War\" -> \"Vietnam syndrome\" -> \"Post-Traumatic Stress Disorder\"\n",
                        "\n",
                        "Let's use the `test_path` tool for this. I will initiate this test.\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        " TESTING PATH \n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = test_path, Args = {\"path\":\"Vietnam War -> Vietnam syndrome -> Post-Traumatic Stress Disorder\"} \n",
                        "TOOL RESPONSE:\n",
                        " This path is valid.\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): Since the path from \"Vietnam War\" to \"Vietnam syndrome\" and then to \"Post-Traumatic Stress Disorder\" is valid, I will proceed with this plan. The topic of \"Post-Traumatic Stress Disorder\" (PTSD) is closely related to mental health, which I believe can lead me toward the psychology content where the Rosenhan experiment is located.\n",
                        "\n",
                        "Here's the plan of action:\n",
                        "\n",
                        "1. **Move to \"Vietnam syndrome\"**: I'll first navigate to the \"Vietnam syndrome\" page from the \"Vietnam War\" page.\n",
                        "2. **Then to \"Post-Traumatic Stress Disorder\"**: After that, I'll move from \"Vietnam syndrome\" to \"Post-Traumatic Stress Disorder,\" as the next step in this path.\n",
                        "3. **Explore the PTSD Page**: Once on the PTSD page, I will investigate the links there to find any related to psychology or studies pertaining to psychiatric diagnosis, which may include discussions or references to the Rosenhan experiment.\n",
                        "\n",
                        "Let’s execute the first move to go to the page: \"Vietnam syndrome.\"  I will now use the `move_page` function to navigate there.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Vietnam syndrome\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Vietnam syndrome\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=4): 49th Fighter Training Squadron -> 14th Flying Training Wing -> Vietnam War -> Vietnam syndrome \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Rosenhan experiment by accessing links from wikipedia pages. Your current page is Vietnam syndrome. You have access to 4 tools, which are:\n",
                        "get_content:Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select to move to will be wrapped in <link></link> tags.\n",
                        "move_page:Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n",
                        "test_path:Accepts a test path string in the form \"current_page -> page1 -> page2 -> ... -> pageN\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \"success.\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\n",
                        "get_page_content:Get all the content for any wikipedia page. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Vietnam syndrome. Make sure you start by reasoning about what steps you should take to get to the article on Rosenhan experiment. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Rosenhan experiment has the following summary:\n",
                        "[Begin Summary]\n",
                        "The Rosenhan experiment or Thud experiment was an experiment regarding the validity of psychiatric diagnosis. For the experiment, participants submitted themselves for evaluation at various psychiatric institutions and feigned hallucinations in order to be accepted, but acted normally from then onward. Each was diagnosed with a psychiatric disorder and given antipsychotic medication.\n",
                        "[End Summary]\n",
                        "\n",
                        "\n",
                        "            \n",
                        "        The pages you've visited so far are: 49th Fighter Training Squadron -> 14th Flying Training Wing -> Vietnam War -> Vietnam syndrome\n",
                        "\n",
                        " Make sure to use the test_path tool liberally to explore your options! Use it at least 3 times before attempting to move page! Use it to test very long-horizon candidate paths (e.g. many more than just one link)\n",
                        "\n",
                        "Model response ('Reason'): To reach the Rosenhan experiment, I need to identify relevant links on the current page, Vietnam syndrome, and look for pathways to articles focused on psychology, psychiatric diagnosis, or mental health, as those concepts are closely related to the Rosenhan experiment.\n",
                        "\n",
                        "I'll take the following steps:\n",
                        "\n",
                        "1. **Get the content of the current page (Vietnam syndrome)** to identify any potential links to pages that might lead me toward the field of psychology or mental health.\n",
                        "\n",
                        "2. After analyzing the content for links, I will consider a few possible paths to take to get to Rosenhan's experiment.\n",
                        "\n",
                        "3. I will use the test_path tool to ensure that the paths I have in mind are valid and check multiple options before making a single move.\n",
                        "\n",
                        "Let's begin by getting the content on the Vietnam syndrome page. I'll start with that now. \n",
                        "\n",
                        "**Action 1:** Get content for the Vietnam syndrome page using `get_content`.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Vietnam syndrome is a term in <link>U.S. politics</link> that refers to public aversion to American overseas military involvements after the domestic controversy over the <link>Vietnam War</link>. In 1973, the U.S. ended combat operations in Vietnam. Since the early 1980s, some possible effects of V\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): The content from the Vietnam syndrome page includes discussions around U.S. military actions and public perceptions following the Vietnam War but does not directly relate to psychology, psychiatric diagnosis, or mental health—which are relevant to the Rosenhan experiment.\n",
                        "\n",
                        "Here are some potential pathways I can pursue based on the links provided:\n",
                        "\n",
                        "1. **U.S. politics** - While this may lead to more political discussions, it could potentially link to the broader context of American societal issues, including mental health.\n",
                        "\n",
                        "2. **Vietnam War** - This may lead to pages on specific aspects of the war, but it's more likely to remain within military history rather than psychological topics.\n",
                        "\n",
                        "3. **Post-traumatic stress disorder** - This term appears under the \"See also\" section and is closely related to mental health and psychological impacts, which could lead me much closer to the Rosenhan experiment.\n",
                        "\n",
                        "4. **Bosnian War** and **War-weariness** - These might also have relevant links, but they do not seem as direct as PTSD.\n",
                        "\n",
                        "Among these options, moving towards \"Post-traumatic stress disorder\" (PTSD) seems promising, as PTSD is directly related to mental health.\n",
                        "\n",
                        "**Next Step:** I will use the `move_page` function to go to the \"Post-traumatic stress disorder\" page since it appears to be the best option that provides a link to relevant psychological topics. \n",
                        "\n",
                        "**Action:** Move to the page for \"Post-traumatic stress disorder\".\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Post-traumatic_stress_disorder\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Post-traumatic stress disorder\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=5): 49th Fighter Training Squadron -> 14th Flying Training Wing -> Vietnam War -> Vietnam syndrome -> Post-traumatic stress disorder \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Rosenhan experiment by accessing links from wikipedia pages. Your current page is Post-traumatic stress disorder. You have access to 4 tools, which are:\n",
                        "get_content:Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select to move to will be wrapped in <link></link> tags.\n",
                        "move_page:Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n",
                        "test_path:Accepts a test path string in the form \"current_page -> page1 -> page2 -> ... -> pageN\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \"success.\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\n",
                        "get_page_content:Get all the content for any wikipedia page. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Post-traumatic stress disorder. Make sure you start by reasoning about what steps you should take to get to the article on Rosenhan experiment. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Rosenhan experiment has the following summary:\n",
                        "[Begin Summary]\n",
                        "The Rosenhan experiment or Thud experiment was an experiment regarding the validity of psychiatric diagnosis. For the experiment, participants submitted themselves for evaluation at various psychiatric institutions and feigned hallucinations in order to be accepted, but acted normally from then onward. Each was diagnosed with a psychiatric disorder and given antipsychotic medication.\n",
                        "[End Summary]\n",
                        "\n",
                        "\n",
                        "            \n",
                        "        The pages you've visited so far are: 49th Fighter Training Squadron -> 14th Flying Training Wing -> Vietnam War -> Vietnam syndrome -> Post-traumatic stress disorder\n",
                        "\n",
                        " Make sure to use the test_path tool liberally to explore your options! Use it at least 3 times before attempting to move page! Use it to test very long-horizon candidate paths (e.g. many more than just one link)\n",
                        "\n",
                        "Model response ('Reason'): To reach the Rosenhan experiment from the current page on Post-traumatic Stress Disorder (PTSD), I need to find links that lead toward topics related to psychiatric diagnosis, mental health experiments, or studies relevant to the validity of psychiatric evaluation.\n",
                        "\n",
                        "Given that Rosenhan's experiment centers around psychiatric diagnosis, I should look for links from the current page that may lead to mental health or psychiatric topics. I should also consider that related pages might include terms like \"psychiatry,\" \"psychological experiments,\" or \"mental disorders.\"\n",
                        "\n",
                        "Here’s a strategy for movement:\n",
                        "1. Identify potentially relevant links on the PTSD page.\n",
                        "2. Use the `test_path` tool to check for links leading to the field of psychiatry or psychological experiments.\n",
                        "3. Progress through the links while checking the relevance toward investigation of psychiatric diagnosis.\n",
                        "\n",
                        "Let's first check the existing links on the Post-traumatic Stress Disorder page to analyze possible pathways. \n",
                        "\n",
                        "I'll start by using `get_content` to see the links available on the Post-traumatic Stress Disorder page. This will help me find the relevant topics to test longer paths.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Post-traumatic stress disorder (PTSD) is a mental and behavioral disorder that develops from experiencing a traumatic event, such as sexual assault, warfare, traffic collisions, child abuse, domestic violence, or other threats on a person's life or well-being. Symptoms may include disturbing thought\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): After reviewing the content from the Post-traumatic Stress Disorder page, it appears that there are several paths I might explore that could relate to psychiatric research and diagnoses. The focus should be on topics that link to either the field of psychiatry, psychological disorders, or experimental methodologies.\n",
                        "\n",
                        "### Strategy for Next Steps:\n",
                        "1. **Identify Key Links:** Look for links related to psychiatric diagnoses, mental health experiments, or notable studies in psychology that may connect to the Rosenhan experiment.\n",
                        "  \n",
                        "2. **Test Paths:** Since the goal is to find a direct path toward the Rosenhan experiment, I will utilize the `test_path` tool by focusing on key links that indicate psychiatric experimentation or diagnosis, such as links to \"American Psychiatric Association,\" \"psychiatry,\" or links that may discuss related experiments or studies.\n",
                        "\n",
                        "### Key Links to Consider from Current Context:\n",
                        "- **American Psychiatric Association:** This could lead to broader discussions regarding psychiatric diagnosis.\n",
                        "- **Diagnosis/Diagnostic and Statistical Manual of Mental Disorders (DSM):** Since the Rosenhan experiment critiques psychiatric diagnosis, this could be highly relevant.\n",
                        "- **Psychological experiments** or studies.\n",
                        "\n",
                        "### Testing Paths\n",
                        "Given these considerations, I will first test a path that includes \"American Psychiatric Association\" and includes the DSM, both of which are pivotal in psychiatric research. \n",
                        "\n",
                        "I will start by testing the following path:\n",
                        "- **PTSD -> American Psychiatric Association -> Diagnostic and Statistical Manual of Mental Disorders -> Rosenhan experiment**\n",
                        "\n",
                        "Let’s see if this path is viable. I'll use `test_path` to check this route. \n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        " TESTING PATH \n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = test_path, Args = {\"path\":\"Post-traumatic stress disorder -> American Psychiatric Association -> Diagnostic and Statistical Manual of Mental Disorders -> Rosenhan experiment\"} \n",
                        "TOOL RESPONSE:\n",
                        " This path works until Diagnostic and Statistical Manual of Mental Disorders, which is not accessible from American Psychiatric Association\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): The test path I attempted worked up until the American Psychiatric Association page, but I couldn't access \"Diagnostic and Statistical Manual of Mental Disorders\" from there. Therefore, I need to adjust my approach to find an alternative route leading toward the Rosenhan experiment.\n",
                        "\n",
                        "### Next Steps:\n",
                        "1. **Look for Other Related Links:** I'll examine the content on the PTSD page for other relevant links. This may include links to psychology or psychiatry, methodology of psychological studies, or even historical contexts surrounding mental health diagnoses.\n",
                        "\n",
                        "2. **New Test Path:** Based on the new links I find, I can test new paths. Some other potential links that seemed significant from the page content that could be relevant include:\n",
                        "   - \"Veterans\" (as they relate to PTSD and may lead to historical studies)\n",
                        "   - \"Substance use disorder\" (to see if there's a connection to broader psychiatric studies)\n",
                        "   - \"Counselling\" (referring to therapeutic methods which may discuss experiments or methodologies)\n",
                        "   - Directly check \"Diagnostic and Statistical Manual of Mental Disorders\" if it's linkable independently.\n",
                        "\n",
                        "3. **Moving Forward:** I’ll start by checking possible links directly for \"Diagnostic and Statistical Manual of Mental Disorders\" or reviewing other keywords that might connect to psychiatric experiments. \n",
                        "\n",
                        "Let me get the page content again and check how I can find a more effective link leading toward the Rosenhan experiment. If I can't find \"Diagnostic and Statistical Manual of Mental Disorders,\" I will focus on other significant links. \n",
                        "\n",
                        "I'll proceed to check the links again from the PTSD content that might be more useful. I'll explicitly look for links related to psychiatry, experiments, and studies.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " Post-traumatic stress disorder (PTSD) is a mental and behavioral disorder that develops from experiencing a traumatic event, such as sexual assault, warfare, traffic collisions, child abuse, domestic violence, or other threats on a person's life or well-being. Symptoms may include disturbing thought\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): After reviewing the content again, I see that we have several areas of relevance, especially surrounding psychiatric concepts and diagnostic manuals. Clearly, the \"Diagnostic and Statistical Manual of Mental Disorders\" (DSM) is deeply connected to the validity of psychiatric diagnoses, which is crucial for the Rosenhan experiment.\n",
                        "\n",
                        "Here's a revised approach based on this understanding:\n",
                        "\n",
                        "### Potential Links to Explore:\n",
                        "- **Diagnostic and Statistical Manual of Mental Disorders (DSM)**: This page relates directly to psychiatric diagnoses and will likely link closely to the Rosenhan experiment, which critiques these diagnoses.\n",
                        "- **History**: The history of PTSD and the DSM could have paths related to the evolution of psychiatric diagnoses, including links to the Rosenhan experiment.\n",
                        "  \n",
                        "### Strategy:\n",
                        "1. **Use Test Paths for Known Links**: I will try to construct paths using the “Diagnostic and Statistical Manual of Mental Disorders.”\n",
                        "2. **Look at Related Topics**: Besides the DSM, I can use links surrounding \"psychological experiments,\" as the Rosenhan experiment is a pivotal study in psychology.\n",
                        "3. **Explore Links to Individual Studies/Concepts**: Check for any direct links that might lead to notable psychological studies or experiments directly related to the criteria set by DSM.\n",
                        "\n",
                        "### Suggested Path to Test:\n",
                        "- I will begin by testing: **Post-traumatic stress disorder -> Diagnostic and Statistical Manual of Mental Disorders -> Rosenhan experiment**\n",
                        "\n",
                        "This should help confirm whether I can navigate directly towards the Rosenhan experiment through the DSM context. \n",
                        "\n",
                        "Now, I will use `test_path` to check this route again. Let's begin with that.\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        " TESTING PATH \n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = test_path, Args = {\"path\":\"Post-traumatic stress disorder -> Diagnostic and Statistical Manual of Mental Disorders -> Rosenhan experiment\"} \n",
                        "TOOL RESPONSE:\n",
                        " This path is valid.\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): Since the path from \"Post-traumatic stress disorder\" to \"Diagnostic and Statistical Manual of Mental Disorders\" to \"Rosenhan experiment\" is valid, I can proceed to move to the \"Diagnostic and Statistical Manual of Mental Disorders\" page.\n",
                        "\n",
                        "### Next Steps:\n",
                        "1. **Move to the DSM Page**: This will provide me with content related to psychiatric diagnoses, which is directly relevant to the Rosenhan experiment's critique of these diagnoses.\n",
                        "2. **Explore Links on the DSM Page**: After moving to the DSM page, I will look for any relevant information or links that can lead me directly to the Rosenhan experiment or provide context related to it.\n",
                        "\n",
                        "### Action:\n",
                        "I will now execute the move to the \"Diagnostic and Statistical Manual of Mental Disorders\" page. \n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"Diagnostic and Statistical Manual of Mental Disorders\"} \n",
                        "TOOL RESPONSE:\n",
                        " Moving page to Diagnostic and Statistical Manual of Mental Disorders\n",
                        "-------------------------------------------------- \n",
                        "\n",
                        "MOVED TO PAGE \n",
                        "\n",
                        "PATH HISTORY (N=6): 49th Fighter Training Squadron -> 14th Flying Training Wing -> Vietnam War -> Vietnam syndrome -> Post-traumatic stress disorder -> Diagnostic and Statistical Manual of Mental Disorders \n",
                        "\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "SYSTEM: \n",
                        "You are a wikipedia-racing AI. Your goal is to reach Rosenhan experiment by accessing links from wikipedia pages. Your current page is Diagnostic and Statistical Manual of Mental Disorders. You have access to 4 tools, which are:\n",
                        "get_content:Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select to move to will be wrapped in <link></link> tags.\n",
                        "move_page:Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n",
                        "test_path:Accepts a test path string in the form \"current_page -> page1 -> page2 -> ... -> pageN\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \"success.\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\n",
                        "get_page_content:Get all the content for any wikipedia page. \n",
                        "\n",
                        "USER: \n",
                        "You are currently on page: Diagnostic and Statistical Manual of Mental Disorders. Make sure you start by reasoning about what steps you should take to get to the article on Rosenhan experiment. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, Rosenhan experiment has the following summary:\n",
                        "[Begin Summary]\n",
                        "The Rosenhan experiment or Thud experiment was an experiment regarding the validity of psychiatric diagnosis. For the experiment, participants submitted themselves for evaluation at various psychiatric institutions and feigned hallucinations in order to be accepted, but acted normally from then onward. Each was diagnosed with a psychiatric disorder and given antipsychotic medication.\n",
                        "[End Summary]\n",
                        "\n",
                        "\n",
                        "            \n",
                        "        The pages you've visited so far are: 49th Fighter Training Squadron -> 14th Flying Training Wing -> Vietnam War -> Vietnam syndrome -> Post-traumatic stress disorder -> Diagnostic and Statistical Manual of Mental Disorders\n",
                        "\n",
                        " Make sure to use the test_path tool liberally to explore your options! Use it at least 3 times before attempting to move page! Use it to test very long-horizon candidate paths (e.g. many more than just one link)\n",
                        "\n",
                        "Model response ('Reason'): To get closer to the \"Rosenhan experiment\" page, I need to analyze the current page, \"Diagnostic and Statistical Manual of Mental Disorders\", for potential links. Given that the Rosenhan experiment is related to psychiatric diagnosis and treatment, I might need to navigate through relevant psychological theories, psychiatric diagnoses, or historical experiments in psychology.\n",
                        "\n",
                        "However, I should first explore possible paths by testing multiple longer paths that may lead to related concepts or historical experiments about psychiatric evaluation.\n",
                        "\n",
                        "Therefore, I will start by testing several potential paths that explore connections related to psychology, diagnosis, and psychiatry. I need to ensure that these paths can lead to the experiment.\n",
                        "\n",
                        "1. **Path 1:** \"Diagnostic and Statistical Manual of Mental Disorders\" -> \"Psychiatry\" -> \"Psychiatric diagnosis\" -> \"Clinical psychology\"\n",
                        "2. **Path 2:** \"Diagnostic and Statistical Manual of Mental Disorders\" -> \"Mental health\" -> \"Abnormal psychology\" -> \"Psychological experiment\"\n",
                        "3. **Path 3:** \"Diagnostic and Statistical Manual of Mental Disorders\" -> \"History of psychiatry\" -> \"Psychiatric institution\" -> \"Rosenhan experiment\"\n",
                        "\n",
                        "Let's proceed with testing these paths systematically. I will start with Path 1. \n",
                        "\n",
                        "Executing the first test path now. \n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        " TESTING PATH \n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = test_path, Args = {\"path\":\"Diagnostic and Statistical Manual of Mental Disorders -> Psychiatry -> Psychiatric diagnosis -> Clinical psychology\"} \n",
                        "TOOL RESPONSE:\n",
                        " This path works until Psychiatry, which is not accessible from Diagnostic and Statistical Manual of Mental Disorders\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): Since the first path I tested didn't work beyond \"Psychiatry,\" it suggests that there might be more indirect routes I could explore that involve concepts related to mental health or psychology. \n",
                        "\n",
                        "The two alternate paths I had planned also need to be checked. I'll test Path 2 and see if it leads me in a productive direction to ultimately reach the \"Rosenhan experiment.\" \n",
                        "\n",
                        "Let's execute the next test path: \n",
                        "\n",
                        "2. **Path 2:** \"Diagnostic and Statistical Manual of Mental Disorders\" -> \"Mental health\" -> \"Abnormal psychology\" -> \"Psychological experiment\"\n",
                        "\n",
                        "Now, I will test this path to check its validity.\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        " TESTING PATH \n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = test_path, Args = {\"path\":\"Diagnostic and Statistical Manual of Mental Disorders -> Mental health -> Abnormal psychology -> Psychological experiment\"} \n",
                        "TOOL RESPONSE:\n",
                        " This path works until Mental health, which is not accessible from Diagnostic and Statistical Manual of Mental Disorders\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): Since testing Path 1 and Path 2 showed limitations, I will now proceed to test Path 3, which focuses on the historical context related to psychiatric institutions.\n",
                        "\n",
                        "3. **Path 3:** \"Diagnostic and Statistical Manual of Mental Disorders\" -> \"History of psychiatry\" -> \"Psychiatric institution\" -> \"Rosenhan experiment\"\n",
                        "\n",
                        "This might lead me closer to the Rosenhan experiment based on its context in psychiatric history. I will go ahead and test this path now.\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        " TESTING PATH \n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = test_path, Args = {\"path\":\"Diagnostic and Statistical Manual of Mental Disorders -> History of psychiatry -> Psychiatric institution -> Rosenhan experiment\"} \n",
                        "TOOL RESPONSE:\n",
                        " This path works until History of psychiatry, which is not accessible from Diagnostic and Statistical Manual of Mental Disorders\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): Since my previous attempts to find a path to the \"Rosenhan experiment\" through tested paths have faced blocks, I'll change my approach by examining the content of the current page to find any potential links that can lead me in a different direction. \n",
                        "\n",
                        "Instead of testing long paths further without information, I'll first retrieve the links available on the \"Diagnostic and Statistical Manual of Mental Disorders\" page to identify more specific connections related to psychiatric diagnosis and experiments.\n",
                        "\n",
                        "I will execute the action to get all the content on the current page to see what links are available.\n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = get_content, Args = {} \n",
                        "TOOL RESPONSE:\n",
                        " The Diagnostic and Statistical Manual of Mental Disorders (DSM; latest edition: DSM-5-TR, published in March 2022) is a publication by the <link>American Psychiatric Association</link> (APA) for the classification of mental disorders using a common language and standard criteria. It is an internatio\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): Upon reviewing the content from the \"Diagnostic and Statistical Manual of Mental Disorders\" page, I noticed that the \"Rosenhan experiment\" is explicitly mentioned in the context of critiques of the DSM, particularly in the section discussing DSM-II. This suggests that there's a direct link using the topic of the Rosenhan experiment.\n",
                        "\n",
                        "Now that I have that information, I will prioritize moving to the \"DSM-II\" section from the current page since it directly references the Rosenhan experiment.\n",
                        "\n",
                        "I need to explore the related content more strategically. I need to check if there is a specific mention or link for \"Rosenhan experiment.\" \n",
                        "\n",
                        "Based on the context, an immediate next step would be to look for the link directly associated with \"Rosenhan experiment\" or check the subsection on \"Rosenhan experiment\" if it appears in the current overview. In the earlier content, I saw it mentioned under the \"DSM-II\" section, and it’s likely that there might be a more detailed overview within that section.\n",
                        "\n",
                        "I will check if the \"Rosenhan experiment\" can be directly accessed as a specific link from the available content.\n",
                        "\n",
                        "Since there is mention of it within the discussion of DSM-II, I will look for the link to DSM-II in the content provided. \n",
                        "\n",
                        "I will now try moving to the \"DSM-II\" page to see if it includes more about the Rosenhan experiment. \n",
                        "\n",
                        "TOOL CALL: \n",
                        "Tool = move_page, Args = {\"new_page\":\"DSM-II\"} \n",
                        "TOOL RESPONSE:\n",
                        " Couldn't move page to DSM-II. This is not a valid link.\n",
                        "\n",
                        "USER: \n",
                        "What's your next step to get to Rosenhan experiment?\n",
                        "\n",
                        "Model response ('Reason'): Since I was unable to move to the \"DSM-II\" page directly and have already identified that the \"Rosenhan experiment\" is referenced on the page I just came from, it seems I need to take a different approach.\n",
                        "\n",
                        "I need to confirm the context around the \"Rosenhan experiment\" within the \"Diagnostic and Statistical Manual of Mental Disorders\" page. The experiment is discussed in relation to the validity and reliability concerns regarding psychiatric diagnoses in the DSM-II section.\n",
                        "\n",
                        "To proceed efficiently, I will:\n",
                        "1. Search within the page for any direct reference to \"Rosenhan experiment\" or details that elucidate its significance.\n",
                        "2. Look at if there are further links or contexts mentioned that directly connect to the Rosenhan experiment or related topics.\n",
                        "\n",
                        "Since I cannot directly move to another page, I will extract more content directly from the current page to find all pertinent references to the \"Rosenhan experiment,\" ensuring no further steps are missed.\n",
                        "\n",
                        "Let me proceed to retrieve additional content again for insights, focusing on potential connections leading to the \"Rosenhan experiment.\"\n"
                    ]
                },
                {
                    "ename": "TypeError",
                    "evalue": "get_page_content.execute() missing 1 required positional argument: 'page_title'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[186], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m agent \u001b[38;5;241m=\u001b[39m WikiAgentReAct(game, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m, tools \u001b[38;5;241m=\u001b[39m wiki_game_tools)\n\u001b[0;32m      2\u001b[0m game \u001b[38;5;241m=\u001b[39m WikiGameHistory(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m49th Fighter Training Squadron\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRosenhan experiment\u001b[39m\u001b[38;5;124m\"\u001b[39m, tools \u001b[38;5;241m=\u001b[39m wiki_game_tools)\n\u001b[1;32m----> 3\u001b[0m \u001b[43magent_loop_ReAct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
                        "Cell \u001b[1;32mIn[122], line 15\u001b[0m, in \u001b[0;36magent_loop_ReAct\u001b[1;34m(game, agent, num_loops)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "Cell \u001b[1;32mIn[121], line 126\u001b[0m, in \u001b[0;36mWikiAgentReAct.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_reason_and_action()\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtool_calls:\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_tool_calls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mrefusal:\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_refusal(response)\n",
                        "Cell \u001b[1;32mIn[118], line 79\u001b[0m, in \u001b[0;36mWikiAgent.handle_tool_calls\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_history(response)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Execute the tool calls\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m tool_responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_tool_calls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Add tool calls and responses to the history\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tool_call, tool_response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(response\u001b[38;5;241m.\u001b[39mtool_calls, tool_responses):\n",
                        "Cell \u001b[1;32mIn[57], line 54\u001b[0m, in \u001b[0;36mSimpleAgent.execute_tool_calls\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m     50\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m     51\u001b[0m         (tool \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools \u001b[38;5;28;01mif\u001b[39;00m tool\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m tool_call\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m     52\u001b[0m     )\n\u001b[0;32m     53\u001b[0m     arguments \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(tool_call\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39marguments)\n\u001b[1;32m---> 54\u001b[0m     tool_response \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39marguments, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask)\n\u001b[0;32m     55\u001b[0m     tool_responses\u001b[38;5;241m.\u001b[39mappend(tool_response)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tool_responses\n",
                        "\u001b[1;31mTypeError\u001b[0m: get_page_content.execute() missing 1 required positional argument: 'page_title'"
                    ]
                }
            ],
            "source": [
                "agent = WikiAgentReAct(game, model=\"gpt-4o-mini\", tools = wiki_game_tools)\n",
                "game = WikiGameHistory(\"49th Fighter Training Squadron\", \"Rosenhan experiment\", tools = wiki_game_tools)\n",
                "agent_loop_ReAct(game, agent, 30)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 5️⃣ Bonus"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Implement additional rules\n",
                "```c\n",
                "Difficulty: 🔴🔴⚪⚪⚪\n",
                "Importance: 🔵⚪⚪⚪⚪\n",
                "```\n",
                "\n",
                "Allow the game to have additional rules. Some suggestions are a \"No country\" rule, and a \"No articles above a given length\" rule, but feel free to add more if you think of any others. With all of our elicitation methods, the agent generally only fails if the path is impossible or incredibly incredibly hard"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class WikiGameRules(WikiGameHistory):\n",
                "    \"\"\"\n",
                "    Inherits from WikiGameHistory and adds the ability to store and display the rules of the game.\n",
                "\n",
                "    Attributes:\n",
                "        starting_page (str): The title of the starting page (inherited)\n",
                "        goal_page (str): The title of the goal page (inherited)\n",
                "        current_page (WikipediaPage): The current Wikipedia page (inherited)\n",
                "        page_history (List[str]): The history of pages visited (inherited)\n",
                "        full_chat_history (List[dict]): The full history of messages sent (inherited)\n",
                "\n",
                "    Methods:\n",
                "        get_page(title: str) -> WikipediaPage: Get a Wikipedia page object given a title (inherited)\n",
                "\n",
                "        get_page_summary(page: WikipediaPage | None = None) -> str: Get the summary of a Wikipedia page (inherited)\n",
                "\n",
                "        get_permitted_links(title: Optional[str] = None) -> list[str]: Get permitted links for the current page (inherited)\n",
                "\n",
                "        is_permitted_link(link: str) -> bool: Check if a link is permitted (inherited)\n",
                "\n",
                "        system_instruction -> dict: Generate the starting instructions for the game (inherited)\n",
                "\n",
                "        on_page_instruction -> dict: Generate instructions for the current page (inherited)\n",
                "\n",
                "        next_step_instruction -> dict: Generate instructions for the next step (inherited)\n",
                "\n",
                "        get_instructions(system: bool, on_page: bool, next_step: bool) -> str: Generate instruction messages based on the current game state (inherited)\n",
                "\n",
                "        check_win() -> bool: Check if the game has been won (inherited)\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(self, starting_page: str, goal_page: str, rules: List[Literal[\"no countries\", \"no pages above length 30000\"]], tools=None):\n",
                "        super().__init__(starting_page, goal_page, tools)\n",
                "        self.rules = rules if rules else None\n",
                "\n",
                "    def system_instruction(self):\n",
                "        \"\"\"\n",
                "        Provide improved starting instructions for the game.\n",
                "\n",
                "        Returns:\n",
                "            dict: The starting instructions. \"role\" is \"system\" for system messages.\n",
                "        \"\"\"\n",
                "        if self.rules:\n",
                "            return {\n",
                "            \"role\" : \"system\",\n",
                "            \"content\" : f\"\"\"You are a wikipedia-racing AI. Your goal is to reach {self.goal_page.title} by accessing links from wikipedia pages. Your current page is {self.current_page.title}. You have access to {str(len(self.tools))} tools, which are:\\n{tool_descriptions}\\n\\nThe additional rules of the game are: {\",\".join(self.rules)}\"\"\"\n",
                "        }\n",
                "        else:\n",
                "            return {\n",
                "            \"role\" : \"system\",\n",
                "            \"content\" : f\"\"\"You are a wikipedia-racing AI. Your goal is to reach {self.goal_page.title} by accessing links from wikipedia pages. Your current page is {self.current_page.title}. You have access to {str(len(self.tools))} tools, which are:\\n{tool_descriptions}\"\"\"\n",
                "        }\n",
                "\n",
                "    def on_page_instruction(self):\n",
                "        \"\"\"\n",
                "        Provide improved instructions for the current page.\n",
                "\n",
                "        Returns:\n",
                "            dict: The instructions for the current page. \"role\" is \"user\" for user messages.\n",
                "        \"\"\"\n",
                "        return {\n",
                "            \"role\" : \"user\",\n",
                "            \"content\" : f\"\"\"You are currently on page: {self.current_page.title}. Make sure you start by reasoning about what steps you should take to get to the article on {self.goal_page.title}. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, {self.goal_page.title} has the following summary:\\n[Begin Summary]\\n{self.get_page_summary(self.goal_page)}\\n[End Summary]\\n\\nThe pages you've visited so far are: {\" -> \".join(self.page_history)}\\n\\nThe rules of the game are: {\",\".join(self.rules)}\"\"\"\n",
                "        }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class move_page_tool_rules(move_page_tool):\n",
                "    \"\"\"\n",
                "    Inherits from move_page_tool and adds the ability to check the rules of the game.\n",
                "    \"\"\"\n",
                "\n",
                "    @staticmethod\n",
                "    def execute(new_page: str, task: Any) -> str:\n",
                "        \"\"\"\n",
                "        Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n",
                "\n",
                "        Args:\n",
                "            task (BaseWikiGame): The current task object.\n",
                "            new_page (str): The title of the new page to move to.\n",
                "\n",
                "        Returns:\n",
                "            str: A message indicating the result of the move\n",
                "        \"\"\"\n",
                "        new_page_normalized = new_page.replace(\"_\", \" \")\n",
                "        if task.is_permitted_link(new_page_normalized):\n",
                "            task.current_page = task.get_page(new_page_normalized)\n",
                "            task.page_history.append(task.current_page.title)\n",
                "            return f\"Moving page to {task.current_page.title}\"\n",
                "        else:\n",
                "            return f\"Couldn't move page to {new_page}. This is not a valid link.\"\n",
                "\n",
                "    @property\n",
                "    def description(self):\n",
                "        \"\"\"\n",
                "        Provides the description of the move_page tool\n",
                "\n",
                "        Returns:\n",
                "            dict: The description of the move_page tool for the API\n",
                "        \"\"\"\n",
                "        return {\n",
                "            \"type\": \"function\",\n",
                "            \"function\": {\n",
                "                \"name\": self.name,\n",
                "                \"description\": \"Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page. If any pages violate the rules of the game\",\n",
                "                \"parameters\": {\n",
                "                    \"type\": \"object\",\n",
                "                    \"properties\": {\n",
                "                        \"new_page\": {\n",
                "                            \"type\": \"string\",\n",
                "                            \"description\": 'The title of the new page you want to move to. This should be formatted the way the title appears on wikipedia (e.g. to move to the wikipedia page for the United States of America, you should enter \"United States\"). Underscores are not necessary.',\n",
                "                        }\n",
                "                    },\n",
                "                    \"required\": [\"new_page\"],\n",
                "                },\n",
                "            },\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Try further elicitation methods\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Test agent performance on these tasks (Need to run agent loads of times to figure out varying difficulty tasks to trial here):\n",
                "- Task 1\n",
                "\n",
                "- Task 2\n",
                "\n",
                "- Task 3\n",
                "\n",
                "- Task 4\n",
                "\n",
                "- Task 5\n",
                "\n",
                "- Task 6\n",
                "\n",
                "- Task 7\n",
                "\n",
                "- Task 8\n",
                "\n",
                "- Task 9\n",
                "\n",
                "- Task 10\n",
                "\n",
                "See what combination of tools appears to work best."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [],
            "source": [
                "x = get_page(\"Aristotle\")\n",
                "print(dir(x))\n",
                "print(x.section(\"Metaphysics/Substance\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "arena",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
